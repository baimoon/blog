<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/blog/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/blog/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="spark," />








  <link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico?v=5.0.1" />






<meta name="description" content="Spark SQL, DataFrames and Dataset GuideOverviewSpark SQL是一个用于结构化数据处理的Spark模块。与Spark RDD API不同，由Spark SQL提供的这些接口在结构化数据和结构化计算执行方面提供了更多信息。在内部，Spark SQL使用了这个额外信息来执行额外的优化。有几种与Spark SQL交互的方法，包括SQL和Dataset A">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark 2.3.1 Spark SQL DataFrames and DatasetsGuide">
<meta property="og:url" content="http://baimoon.github.io/2018/08/10/spark-2-3-1-SparkSQL-DataFramesAndDatasetsGuide/index.html">
<meta property="og:site_name" content="Baimoon's Note">
<meta property="og:description" content="Spark SQL, DataFrames and Dataset GuideOverviewSpark SQL是一个用于结构化数据处理的Spark模块。与Spark RDD API不同，由Spark SQL提供的这些接口在结构化数据和结构化计算执行方面提供了更多信息。在内部，Spark SQL使用了这个额外信息来执行额外的优化。有几种与Spark SQL交互的方法，包括SQL和Dataset A">
<meta property="og:updated_time" content="2018-08-14T04:32:20.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark 2.3.1 Spark SQL DataFrames and DatasetsGuide">
<meta name="twitter:description" content="Spark SQL, DataFrames and Dataset GuideOverviewSpark SQL是一个用于结构化数据处理的Spark模块。与Spark RDD API不同，由Spark SQL提供的这些接口在结构化数据和结构化计算执行方面提供了更多信息。在内部，Spark SQL使用了这个额外信息来执行额外的优化。有几种与Spark SQL交互的方法，包括SQL和Dataset A">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://baimoon.github.io/2018/08/10/spark-2-3-1-SparkSQL-DataFramesAndDatasetsGuide/"/>

  <title> Spark 2.3.1 Spark SQL DataFrames and DatasetsGuide | Baimoon's Note </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/blog/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Baimoon's Note</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Spark 2.3.1 Spark SQL DataFrames and DatasetsGuide
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-08-10T15:21:30+08:00" content="2018-08-10">
              2018-08-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-3-1/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.3.1</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Spark-SQL-DataFrames-and-Dataset-Guide"><a href="#Spark-SQL-DataFrames-and-Dataset-Guide" class="headerlink" title="Spark SQL, DataFrames and Dataset Guide"></a>Spark SQL, DataFrames and Dataset Guide</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Spark SQL是一个用于结构化数据处理的Spark模块。与Spark RDD API不同，由Spark SQL提供的这些接口在结构化数据和结构化计算执行方面提供了更多信息。在内部，Spark SQL使用了这个额外信息来执行额外的优化。有几种与Spark SQL交互的方法，包括SQL和Dataset API。当计算一个结果时，相同的计算引擎会被使用，与你执行计算使用的API／语言无关。这种统一意味着开发者能够轻松在那些提供更加原始的方式处理给定转换的不同API之间进行来回切换。<br>本篇中所有例子使用的样例数据包含在Spark中，并能够使用spark-shell、pyspark shell或sparkR shell来运行。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>Spark SQL的一种用法时执行SQL查询。Spark SQL还能够被用来从Hive实例中读取数据。关于如何配置这个特性，请参考<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables" title="Hive Tables " target="_blank" rel="external">Hive Tables</a>。当在另一种编程语言中执行SQL时，结果会作为一个Dataset/DataFrame来返回。你还能够使用<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#running-the-spark-sql-cli" title="command-line" target="_blank" rel="external">command-line</a>或<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#running-the-thrift-jdbcodbc-server" title="JDBC/ODBC" target="_blank" rel="external">JDBC/ODBC</a>的方式与SQL接口进行交互。</p>
<h3 id="Datasets-and-DataFrames"><a href="#Datasets-and-DataFrames" class="headerlink" title="Datasets and DataFrames"></a>Datasets and DataFrames</h3><p>一个Dataset就是一个分布式数据集。Dataset作为一个新接口在Spark 1.6中被添加，它提供了RDD的优点（强类型、能够使用强大的lambda函数）和Spark SQL的优化执行引擎的有点。一个Dataset能够根据JVM对象来构造，然后使用函数转换（map、flatMap、filter）进行操作。Dataset的API在Scala和Java中时可用的。Python还不支持Dataset API。但是因为Python的动态特性，Dataset API的很多优点已经可用了（例如你可以很自然的通过名称来访问某一行的一个字段 row.columnName）。对于R语言也是如此。<br>一个DataFrame是一个带有列名的数据集。它在概念上等同于关系数据库中的一个表或者一个是R语言或Python语言中data frame，但是底层具更加优化。DataFrame可以根据各种资源进行构建，例如：结构化的数据文件、Hive中的表、外部数据库以及已经存在的RDD。DataFrame API在Scala、Java、Python和R语言中都可用。在Scala和Java中，一个DataFrame相当于一个有很多行的Dataset。在<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset" title="Scala API" target="_blank" rel="external">Scala API</a>中，DataFrame相当于一个Dataset[Row]类型。而在<a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/sql/Dataset.html" title="Java API" target="_blank" rel="external">Java API</a>中，用户需要使用Dataset<row>来表述一个DataFrame。<br>在本文中，我们将经常引用Scala/Java由有Row组成的Dataset来表述DataFrame。</row></p>
<h2 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h2><h3 id="Starting-Point-SparkSession"><a href="#Starting-Point-SparkSession" class="headerlink" title="Starting Point: SparkSession"></a>Starting Point: SparkSession</h3><p>Spark中，所有功能的切入点是<a href="http://spark.apache.org/docs/latest/api/java/index.html#org.apache.spark.sql.SparkSession" title="SparkSession" target="_blank" rel="external">SparkSession</a>类。要创建一个基本的SparkSession，只需要使用SparkSession.builder()<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</div><div class="line"></div><div class="line">SparkSession spark = SparkSession</div><div class="line">  .builder()</div><div class="line">  .appName(<span class="string">"Java Spark SQL basic example"</span>)</div><div class="line">  .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>)</div><div class="line">  .getOrCreate();</div></pre></td></tr></table></figure></p>
<p>在Spark库的“examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java”目录下，查看完整的示例代码。<br>SparkSession是Spark 2.0的内置功能，用于提供Hive特性，包括用来写HiveQL查询、<br>访问Hive UDFs已经从Hive表中读取数据。要使用这些特性，你不需要配置Hive。</p>
<h3 id="Creating-DataFrames"><a href="#Creating-DataFrames" class="headerlink" title="Creating DataFrames"></a>Creating DataFrames</h3><p>使用SparkSession，application能够从一个已经存在的RDD、一个Hive表或<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources" title="Spark data sources" target="_blank" rel="external">Spark data sources</a>来创建DataFrame。<br>作为一个例子，下面的代码根据一个JSON文件中的内容来创建一个DataFrame：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</div><div class="line"></div><div class="line">Dataset&lt;Row&gt; df = spark.read().json(<span class="string">"examples/src/main/resources/people.json"</span>);</div><div class="line"></div><div class="line"><span class="comment">// Displays the content of the DataFrame to stdout</span></div><div class="line">df.show();</div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// | age|   name|</span></div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// |null|Michael|</span></div><div class="line"><span class="comment">// |  30|   Andy|</span></div><div class="line"><span class="comment">// |  19| Justin|</span></div><div class="line"><span class="comment">// +----+-------+</span></div></pre></td></tr></table></figure></p>
<p>完整的代码，请查看Spark库中的“examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java”。</p>
<h3 id="Untyped-Dataset-Operations-aka-DataFrame-Operations"><a href="#Untyped-Dataset-Operations-aka-DataFrame-Operations" class="headerlink" title="Untyped Dataset Operations(aka DataFrame Operations)"></a>Untyped Dataset Operations(aka DataFrame Operations)</h3><p>在Scala、Java、Python和R语言中，DataFrames针对不同的语言提供不同的结构化数据操作。正如上面提到的，在Spark2.0中，在Scala和Java的API中，DataFrames是以Dataset<row>来表述的。这些操作也被称为“无类型转换”，与强类型转换的Scala/Java Dataset的类型形成对比。<br>这里，我们展示了使用Dataset进行结构化数据处理的基本示例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// col("...") is preferable to df.col("...")</span></div><div class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.apache.spark.sql.functions.col;</div><div class="line"></div><div class="line"><span class="comment">// Print the schema in a tree format</span></div><div class="line">df.printSchema();</div><div class="line"><span class="comment">// root</span></div><div class="line"><span class="comment">// |-- age: long (nullable = true)</span></div><div class="line"><span class="comment">// |-- name: string (nullable = true)</span></div><div class="line"></div><div class="line"><span class="comment">// Select only the "name" column</span></div><div class="line">df.select(<span class="string">"name"</span>).show();</div><div class="line"><span class="comment">// +-------+</span></div><div class="line"><span class="comment">// |   name|</span></div><div class="line"><span class="comment">// +-------+</span></div><div class="line"><span class="comment">// |Michael|</span></div><div class="line"><span class="comment">// |   Andy|</span></div><div class="line"><span class="comment">// | Justin|</span></div><div class="line"><span class="comment">// +-------+</span></div><div class="line"></div><div class="line"><span class="comment">// Select everybody, but increment the age by 1</span></div><div class="line">df.select(col(<span class="string">"name"</span>), col(<span class="string">"age"</span>).plus(<span class="number">1</span>)).show();</div><div class="line"><span class="comment">// +-------+---------+</span></div><div class="line"><span class="comment">// |   name|(age + 1)|</span></div><div class="line"><span class="comment">// +-------+---------+</span></div><div class="line"><span class="comment">// |Michael|     null|</span></div><div class="line"><span class="comment">// |   Andy|       31|</span></div><div class="line"><span class="comment">// | Justin|       20|</span></div><div class="line"><span class="comment">// +-------+---------+</span></div><div class="line"></div><div class="line"><span class="comment">// Select people older than 21</span></div><div class="line">df.filter(col(<span class="string">"age"</span>).gt(<span class="number">21</span>)).show();</div><div class="line"><span class="comment">// +---+----+</span></div><div class="line"><span class="comment">// |age|name|</span></div><div class="line"><span class="comment">// +---+----+</span></div><div class="line"><span class="comment">// | 30|Andy|</span></div><div class="line"><span class="comment">// +---+----+</span></div><div class="line"></div><div class="line"><span class="comment">// Count people by age</span></div><div class="line">df.groupBy(<span class="string">"age"</span>).count().show();</div><div class="line"><span class="comment">// +----+-----+</span></div><div class="line"><span class="comment">// | age|count|</span></div><div class="line"><span class="comment">// +----+-----+</span></div><div class="line"><span class="comment">// |  19|    1|</span></div><div class="line"><span class="comment">// |null|    1|</span></div><div class="line"><span class="comment">// |  30|    1|</span></div><div class="line"><span class="comment">// +----+-----+</span></div></pre></td></tr></table></figure></row></p>
<p>完整的样例代码，查看Spark库的examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java。<br>在Dataset上能够执行的操作类型列表，可以查看<a href="http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Dataset.html" title="API Document" target="_blank" rel="external">API Document</a>。<br>除了简单的列引用和计算外，Dataset还有一个丰富的函数库，包括字符串的操作、日期的计算以及常用的数学操作等。完整的列表可以在<a href="http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/functions.html" title="DataFrame Function Reference" target="_blank" rel="external">DataFrame Function Reference</a>找到。</p>
<h3 id="Running-SQL-Queries-Programmatically"><a href="#Running-SQL-Queries-Programmatically" class="headerlink" title="Running SQL Queries Programmatically"></a>Running SQL Queries Programmatically</h3><p>SparkSession上的sql函数使application能够执行SQL查询，并返回一个Dataset<row>作为结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.sql.Dataset;</div><div class="line">import org.apache.spark.sql.Row;</div><div class="line"></div><div class="line">// Register the DataFrame as a SQL temporary view</div><div class="line">df.createOrReplaceTempView(&quot;people&quot;);</div><div class="line"></div><div class="line">Dataset&lt;Row&gt; sqlDF = spark.sql(&quot;SELECT * FROM people&quot;);</div><div class="line">sqlDF.show();</div><div class="line">// +----+-------+</div><div class="line">// | age|   name|</div><div class="line">// +----+-------+</div><div class="line">// |null|Michael|</div><div class="line">// |  30|   Andy|</div><div class="line">// |  19| Justin|</div><div class="line">// +----+-------+</div></pre></td></tr></table></figure></row></p>
<p>完整的代码，请查看Spark库中的 examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java 。</p>
<h3 id="Global-Temporary-View"><a href="#Global-Temporary-View" class="headerlink" title="Global Temporary View"></a>Global Temporary View</h3><p>在Spark SQL中，临时视图是session范围的，将会伴随着创建它的那个session的终止而消失。如果你想要跨session共享一个临时视图，并让它存活到application终止，你可以创建一个全局临时视图。全局视图与一个名为‘global_temp’的由系统保护的数据库进行绑定，我们必须使用这个特殊的名字来引用它，如：SELECT * FROM global_temp.view1。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Register the DataFrame as a global temporary view</span></div><div class="line">df.createGlobalTempView(<span class="string">"people"</span>);</div><div class="line"></div><div class="line"><span class="comment">// Global temporary view is tied to a system preserved database `global_temp`</span></div><div class="line">spark.sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show();</div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// | age|   name|</span></div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// |null|Michael|</span></div><div class="line"><span class="comment">// |  30|   Andy|</span></div><div class="line"><span class="comment">// |  19| Justin|</span></div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"></div><div class="line"><span class="comment">// Global temporary view is cross-session</span></div><div class="line">spark.newSession().sql(<span class="string">"SELECT * FROM global_temp.people"</span>).show();</div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// | age|   name|</span></div><div class="line"><span class="comment">// +----+-------+</span></div><div class="line"><span class="comment">// |null|Michael|</span></div><div class="line"><span class="comment">// |  30|   Andy|</span></div><div class="line"><span class="comment">// |  19| Justin|</span></div><div class="line"><span class="comment">// +----+-------+</span></div></pre></td></tr></table></figure></p>
<p>完整的代码，请查看“examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java”。</p>
<h3 id="Creating-Datasets"><a href="#Creating-Datasets" class="headerlink" title="Creating Datasets"></a>Creating Datasets</h3>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/spark/" rel="tag">#spark</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018/08/10/spark-2-3-1-QuickStart/" rel="next" title="spark_2.3.1_QuickStart">
                <i class="fa fa-chevron-left"></i> spark_2.3.1_QuickStart
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2018/08/13/ambari/" rel="prev" title="Ambari">
                Ambari <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/blog/uploads/avatar.png"
               alt="baimoon" />
          <p class="site-author-name" itemprop="name">baimoon</p>
          <p class="site-description motion-element" itemprop="description">Baimoon's blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/blog/archives">
              <span class="site-state-item-count">37</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/blog/categories">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/blog/tags">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/baimoon" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://gallery.xrange.org" title="xrange" target="_blank">xrange</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark-SQL-DataFrames-and-Dataset-Guide"><span class="nav-number">1.</span> <span class="nav-text">Spark SQL, DataFrames and Dataset Guide</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Overview"><span class="nav-number">1.1.</span> <span class="nav-text">Overview</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SQL"><span class="nav-number">1.1.1.</span> <span class="nav-text">SQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Datasets-and-DataFrames"><span class="nav-number">1.1.2.</span> <span class="nav-text">Datasets and DataFrames</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Getting-Started"><span class="nav-number">1.2.</span> <span class="nav-text">Getting Started</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Starting-Point-SparkSession"><span class="nav-number">1.2.1.</span> <span class="nav-text">Starting Point: SparkSession</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Creating-DataFrames"><span class="nav-number">1.2.2.</span> <span class="nav-text">Creating DataFrames</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Untyped-Dataset-Operations-aka-DataFrame-Operations"><span class="nav-number">1.2.3.</span> <span class="nav-text">Untyped Dataset Operations(aka DataFrame Operations)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Running-SQL-Queries-Programmatically"><span class="nav-number">1.2.4.</span> <span class="nav-text">Running SQL Queries Programmatically</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Global-Temporary-View"><span class="nav-number">1.2.5.</span> <span class="nav-text">Global Temporary View</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Creating-Datasets"><span class="nav-number">1.2.6.</span> <span class="nav-text">Creating Datasets</span></a></li></ol></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016-07 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">baimoon</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/blog/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/blog/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/blog/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
