<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/blog/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/blog/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico?v=5.0.1" />






<meta name="description" content="Baimoon&apos;s blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Baimoon's Note">
<meta property="og:url" content="http://baimoon.github.io/page/2/index.html">
<meta property="og:site_name" content="Baimoon's Note">
<meta property="og:description" content="Baimoon&apos;s blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Baimoon's Note">
<meta name="twitter:description" content="Baimoon&apos;s blog">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://baimoon.github.io/page/2/"/>

  <title> Baimoon's Note </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/blog/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Baimoon's Note</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/08/09/spark-2-3-1-submit-applications/" itemprop="url">
                  Spark 2.3.1 Submit Applications
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-08-09T15:33:36+08:00" content="2018-08-09">
              2018-08-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-3-1/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.3.1</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Submitting-Applications"><a href="#Submitting-Applications" class="headerlink" title="Submitting Applications"></a>Submitting Applications</h1><p>Spark的bin目录下的spark-submit脚本用于在一个集群上启动一个应用。通过一个统一的接口，它可以使用所有Spark支持的集群管理器，因此你不需要针对每种集群管理器来单独配置你的应用。</p>
<h2 id="Bunding-Your-Application’s-Dependencies"><a href="#Bunding-Your-Application’s-Dependencies" class="headerlink" title="Bunding Your Application’s Dependencies"></a>Bunding Your Application’s Dependencies</h2><p>如果你的代码依赖其他项目，那么你需要将它们和你的应用一并打包，以便分发代码到一个spark集群。要完成这些，需要创建一个assembly jar(uber jar)来包含你的代码和代码的依赖。sbt和Maven都有assembly插件。当创建assembly jar时，排除Spark和Hadoop提供的依赖，因为这些不需要绑定，因为这些将由集群管理器在运行时提供。一旦你弄好了assembly jar，你就可以如下所示在调用 bin/spark-submit脚本是传递你的jar。<br>对于Python，你可以使用spark-submit的–py-files参数来添加.py、.zip或.egg文件，让他们和你的应用一起分发。如果你依赖多个python文件，我们推荐将他们打到一个.zip或.egg包中。</p>
<h2 id="Launching-Applications-with-spark-submit"><a href="#Launching-Applications-with-spark-submit" class="headerlink" title="Launching Applications with spark-submit"></a>Launching Applications with spark-submit</h2><p>一旦一个用户应用被绑定，就可以使用bin/spark-submit脚本来启动这个应用。这个脚本负责设置Spark的classpath和它依赖，而且脚本支持由Spark支持的不同的集群管理器和部署模式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit \</div><div class="line">  --class &lt;main-class&gt; \</div><div class="line">  --master &lt;master-url&gt; \</div><div class="line">  --deploy-mode &lt;deploy-mode&gt; \</div><div class="line">  --conf &lt;key&gt;=&lt;value&gt; \</div><div class="line">  ... # other options</div><div class="line">  &lt;application-jar&gt; \</div><div class="line">  [application-arguments]</div></pre></td></tr></table></figure></p>
<p>一些常用的选项：</p>
<blockquote>
<p>–class：你应用的执行程序(如：org.apache.spark.example.SparkPi)<br>–master：集群的master URL（如：spark://23.195.26.187:7077）<br>–deploy-mode：在worker节点(cluster)上部署你的driver还是在本地作为一个额外的客户端(client)来部署。默认是client。<br>–conf：以key=velue格式配置的任意的Spark配置属性。对于包含空格的值，使用双引号包含起来，如”key=value”。<br>application-jar：指向你的应用程序和它依赖的jar的路径。这个URL必须是你集群内部全局可见，例如，一个hdfs://路径或一个在所有节点上都存在的file://路径。<br>application-arguments：任何需要传递给你的主类的主方法的参数。</p>
</blockquote>
<p>常见的部署策略是，在一个与你的worker机位置相同的gateway机器上提交你的应用。在这种设置中，client模式是合适的，driver在spark-submit进程中被直接启动，这种方式像是集群的一个client。这个应用的输入和输出被打印到控制台。因此这种模式特别适合那些涉及REPL的应用。</p>
<p>此外，如果你的应用是用一个远离worker机器的机器上提交的，通常使用cluster模式来降低drivers和executors之间的网络传输。目前，standalone模式还不能够为Python应用提供cluster模式。</p>
<p>对于Python应用，在<application-jar>处传递一个.py来代替一个jar，在–py-files中添加.zip、.egg或.py，作为搜索目录。</application-jar></p>
<p>这里有一些选项可用，用来指定使用的集群管理器。例如，对于cluster部署模式的standalone管理器管理的Saprk集群，你可以指定 –supervise 来保证在非0退出代码时，driver被自动重启。要枚举spark-submit所有可用的选项，使用–help运行spark-submit。这里有些常用的选项：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"># Run application locally on 8 cores</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master local[8] \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  100</div><div class="line"></div><div class="line"># Run on a Spark standalone cluster in client deploy mode</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master spark://207.184.161.138:7077 \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"></div><div class="line"># Run on a Spark standalone cluster in cluster deploy mode with supervise</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master spark://207.184.161.138:7077 \</div><div class="line">  --deploy-mode cluster \</div><div class="line">  --supervise \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"></div><div class="line"># Run on a YARN cluster</div><div class="line">export HADOOP_CONF_DIR=XXX</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master yarn \</div><div class="line">  --deploy-mode cluster \  # can be client for client mode</div><div class="line">  --executor-memory 20G \</div><div class="line">  --num-executors 50 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"></div><div class="line"># Run a Python application on a Spark standalone cluster</div><div class="line">./bin/spark-submit \</div><div class="line">  --master spark://207.184.161.138:7077 \</div><div class="line">  examples/src/main/python/pi.py \</div><div class="line">  1000</div><div class="line"></div><div class="line"># Run on a Mesos cluster in cluster deploy mode with supervise</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master mesos://207.184.161.138:7077 \</div><div class="line">  --deploy-mode cluster \</div><div class="line">  --supervise \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  http://path/to/examples.jar \</div><div class="line">  1000</div><div class="line"></div><div class="line"># Run on a Kubernetes cluster in cluster deploy mode</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master k8s://xx.yy.zz.ww:443 \</div><div class="line">  --deploy-mode cluster \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --num-executors 50 \</div><div class="line">  http://path/to/examples.jar \</div><div class="line">  1000</div></pre></td></tr></table></figure></p>
<h2 id="Master-URLs"><a href="#Master-URLs" class="headerlink" title="Master URLs"></a>Master URLs</h2><p>传递给Spark的master URL可以是下面格式中的一个：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Master URL</th>
<th style="text-align:left">Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">local</td>
<td style="text-align:left">使用单个线程以本地模式运行Spark</td>
</tr>
<tr>
<td style="text-align:left">local[K]</td>
<td style="text-align:left">使用K个线程以本地模式运行Spark</td>
</tr>
<tr>
<td style="text-align:left">local[K, F]</td>
<td style="text-align:left">使用K个线程以本地模式运行Spark，允许最多F个失败</td>
</tr>
<tr>
<td style="text-align:left">local[*]</td>
<td style="text-align:left">使用与你机器逻辑核数相同的线程，以本地模式运行Spark</td>
</tr>
<tr>
<td style="text-align:left">local[*, F]</td>
<td style="text-align:left">使用于你机器逻辑核数相同的香橙，以本地模式运行Spark，允许最多F个失败</td>
</tr>
<tr>
<td style="text-align:left">spark://HOST:PORT</td>
<td style="text-align:left">连接到给定的以standalone模式运行的集群的Master。端口必须是你的master所配置使用的，默认为7077</td>
</tr>
<tr>
<td style="text-align:left">spark://HOST1:PORT1,HOST2:PORT2</td>
<td style="text-align:left">连接到使用了Zookeeper以standalone模式运行的带有standby master的集群。这个列表必须包含了使用Zookeeper配置的高可用集群的所有master的host。端口必须是你的master所配置使用的，默认为7077。</td>
</tr>
<tr>
<td style="text-align:left">mesos://HOST:PORT</td>
<td style="text-align:left">连接到给定的以MESOS模式运行的集群。端口必须是你的配置中使用的，默认为5050。或者，对于使用了Zookeeper的Mesos集群，使用mesos://zk://…配合–deploy-mode cluster来提交，HOST:PORT应该被配置为连接到MesosClusterDispatcher。</td>
</tr>
<tr>
<td style="text-align:left">yarn</td>
<td style="text-align:left">以cluster或client模式连接到yarn集群，连接模式通过 –deploy-mode来指定。这个集群的位置将基于HADOOP_CONF_DIR或YARN_CONF_DIR变量来找到。</td>
</tr>
<tr>
<td style="text-align:left">k8s://HOST:PORT</td>
<td style="text-align:left">以cluster模式连接到Kubernetes集群。Client模式当前还不支持，将会在未来被支持。HOST和PORT指向[Kubernetes API Server]。默认使用TLS连接。想要强制使用不安全的连接，你可以使用k8s://<a href="http://HOST:PORT。" target="_blank" rel="external">http://HOST:PORT。</a></td>
</tr>
</tbody>
</table>
<h2 id="Loading-Configuration-from-a-File"><a href="#Loading-Configuration-from-a-File" class="headerlink" title="Loading Configuration from a File"></a>Loading Configuration from a File</h2><p>spark-submit脚本能够从一个属性文件中加载默认的Spark配置属性值，并传递它们到你的应用。默认它将从<br>Spark目录的conf/spark-defaults.conf中读取选项。<br>加载默认Spark配置，这种方式可以避免给spark-submit设置有确切值的选项（有些选项的值是固定的）。例如，如果设置了spark.master属性，你就可以在spark-submit中忽略–master项了。通常，在SparkConf中设置的值具有最高优先级，其次是传递给spark-submit的值，最后是默认文件里的值。</p>
<p>如果你无法确认配置项的值来自哪里，你可以在运行spark-submit是使用-verbose选项，将细粒度的调试信息打印出来。</p>
<h2 id="Advanced-Dependency-Management"><a href="#Advanced-Dependency-Management" class="headerlink" title="Advanced Dependency Management"></a>Advanced Dependency Management</h2><p>在使用spark-submit的时候，应用程序jar以及使用–jars选项包含的人和jar将会自动传输到集群。–jars后面提供的URLs必须以逗号分隔。那个列表被包含在driver和executor的classpath中。目录范围在–jars中不起作用。<br>Spark使用如下的URL模式来允许不同的策略传递jar：</p>
<blockquote>
<p>file: 绝对路径，并且file:/ URLs由driver的HTTP文件服务提供服务，每个executor从driver的HTTP服务拉取文件。<br>hdfs:、http:、https:、ftp: 这些按照期望的那样从URI拉取文件和Jars。<br>local: 一个以local:/开头的URI，希望作为每个worker节点上的本地文件而存在。这意味着将不会发生网络IO。这种适用于将较大文件或jar推送到每个worker或通过NFS、GlusterFS等共享较大文件或Jar的方式。</p>
</blockquote>
<p>注意，JARs和文件会为每个运行在executor节点上的SparkContext拷贝一份到工作目录。随着时间的推移，这将耗费大量的空间，因此需要清理。对于使用YARN的方式，清理将会自动方式；对于使用standalone方式的，自动清理工作可以通过spark.worker.cleanup.appDataTtl属性配置。</p>
<p>用户还可以通过使用-packages提供以逗号分隔的Maven坐标列表来包含任何其他依赖。使用此命令时，所有传递的依赖都将被处理。另外，使用–repositories选项，还可以用来添加maven库。多个库之间使用逗号分隔。这些命令可以被pyspark、spark-shell以及spark-submit来使用来包含Saprk包。<br>对于Python，–py-files选项可以被用来分发.egg、.zip以及.py文件到executors。</p>
<h2 id="More-Information"><a href="#More-Information" class="headerlink" title="More Information"></a>More Information</h2><p>一旦你部署了你的应用，cluster mode overview 描述了分布式执行中的各个组件，以及如何监控和调试应用。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/08/09/spark-2-3-1-overview/" itemprop="url">
                  Spark 2.3.1 Overview
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-08-09T12:45:35+08:00" content="2018-08-09">
              2018-08-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-3-1/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.3.1</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Spark-Overview"><a href="#Spark-Overview" class="headerlink" title="Spark Overview"></a>Spark Overview</h1><p>Apache Spark是一个很快的用于一般目的的集群计算系统。它在Java、Python和R语言上提供了高级别的API，并且提供了一个支持一般图计算的优化引擎。它还提供了一组丰富的高级别的工具，包括SQL和结构化数据处理所需要的Spark SQL、机器学习所需要的MLlib、图处理所需要的GraphX以及Spark Streaming。</p>
<h2 id="Downloading"><a href="#Downloading" class="headerlink" title="Downloading"></a>Downloading</h2><p>从项目网站的下载页获取Spark。这个文档为是针对的Spark2.3.1版本。Spark为了使用HDFS和YARN使用了Hadoop客户端库。这个下载中预置了一些常用的Hadoop版本。用户还可以下载一个”Hadoop free”库通过Spark的classpath指定Hadoop版本来运行Spark。Scala和Java用户可以在自己的项目的中使用Spark的Mave依赖来包含Spark，而Python用户在未来也可以从PyPI中安装Spark。</p>
<p>如果你喜欢从源码构建Spark，可以通过这个链接来操作。</p>
<p>Spark能够运行在Windowns和类UNIX的系统上。在一台机器上以本地模式运行很容易–你需要做的事情就是在你的系统路径中安装java或者在环境变量JAVA_HOME中指向Java的安装。</p>
<p>Spark运行在Java 8+， Python 2.7+/3.4+或R 3.1+上。对于Scala API，Spark2.3.1使用的是Scala2.11。你需要使用一个合适Scala版本（Scala2.11+）。</p>
<p>注意，对于Java 7、Python 2.6以及2.6.5以前的Hadoop版本的支持，已经在Spark 2.2.0中移除。对于Scala2.10版本的支持在Spark 2.3.0中移除了。</p>
<h2 id="Running-the-Examples-and-Shell"><a href="#Running-the-Examples-and-Shell" class="headerlink" title="Running the Examples and Shell"></a>Running the Examples and Shell</h2><p>Spark带有一些简单的样例程序。Scala、Java和R的样例都在examples/src/main目录下。想要运行一个Java或Scala样例程序，需要使用顶级Spark目录下bin/run-example <class> [params]。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/run-example SparkPi 10</div></pre></td></tr></table></figure></class></p>
<p>你还可以通过Scala shell的一个修改版，以交互的方式运行Saprk。这对于学习这个框架是很好的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/spark-shell --master local[2]</div></pre></td></tr></table></figure></p>
<p>其中的–master选项指定了一个分布式集群的master的URL，或者使用一个线程以本地模式运行，或者local[N]表示使用N个线程以本地模式运行。你可以从使用本地模式做测试来开始。对于选项的全部列表，使用使用–help选项来运行Spark shell。<br>Spark还提供了一个Python的API。想要在Python解析器中以交互方式运行Spark，可以使用 bin/pyspark：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/pyspark --master local[2]</div></pre></td></tr></table></figure></p>
<p>样例application也提供了Python版本。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit examples/src/main/python/pi.py 10</div></pre></td></tr></table></figure></p>
<p>从Spark1.4开始Spark也提供了R API的样例。要以R解析器中以交互方式运行Spark，可以使用 bin/sparkR:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/sparkR --master local[2]</div></pre></td></tr></table></figure></p>
<p>样例程序同样也提供了R语言版本的，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit examples/src/main/r/dataframe.R</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/07/13/HiveStudy/" itemprop="url">
                  Hive Study
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-07-13T15:53:05+08:00" content="2018-07-13">
              2018-07-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用来记录自己在使用Hive Sql方面的一些经验。</p>
<h1 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h1><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># 创建了一个带有两个分区的表，这个表按照partition_date和hour进行分区</div><div class="line">CREATE EXTERNAL TABLE `user.user_action`(</div><div class="line">     `action` string COMMENT '&#123;"chs_name":"", "description":"","etl":"","value":"","remark":""&#125;',</div><div class="line">     `num` double comment '&#123;"chs_name":"", "description":"","etl":"","value":"","remark":""&#125;'</div><div class="line">  )</div><div class="line">PARTITIONED BY ( `partition_date` string COMMENT '分区日期',  `hour` string COMMENT '小时')</div><div class="line">ROW FORMAT DELIMITED</div><div class="line">    --TODO: 导入MYSQL的表建议'\t'分隔</div><div class="line">    FIELDS TERMINATED BY '\t'</div><div class="line">    COLLECTION ITEMS TERMINATED BY '\002'</div><div class="line">    MAP KEYS TERMINATED BY '\003'</div><div class="line">    LINES TERMINATED BY '\n'</div><div class="line">STORED as textfile;</div></pre></td></tr></table></figure>
<h1 id="查询数据并将数据写入到表中"><a href="#查询数据并将数据写入到表中" class="headerlink" title="查询数据并将数据写入到表中"></a>查询数据并将数据写入到表中</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> user.user_action</div><div class="line"><span class="keyword">partition</span>(partition_date = <span class="string">'20180602'</span>, <span class="keyword">hour</span>=<span class="string">'0'</span>)</div><div class="line"><span class="keyword">select</span> <span class="keyword">action</span>,</div><div class="line">       <span class="keyword">sum</span>(<span class="keyword">num</span>) <span class="keyword">as</span> n</div><div class="line">  <span class="keyword">from</span> (</div><div class="line">        <span class="keyword">select</span> <span class="keyword">action</span>,</div><div class="line">               <span class="keyword">num</span></div><div class="line">          <span class="keyword">from</span> (</div><div class="line">               <span class="keyword">select</span> momo_id, </div><div class="line">                      event_num_map </div><div class="line">                 <span class="keyword">from</span> db.event_summary </div><div class="line">                <span class="keyword">where</span> partition_date = <span class="string">'20180602'</span></div><div class="line">                  <span class="keyword">and</span> <span class="keyword">size</span>(event_num_map)&gt;<span class="number">0</span></div><div class="line">          )a</div><div class="line">          LATERAL <span class="keyword">VIEW</span> EXPLODE(event_num_map)t <span class="keyword">AS</span> <span class="keyword">action</span>, <span class="keyword">num</span></div><div class="line">    </div><div class="line">  )b</div><div class="line">  <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">action</span>;</div></pre></td></tr></table></figure>
<p>该表从db.event_summary中查询数据然后吸入到user.user_action表中。需要注意db.event_summay中的event_num_map字段是一个map，map的key是action，value是action的数量。这里使用了一个函数LATERAL VIEW EXPLODE，用来map展开。</p>
<h1 id="一些常用函数"><a href="#一些常用函数" class="headerlink" title="一些常用函数"></a>一些常用函数</h1><h2 id="ROW-NUMBER-OVER-函数"><a href="#ROW-NUMBER-OVER-函数" class="headerlink" title="ROW_NUMBER() OVER()函数"></a>ROW_NUMBER() OVER()函数</h2><p>ROW_NUMBER() OVER()函数用来为每条记录返回一个行号，可以用来对记录进行排序并返回该序号，需要从1开始排序。<br>OVER()是一个聚合函数，可以对记录进行分组和排序。ROW_NUMBER()不能单独使用，必须搭配OVER()才能使用，否则会报错。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select *, row_number() over() as r from mytable;</div></pre></td></tr></table></figure></p>
<p>配合partition by/order by<br>按照某个字段排序后返回行号<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select *, row_number() over(partition by aaaaab order by num desc) r from mytable;</div></pre></td></tr></table></figure></p>
<p>按照aaaaab分组后，并根据aaaaaab进行倒序排列。</p>
<h1 id="SQL中的类型转换"><a href="#SQL中的类型转换" class="headerlink" title="SQL中的类型转换"></a>SQL中的类型转换</h1><p>需要使用cast()函数进行类型转换。</p>
<blockquote>
<p>cast(str_column as int) </p>
</blockquote>
<h1 id="一些经验的总结"><a href="#一些经验的总结" class="headerlink" title="一些经验的总结"></a>一些经验的总结</h1><h2 id="一个表中分时段记录内容的统一查询"><a href="#一个表中分时段记录内容的统一查询" class="headerlink" title="一个表中分时段记录内容的统一查询"></a>一个表中分时段记录内容的统一查询</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>遇到的情况是这样的，有一个表A，表A中有24个字段（event_0_map … event_24_map）用来记录对应小时内每个用户各自发生的一些事情的数量。表结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">id string = 1000010</div><div class="line">event_0_map = &#123;&apos;event0&apos;:200, &apos;event2&apos;:100&#125;</div><div class="line">...</div><div class="line">event_24_map = &#123;&apos;event0&apos;:500, &apos;event2&apos;:800&#125;</div><div class="line">partition = &apos;20180101&apos;</div></pre></td></tr></table></figure></p>
<p>现在有一个需求：需要统计每个小时发生事件最多的前100个事件</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>因为是每个小时执行的任务，而且每个小时的数据是存放在不同的字段里面，而字段名在SQL中是不可以拼接的，如：event_24_map，无法来拼接，因此有两种方案。</p>
<h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h4><p>生成24个任务，每个任务的SQL都一样，只是查询的字段不一样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">select action,</div><div class="line">       num</div><div class="line">  from (</div><div class="line">       select id, </div><div class="line">              event_0_map </div><div class="line">         from online.tableA </div><div class="line">        where partition = &apos;$&#123;partition_date&#125;&apos;</div><div class="line">          and size(event_0_map)&gt;0</div><div class="line">  )a0</div><div class="line">  LATERAL VIEW EXPLODE(event_0_map)t AS action, num</div></pre></td></tr></table></figure></p>
<h4 id="方案二-推荐"><a href="#方案二-推荐" class="headerlink" title="方案二(推荐)"></a>方案二(推荐)</h4><p>将所有的字段同时解析，生成一个大表，再对大表进行过滤查询<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">select action,</div><div class="line">       num</div><div class="line">  from (</div><div class="line">		select action,</div><div class="line">		       num,</div><div class="line">		       &apos;00&apos; as hour</div><div class="line">		  from (</div><div class="line">		       select id, </div><div class="line">		              event_0_map </div><div class="line">		         from online.tableA </div><div class="line">		        where partition = &apos;$&#123;partition_date&#125;&apos;</div><div class="line">		          and size(event_0_map)&gt;0</div><div class="line">		  )a0</div><div class="line">		  LATERAL VIEW EXPLODE(event_0_map)t AS action, num</div><div class="line">		union all</div><div class="line">		select action,</div><div class="line">		       num,</div><div class="line">		       &apos;01&apos; as hour</div><div class="line">		  from (</div><div class="line">		       select id, </div><div class="line">		              event_2_map </div><div class="line">		         from online.tableA </div><div class="line">		        where partition = &apos;$&#123;partition_date&#125;&apos;</div><div class="line">		          and size(event_2_map)&gt;0</div><div class="line">		  )a1</div><div class="line">		  LATERAL VIEW EXPLODE(event_2_map)t AS action, num</div><div class="line">	) data</div><div class="line"> where hour = &apos;$&#123;partition_hour&#125;&apos;</div></pre></td></tr></table></figure></p>
<h2 id="表的删除和恢复"><a href="#表的删除和恢复" class="headerlink" title="表的删除和恢复"></a>表的删除和恢复</h2><p>在使用Hive的表的过程中，难免会有对表进行删除的情况，其实把表删除后，数据文件还是存在的，那么如何将数据按照新表的结构恢复一下呢？可以如下操作，但是需要注意的是，对于新增的字段，值是NULL。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">drop table db.table_test;</div><div class="line">...</div><div class="line">create table xxx...</div><div class="line">...</div><div class="line">MSCK REPAIR TABLE db.table_test;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/07/10/easyUseMapreduce/" itemprop="url">
                  Easy Use Mapreduce
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-07-10T15:19:55+08:00" content="2018-07-10">
              2018-07-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用来记录MR的使用，已经遇到的一些问题和解决方法</p>
<p>#使用Python执行MR</p>
<h2 id="Mapper的写法"><a href="#Mapper的写法" class="headerlink" title="Mapper的写法"></a>Mapper的写法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="comment">#加载编码</span></div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">    j = json.loads(line.strip())</div><div class="line">    <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (j.get(<span class="string">"name"</span>), j.get(<span class="string">"age"</span>))</div></pre></td></tr></table></figure>
<h2 id="Reducer的写法"><a href="#Reducer的写法" class="headerlink" title="Reducer的写法"></a>Reducer的写法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/bin/env python</span></div><div class="line">  <span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line">  </div><div class="line">  <span class="keyword">import</span> sys</div><div class="line">  <span class="keyword">import</span> json</div><div class="line">  <span class="keyword">import</span> time</div><div class="line">  </div><div class="line">  <span class="comment">#加载编码</span></div><div class="line">  reload(sys)</div><div class="line">  sys.setdefaultencoding(<span class="string">'utf-8'</span>)</div><div class="line">  </div><div class="line">  uri_count = &#123;&#125;</div><div class="line">  <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">      data = line.strip().split(<span class="string">"\t"</span>)</div><div class="line">      key = <span class="string">"%s-%s"</span> % (data[<span class="number">0</span>], data[<span class="number">1</span>])</div><div class="line">      c = uri_count.get(key, <span class="number">0</span>)</div><div class="line">      uri_count[key] = c + <span class="number">1</span></div><div class="line">  </div><div class="line">  <span class="keyword">for</span> key <span class="keyword">in</span> uri_count:</div><div class="line">      <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (key, uri_count.get(key, <span class="number">0</span>))</div></pre></td></tr></table></figure>
<p>从上面的代码可以看出来，python的脚本需要从标准输入(sys.stdin)中接入数据。</p>
<h2 id="执行Mapreduce"><a href="#执行Mapreduce" class="headerlink" title="执行Mapreduce"></a>执行Mapreduce</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">/home/hadoop/yarn-2.8.1/bin/hadoop jar /home/hadoop/yarn-2.8.1/share/hadoop/tools/lib/hadoop-streaming-2.8.1.jar \</div><div class="line">-D mapreduce.job.queuename=bigdata.queue \</div><div class="line">-input hdfs://nameservice1/data/mylogs/api_request/2018/07/03/*/* \</div><div class="line">-output /tmp/20180703SpecialUri \</div><div class="line">-mapper &quot;specialUriMapper.py&quot; \</div><div class="line">-reducer &quot;specialUriReducer.py&quot; \</div><div class="line">-file /home/hadoop/script/user_action/specialUriMapper.py \</div><div class="line">-file /home/hadoop/script/user_action/specialUriReducer.py \</div><div class="line">-file /home/hadoop/script/user_action/kickA.log</div></pre></td></tr></table></figure>
<p>参数说明：</p>
<blockquote>
<p>-D mapreduce.job.queuename用指定需要运行MR的队列<br>-input MR的输入<br>-output MR的输出<br>-mapper 指定执行MR中Mapper的程序<br>-reducer 指定执行MR中Reducer的程序<br>-file 需要一起上传的文件，如果python程序中使用了其他的数据文件，可以通过这个参数一起上传。</p>
</blockquote>
<p>其他一些参数：</p>
<blockquote>
<p>-D mapreduce.job.name Job的名称<br>-D mapreduce.job.user.name<br>-D mapreduce.job.node-label-expression<br>-D mapreduce.job.queuename<br>-D mapreduce.map.memory.mb<br>-D mapreduce.reduce.memory.mb</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/06/29/netty-study/" itemprop="url">
                  netty-study
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-06-29T11:15:01+08:00" content="2018-06-29">
              2018-06-29
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/netty/" itemprop="url" rel="index">
                    <span itemprop="name">netty</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>NETTY学习笔记</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/05/24/kafka-script/" itemprop="url">
                  kafka-script
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-05-24T17:53:42+08:00" content="2017-05-24">
              2017-05-24
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文主要讨论kafka服务的相关启动和关闭脚本。</p>
<h1 id="kafka-server-start-sh"><a href="#kafka-server-start-sh" class="headerlink" title="kafka-server-start.sh"></a>kafka-server-start.sh</h1><p>Kafka服务的启动脚本，正确的用法为 kafka-server-start.sh [-daemon] server.properties<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># 如果执行脚本时传入的参数小于1个，则退出执行并提示用户需要指定服务属性配置文件， 此处也说明了执行kafka-server-start.sh的正确用法</div><div class="line">if [ $# -lt 1 ];</div><div class="line">then</div><div class="line">	echo &quot;USAGE: $0 [-daemon] server.properties&quot;</div><div class="line">	exit 1</div><div class="line">fi</div><div class="line"></div><div class="line"># $0 表示的是当前shell的文件名，dirname用来获取当前shell文件的所在目录</div><div class="line">base_dir=$(dirname $0)</div><div class="line"></div><div class="line"># 读取环境变量中的KAFKA_LOG4J_OPTS的信息，如果没有配置该环境变量，则将kafka目录下conf中的log4j.properties作为配置添加到环境变量中，配置给KAFKA_LOG4J_OPTS</div><div class="line">if [ &quot;x$KAFKA_LOG4J_OPTS&quot; = &quot;x&quot; ]; then</div><div class="line">    export KAFKA_LOG4J_OPTS=&quot;-Dlog4j.configuration=file:$base_dir/../config/log4j.properties&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 读取环境变量中KAFKA_HEAP_OPTS的信息，如果没有配置该环境变量，则使用默认配置&quot;-Xmx1G -Xms1G&quot;来配置，并添加到环境变量&quot;KAFKA_HEAP_OPTS&quot;中</div><div class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then</div><div class="line">    export KAFKA_HEAP_OPTS=&quot;-Xmx1G -Xms1G&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 定义一个额外的参数 name，为kafka服务指定了进程名</div><div class="line">EXTRA_ARGS=&quot;-name kafkaServer -loggc&quot;</div><div class="line"></div><div class="line"># 如果服务要作为后台进程运行，则需要添加-daemon参数，而且这个参数必须是第一个参数，如果第一个参数是-daemon，则为进程添加自定义的名称</div><div class="line">COMMAND=$1</div><div class="line">case $COMMAND in</div><div class="line">  -daemon)</div><div class="line">    EXTRA_ARGS=&quot;-daemon &quot;$EXTRA_ARGS</div><div class="line">    shift</div><div class="line">    ;;</div><div class="line">  *)</div><div class="line">    ;;</div><div class="line">esac</div><div class="line"></div><div class="line"># 启动kafka服务，由此处也可以看出来，可以使用kafka-run-class.sh来执行相关的类，其中$@表示的是命令行传入的所有参数，这里要启动的类名为kafka.Kafka</div><div class="line">exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka $@</div></pre></td></tr></table></figure></p>
<h1 id="kafka-server-stop-sh"><a href="#kafka-server-stop-sh" class="headerlink" title="kafka-server-stop.sh"></a>kafka-server-stop.sh</h1><p>Kafka服务的停止脚本，其实就是查找KafkaServer对应的进程号，并kill。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 在进程中过滤包含&quot;kafka.Kafka&quot;且不包含&quot;grep&quot;的java进程，截取进程号kill掉</div><div class="line">ps ax | grep -i &apos;kafka\.Kafka&apos; | grep java | grep -v grep | awk &apos;&#123;print $1&#125;&apos; | xargs kill -SIGTERM</div></pre></td></tr></table></figure></p>
<h1 id="kafka-run-class-sh"><a href="#kafka-run-class-sh" class="headerlink" title="kafka-run-class.sh"></a>kafka-run-class.sh</h1><p>kafka-run-class.sh是用来运行class的脚本。正确的用法为 kafka-run-class.sh [-daemon] [-name servicename] [-loggc] classname [opts]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div></pre></td><td class="code"><pre><div class="line"># 验证kafka-run-class脚本的参数</div><div class="line">if [ $# -lt 1 ];</div><div class="line">then</div><div class="line">  echo &quot;USAGE: $0 [-daemon] [-name servicename] [-loggc] classname [opts]&quot;</div><div class="line">  exit 1</div><div class="line">fi</div><div class="line"></div><div class="line"># 获取Kafka的基目录，就是当前目录（bin）的上一层目录</div><div class="line">base_dir=$(dirname $0)/..</div><div class="line"></div><div class="line"># 创建Kafka的日志目录，首先从环境变量“LOG_DIR”中读取，如果没有配置LOG_DIR，则使用Kafka基目录下的logs目录作为日志目录</div><div class="line"># create logs directory</div><div class="line">if [ &quot;x$LOG_DIR&quot; = &quot;x&quot; ]; then</div><div class="line">    LOG_DIR=&quot;$base_dir/logs&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 如果日志目录目存在则创建日志目录</div><div class="line">if [ ! -d &quot;$LOG_DIR&quot; ]; then</div><div class="line">    mkdir -p &quot;$LOG_DIR&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 获取Scala的版本号，首先从环境变量 SCALA_VERSION 中读取，如果没有配置，则使用默认值 2.10.4</div><div class="line">if [ -z &quot;$SCALA_VERSION&quot; ]; then</div><div class="line">	SCALA_VERSION=2.10.4</div><div class="line">fi</div><div class="line"></div><div class="line"># 获取Scala库的版本号，首先从环境变量 SCALA_BINARY_VERSION 中读取，如果没有配置，则使用默认值 2.10</div><div class="line">if [ -z &quot;$SCALA_BINARY_VERSION&quot; ]; then</div><div class="line">	SCALA_BINARY_VERSION=2.10</div><div class="line">fi</div><div class="line"></div><div class="line"># 这里开始加载各种依赖的jar包，并将这些jar包添加到CLASSPATH环境变量中，由此也可以看出运行完整的Kafka服务（支持各种consumer／producer）需要依赖的jar包</div><div class="line"># run ./gradlew copyDependantLibs to get all dependant jars in a local dir</div><div class="line"></div><div class="line"># 将Kafka依赖Scala的jar包添加到CLASSPATH中</div><div class="line">for file in $base_dir/core/build/dependant-libs-$&#123;SCALA_VERSION&#125;*/*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将Kafka的示例jar添加到CLASSPATH中</div><div class="line">for file in $base_dir/examples/build/libs//kafka-examples*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将kafka的hadoop consumer相关jar包添加到CLASSPATH中</div><div class="line">for file in $base_dir/contrib/hadoop-consumer/build/libs//kafka-hadoop-consumer*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将Kafka的hadoop producer相关jar包添加到CLASSPATH中</div><div class="line">for file in $base_dir/contrib/hadoop-producer/build/libs//kafka-hadoop-producer*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将Kafka客户端相关的jar包添加到CLASSPATH中</div><div class="line">for file in $base_dir/clients/build/libs/kafka-clients*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将Kafka的libs下的jar包添加到CLASSPATH中</div><div class="line"># classpath addition for release</div><div class="line">for file in $base_dir/libs/*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 将Kafka依赖的Scala对应版本的库添加到CLASSPATH中</div><div class="line">for file in $base_dir/core/build/libs/kafka_$&#123;SCALA_BINARY_VERSION&#125;*.jar;</div><div class="line">do</div><div class="line">  CLASSPATH=$CLASSPATH:$file</div><div class="line">done</div><div class="line"></div><div class="line"># 以下是Java管理扩展的设置</div><div class="line"># 如果没有在环境变量中设置KAFKA_JMX_OPTS，则将Kafka的JMX配置关闭</div><div class="line"># JMX settings</div><div class="line">if [ -z &quot;$KAFKA_JMX_OPTS&quot; ]; then</div><div class="line">  KAFKA_JMX_OPTS=&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false &quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 如果设置了KAFKA_JMX_OPTS环境变量，则利用这个值来设置变量KAFKA_JMX_OPTS的值，该值用于指定虚拟机的信息</div><div class="line"># JMX port to use</div><div class="line">if [  $JMX_PORT ]; then</div><div class="line">  KAFKA_JMX_OPTS=&quot;$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT &quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># Log4j的配置</div><div class="line"># Log4j settings 如果环境变量中没有设置KAFKA_LOG4J_OPTS，则使用Kafka基目录下conf/tools-log4j.properties来设置KAFKA_LOG4J_OPTS变量</div><div class="line">if [ -z &quot;$KAFKA_LOG4J_OPTS&quot; ]; then</div><div class="line">  KAFKA_LOG4J_OPTS=&quot;-Dlog4j.configuration=file:$base_dir/config/tools-log4j.properties&quot;</div><div class="line">fi</div><div class="line"># 根据环境变量LOG_DIR和KAFKA_LOG4J_OPTS来生成变量KAFKA_LOG4J_OPTS的新的值</div><div class="line">KAFKA_LOG4J_OPTS=&quot;-Dkafka.logs.dir=$LOG_DIR $KAFKA_LOG4J_OPTS&quot;</div><div class="line"></div><div class="line"># 判断环境变量KAFKA_OPTS是否有相关设置</div><div class="line"># Generic jvm settings you want to add</div><div class="line">if [ -z &quot;$KAFKA_OPTS&quot; ]; then</div><div class="line">  KAFKA_OPTS=&quot;&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 判断环境变量JAVA_HOME中是否有值，如果不存在则使用默认的java，如果有，则使用该目录下指定的java</div><div class="line"># Which java to use</div><div class="line">if [ -z &quot;$JAVA_HOME&quot; ]; then</div><div class="line">  JAVA=&quot;java&quot;</div><div class="line">else</div><div class="line">  JAVA=&quot;$JAVA_HOME/bin/java&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># Kafka的内存配置，如果环境变量KAFKA_HEAP_OPTS的值为空，则设置值为默认值-Xmx256M</div><div class="line"># Memory options</div><div class="line">if [ -z &quot;$KAFKA_HEAP_OPTS&quot; ]; then</div><div class="line">  KAFKA_HEAP_OPTS=&quot;-Xmx256M&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 如果没有设置环境变量KAFKA_JVM-PERFORMANCE_OPTS，则使用默认值进行配置</div><div class="line"># JVM performance options</div><div class="line">if [ -z &quot;$KAFKA_JVM_PERFORMANCE_OPTS&quot; ]; then</div><div class="line">  KAFKA_JVM_PERFORMANCE_OPTS=&quot;-server -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true&quot;</div><div class="line">fi</div><div class="line"></div><div class="line"></div><div class="line"># 这里对脚本传入的参数进行解析，提取守护进程名／是否后台运行／GC日志这个三个信息</div><div class="line"># 第一个case，如果循环到了-name参数，则读取-name的下一参数，下一个参数必定是后台进程的名字，而且控制台的输出日志文件也是该名字</div><div class="line"># 第二个case，如果循环到了-loggc，则表示要记录GC日志，记录GC日志的另一个要求是配置KAFKA_GC_LOG_OPTS环境变量</div><div class="line"># 第三个case，如果循环到了-daemon，则表示服务以后台进程的方式运行</div><div class="line">while [ $# -gt 0 ]; do</div><div class="line">  COMMAND=$1</div><div class="line">  case $COMMAND in</div><div class="line">    -name)</div><div class="line">      DAEMON_NAME=$2</div><div class="line">      CONSOLE_OUTPUT_FILE=$LOG_DIR/$DAEMON_NAME.out</div><div class="line">      shift 2</div><div class="line">      ;;</div><div class="line">    -loggc)</div><div class="line">      if [ -z &quot;$KAFKA_GC_LOG_OPTS&quot;] ; then</div><div class="line">        GC_LOG_ENABLED=&quot;true&quot;</div><div class="line">      fi</div><div class="line">      shift</div><div class="line">      ;;</div><div class="line">    -daemon)</div><div class="line">      DAEMON_MODE=&quot;true&quot;</div><div class="line">      shift</div><div class="line">      ;;</div><div class="line">    *)</div><div class="line">      break</div><div class="line">      ;;</div><div class="line">  esac</div><div class="line">done</div><div class="line"></div><div class="line"></div><div class="line"># 如果启用了GC日志，GC日志的名字为后台进程的名字[-name指定]-gc.log。</div><div class="line"># GC options</div><div class="line">GC_FILE_SUFFIX=&apos;-gc.log&apos;</div><div class="line">GC_LOG_FILE_NAME=&apos;&apos;</div><div class="line">if [ &quot;x$GC_LOG_ENABLED&quot; = &quot;xtrue&quot; ]; then</div><div class="line">  GC_LOG_FILE_NAME=$DAEMON_NAME$GC_FILE_SUFFIX</div><div class="line">  KAFKA_GC_LOG_OPTS=&quot;-Xloggc:$LOG_DIR/$GC_LOG_FILE_NAME -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps &quot;</div><div class="line">fi</div><div class="line"></div><div class="line"># 启动Java进程，将上面的所有信息整合在一起，使用指定的Java，还有各种参数，这里区分了运行模式，其实就是将进程作为后台进程运行还是前台进程运行而已</div><div class="line"># Launch mode</div><div class="line">if [ &quot;x$DAEMON_MODE&quot; = &quot;xtrue&quot; ]; then</div><div class="line">  nohup $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS &quot;$@&quot; &gt; &quot;$CONSOLE_OUTPUT_FILE&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</div><div class="line">else</div><div class="line">  exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS &quot;$@&quot;</div><div class="line">fi</div></pre></td></tr></table></figure></p>
<h1 id="kafka-topics-sh"><a href="#kafka-topics-sh" class="headerlink" title="kafka-topics.sh"></a>kafka-topics.sh</h1><p>kafka-topics.sh是用来操作Kafka的Topic的脚本，其内部通过kafka-run-class.sh脚本来调用kafka.admin.TopicCommand来实现Topic的操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">exec $(dirname $0)/kafka-run-class.sh kafka.admin.TopicCommand $@</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/03/08/redis-lua/" itemprop="url">
                  redis_lua
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-08T10:32:34+08:00" content="2017-03-08">
              2017-03-08
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/02/23/shell-study/" itemprop="url">
                  Shell Study
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-23T22:31:10+08:00" content="2017-02-23">
              2017-02-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/unix/" itemprop="url" rel="index">
                    <span itemprop="name">unix</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <hr>
<p>本文记录一些自己在使用shell进行批量操作、任务调度等工作时用到的一些shell的基础知识，在此记录以备翻阅和查找。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2017/02/23/shell-study/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/02/08/java-execute-command/" itemprop="url">
                  Java execute command
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-08T11:27:12+08:00" content="2017-02-08">
              2017-02-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Java/" itemprop="url" rel="index">
                    <span itemprop="name">Java</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>在Java的使用过程中，难免需要去执行linux命令（执行shell也是linux命令），那么应该如何做呢？本文将进行一些演示。</p>
<h1 id="所依赖的相关类"><a href="#所依赖的相关类" class="headerlink" title="所依赖的相关类"></a>所依赖的相关类</h1><p>要在Java中执行linux命令有两种方式，依赖于三个类。我们先介绍这三个类，然后在使用这三个类，组合两种方案来进行说明。</p>
<h2 id="java-lang-Process"><a href="#java-lang-Process" class="headerlink" title="java.lang.Process"></a>java.lang.Process</h2><h3 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h3><p>ProcessBuilder.start()和Runtime.exec方法创建一个本地进程，并返回一个Process子类的实例，该实例用来控制进程并获得相关信息。Process类提供了执行<br>当Process对象没有更多的引用时，不是删除子进程，而是继续异步执行子进程。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2017/02/08/java-execute-command/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/02/04/python-datetime/" itemprop="url">
                  Python Datetime
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-04T18:38:47+08:00" content="2017-02-04">
              2017-02-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>在使用python写调度任务的时候，离不开的必然有日期和时间的处理；最常见的有根据字符串生成时间、将时间生成指定格式的字符串、日期时间的计算（加减）等等。在python中对日期时间进行操作的包为datetime。下面就对该包的一些常用操作和对应的参数进行介绍。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2017/02/04/python-datetime/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/02/04/python-subprocess/" itemprop="url">
                  Python Subprocess
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-04T18:38:47+08:00" content="2017-02-04">
              2017-02-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在平时python的使用过程中，难免会遇到调用服务器命令的时候。直接调用普通的命令基本上都没有什么问题，令人比较麻烦的是带有控制台的命令，例如python、beeline、spark-shell。虽然向python、spark都有相关的脚本文件或者jar来避免直接使用控制台命令的调用，然后有些时候还是不免会用到控制台的方式，那么对于带有控制台的命令行应该如何实现呢？本文将使用subprocess，并以beeline为背景来实现使用python执行带有控制台的命令行命令。<br>首先看看参考代码，代码是以执行Hive的beeline命令行为例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">beeline</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"# 1 建立连接"</span></div><div class="line">        self.p = subprocess.Popen([<span class="string">'apache-hive-0.14.0-bin/bin/beeline'</span>], stdin=subprocess.PIPE,</div><div class="line">                             stdout=subprocess.PIPE)</div><div class="line">        <span class="keyword">print</span> &gt;&gt; self.p.stdin, <span class="string">'!connect jdbc:hive2://hdfs001:2181,hdfs002:2181,hdfs003:2181,hdfs004:2181,hdfs005:2181/;serviceDiscoveryMode=zookeeper userName password\n'</span></div><div class="line">        self.p.stdin.flush()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">submit</span><span class="params">(self, hql)</span>:</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"# 2 输入命令"</span></div><div class="line">        <span class="keyword">print</span> &gt;&gt; self.p.stdin, hql</div><div class="line">        self.p.stdin.flush()</div><div class="line"></div><div class="line">        <span class="keyword">print</span> <span class="string">"# 3 等待关闭"</span></div><div class="line">        <span class="keyword">print</span> &gt;&gt; self.p.stdin, <span class="string">"!q"</span></div><div class="line">        self.p.wait()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hadoop_get</span><span class="params">(self, from_, to_)</span>:</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"# 4 下载数据"</span></div><div class="line">        (status, output) = commands.getstatusoutput(<span class="string">" "</span>.join((<span class="string">"hadoop-2.6.0/bin/hadoop fs -text"</span>, from_+<span class="string">'*'</span>, <span class="string">'&gt;'</span>, to_)))</div><div class="line">        <span class="keyword">print</span> status, output</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">queryDataByDate</span><span class="params">(start_date, end_date, local_path)</span>:</span></div><div class="line">    sql = <span class="string">"""</span></div><div class="line">    create table database.table_%s_%s</div><div class="line">       ROW FORMAT DELIMITED</div><div class="line">       FIELDS TERMINATED BY '-@-'</div><div class="line">       NULL DEFINED AS '...'</div><div class="line">    STORED AS TEXTFILE</div><div class="line">    AS</div><div class="line">    SELECT * FROM DB.TABLE_NAME;</div><div class="line">"""</div><div class="line">    b = beeline()</div><div class="line">    s = sql % (start_date, end_date, start_date, end_date)</div><div class="line">    b.submit((sql % (start_date, end_date, start_date, end_date)))</div><div class="line"></div><div class="line">    fileName = <span class="string">'feed_%s_%s'</span> % (start_date, end_date)</div><div class="line">    b.hadoop_get((<span class="string">"HDFS_PATH/%s/"</span> % (fileName)), (<span class="string">"LOCAL_PATH/%s"</span> % fileName))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">if</span> len(sys.argv) &lt; <span class="number">2</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">"请输入要获取feed的开始日期和结束日志，如：20160105"</span></div><div class="line">        exit(<span class="number">0</span>)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"正在执行%s文件，来查询%s-%s之间的数据:"</span> % (sys.argv[<span class="number">0</span>], sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>])</div><div class="line">    queryDataByDate(sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>], <span class="string">"/data/"</span>)</div></pre></td></tr></table></figure></p>
<p>该代码块的主要流程是，在初始化beeline对象时调用beeline命令，并进行连接（<strong>init</strong>方法中实现了全部的操作）;然后是提交需要beeline执行的sql（submit方法中实现）;最后是将sql执行的结果从HDFS中取到本地（hadoop_get方法中实现）。queryDataByData方法就是对beeline类中各个方法的一个集成调用。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2017/01/13/doubleArray-trie/" itemprop="url">
                  Double-Array trie
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-01-13T16:01:54+08:00" content="2017-01-13">
              2017-01-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/数据结构/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文主要用来学习Double-Array trie的相关知识。</p>
<p><a href="https://github.com/digitalstain/DoubleArrayTrie" title="Double-Array trie" target="_blank" rel="external">源码的github地址</a></p>
<p>Double-Array trie是Trie结构的压缩形式，仅用两个数组来表示Trie，这个结构有效的结合数字搜索树(Digital Search Tree)检索时间高效的特点和链式表示的Trie空间结构紧凑的特点。双数组Trie的本质是一个确定有限状态自动机(DFA)，每个节点代表自动机的一个状态，根据不同的变量，进行状态转移，当到达结束状态或无法转移时，完成一次查询操作。在双数组所有键中，包含的字符之间的联系都是通过简单的数学加法运算表示的，不仅提高了检索速度，而且省去了链式结构中使用的大量指针，节省了存储空间。</p>
<p>在了解Double-Array trie之前，我们先了解一下“确定有限状态自动机”。在数学理论中，确定有限状态自动机或确定有限自动机（deterministic finite automation, DFA）是一个能实现状态转移的自动机。对于一个给定的属于该自动机的状态和一个属于该自动机字母表的字符，它能够根据实现给定的函数转移到下一个状态。简单的说，就是当前状态根据一个公式和状态的确定值，能够到达另外一个状态，而且要到达的状态是确定的。如图：<br><a href="&quot;确定有限自动机&quot;">确定有限自动状态机</a><br>图中的每个字代表一个状态，并且每个状态都有一个固定的变量。</p>
<p>在了解了确定优先状态自动机之后，我们来了解一下Double-Array trie。Double-Array trie的核心是使用两个整型数组base和check来分别存储状态以及前驱状态。说的简单一些，base用来存储状态，check用来验证。在状态的转移过程中，有如下公式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">check[t]=s</div><div class="line">base[s]+c=t <span class="comment">//其中t和s是数组下标</span></div></pre></td></tr></table></figure></p>
<p>上面的公式表示 base[s]的值 + 状态的变量 = t下标，check[t]的值 = s下标。</p>
<p>举例来说明：</p>
<p>在学习Douoble-Array trie和看DoubleArrayTrie源码的时候，参考了以下文章，在此表示感谢：<br><a href="http://www.hankcs.com/program/java/%E5%8F%8C%E6%95%B0%E7%BB%84trie%E6%A0%91doublearraytriejava%E5%AE%9E%E7%8E%B0.html" title="双数组Trie树(DoubleArrayTrie)Java实现" target="_blank" rel="external">双数组Trie树(DoubleArrayTrie)Java实现</a><br><a href="http://www.cnblogs.com/zhangchaoyang/articles/4508266.html" title="Double Array Trie" target="_blank" rel="external">Double Array Trie</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/12/30/JPinYin/" itemprop="url">
                  JPinYin
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-30T16:28:15+08:00" content="2016-12-30">
              2016-12-30
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文主要介绍JPinYin的使用和配置，<a href="https://github.com/stuxuhai/jpinyin" title="Jpinyin">github的地址</a>。</p>
<h1 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h1><p>Jpinyin是一个开源的用于将汉字转换为拼音的java库。</p>
<h2 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h2><p>1、准确、完善的字库：Unicode编码从4E00-9FA5范围及3007(〇)的20903个汉字中，除了46个异体字（不存在标准拼音）Jpinyin都能转换。<br>2、拼音转换速度快：经测试，转换Unicode编码范围的20902个汉字，Jpinyin耗时约为100毫秒。<br>3、支持多种拼音格式：Jpinyin支持多种拼音输出格式：带声调、不带声调、数字表示声调以及拼音首字母格式输出。<br>4、常见多音字识别：Jpinyin支持常见多音字的识别，其中包括词组、成语、地名等；<br>5、简繁体中文互转。<br>6、支持用户自定义字典。</p>
<h2 id="Maven依赖"><a href="#Maven依赖" class="headerlink" title="Maven依赖"></a>Maven依赖</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;com.github.stuxuhai&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;jpinyin&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.1.8&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">String str = <span class="string">"你好世界"</span>;</div><div class="line">PinyinHelper.convertToPinyinString(str, <span class="string">","</span>, PinyinFormat.WITH_TONE_MARK); <span class="comment">// nǐ,hǎo,shì,jiè</span></div><div class="line">PinyinHelper.convertToPinyinString(str, <span class="string">","</span>, PinyinFormat.WITH_TONE_NUMBER); <span class="comment">// ni3,hao3,shi4,jie4</span></div><div class="line">PinyinHelper.convertToPinyinString(str, <span class="string">","</span>, PinyinFormat.WITHOUT_TONE); <span class="comment">// ni,hao,shi,jie</span></div><div class="line">PinyinHelper.getShortPinyin(str); <span class="comment">// nhsj</span></div><div class="line">PinyinHelper.addPinyinDict(<span class="string">"user.dict"</span>);  <span class="comment">// 添加用户自定义字典</span></div></pre></td></tr></table></figure>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/12/30/JPinYin/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/12/19/scikitImage-ACrashCourseOnNumPyForImages/" itemprop="url">
                  scikit image - a crash course on NumPy for images
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-19T12:43:26+08:00" content="2016-12-19">
              2016-12-19
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/图像处理/" itemprop="url" rel="index">
                    <span itemprop="name">图像处理</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文用来学习scikit-image的官方文档的<a href="http://scikit-image.org/docs/stable/user_guide/numpy_images.html" title="a crash course on NumPy for images">a crash course on NumPy for images</a>，<a href="http://scikit-image.org/docs/stable/user_guide/numpy_images.html" title="a crash course on NumPy for images">原链接</a></p>
<h1 id="A-crash-course-on-NumPy-for-images"><a href="#A-crash-course-on-NumPy-for-images" class="headerlink" title="A crash course on NumPy for images"></a>A crash course on NumPy for images</h1><p>scikit-image是以NumPy数组的方式来操作图像。因此图像很大一部分的操作将是使用NumPy：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> skimage <span class="keyword">import</span> data</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera = data.camera()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>type(camera)</div><div class="line">&lt;type <span class="string">'numpy.ndarray'</span>&gt;</div></pre></td></tr></table></figure></p>
<p>检索图像的几何以及像素数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera.shape</div><div class="line">(<span class="number">512</span>, <span class="number">512</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera.size</div><div class="line"><span class="number">262144</span></div></pre></td></tr></table></figure></p>
<p>检索关于灰度值的统计信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera.min(), camera.max()</div><div class="line">(<span class="number">0</span>, <span class="number">255</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera.mean()</div><div class="line"><span class="number">118.31400299072266</span></div></pre></td></tr></table></figure></p>
<p>代表图片的NumPy数组可以是浮点数类型的不同整数。查看<a href="http://scikit-image.org/docs/stable/user_guide/data_types.html#data-types" title="Image data type and what the mean">Image data type and what the mean</a>获取关于这些类型的更多信息，以及scikit-image如何处理它们。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/12/19/scikitImage-ACrashCourseOnNumPyForImages/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/12/16/scikitImage-gettingStarted/" itemprop="url">
                  scikit image - getting started
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-12-16T16:42:31+08:00" content="2016-12-16">
              2016-12-16
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/图像处理/" itemprop="url" rel="index">
                    <span itemprop="name">图像处理</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用来学习scikit-image的官方文档的入门手册，<a href="http://scikit-image.org/docs/stable/user_guide/getting_started.html" title="Getting started" target="_blank" rel="external">原链接</a></p>
<h1 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a>Getting started</h1><p>scikit-image是一个图像处理的Python包，它使用numpy数组来工作。这个包作为skimage被引入：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> skimage</div></pre></td></tr></table></figure></p>
<p>skimage的大多数函数将在子模块中找到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> skimage <span class="keyword">import</span> data</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera = data.camera()</div></pre></td></tr></table></figure></p>
<p>一个包含子模块和函数的web页面可以在<a href="http://scikit-image.org/docs/stable/api/api.html" title="API Reference" target="_blank" rel="external">API reference</a>中找到。<br>在scikit-image中，图片相当于一个NumPy数组，例如，一个2-D的数组表示了一个灰度的2-D图片<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>type(camera)</div><div class="line">&lt;type <span class="string">'numpy.ndarray'</span>&gt;</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># An image with 512 rows and 512 columns</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>camera.shape</div><div class="line">(<span class="number">512</span>, <span class="number">512</span>)</div></pre></td></tr></table></figure></p>
<p>skimage.data模块提供了一组返回示例图片的函数，这些图片可以用来快速学习scikit-image的函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>coins = data.coins()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> skimage <span class="keyword">import</span> filters</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>threshold_value = filters.threshold_otsu(coins)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>threshold_value</div><div class="line"><span class="number">107</span></div></pre></td></tr></table></figure></p>
<p>当然，还可以使用skimage.io.imread()从图片文件来加载自己的图片信息，加载后的图片也是作为一个NumPy数组：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> os</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>filename = os.path.join(skimage.data_dir, <span class="string">'moon.png'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> skimage <span class="keyword">import</span> io</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>moon = io.imread(filename)</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/11/10/log4j/" itemprop="url">
                  Log4j Architecture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-10T15:25:48+08:00" content="2016-11-10">
              2016-11-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Logging/" itemprop="url" rel="index">
                    <span itemprop="name">Logging</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文主要是针对Log4j的2.x版本的文档的，<a href="http://logging.apache.org/log4j/2.x/" title="Log4j">链接</a></p>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><h2 id="Main-Components"><a href="#Main-Components" class="headerlink" title="Main Components"></a>Main Components</h2><p>Log4j使用的类下面图表中展示。<br><img src="http://oaavtz33a.bkt.clouddn.com/Log4jClasses.jpg" alt="Log4j Classes" title="class Log4j Classes"><br>使用Log4j的applications讲需要使用一个特定的名称向LogManager请求一个Logger。LogManager会定位到适当的LoggerContext，然后从LoggerContext中获取Logger。如果Logger必须被创建，它将与包含了如下内容的LoggerConfig进行关联：1）与Logger相同名称的LoggerConfig；b）父级package的名称的LoggerConfig；3）根级LoggerConfig。LoggerConfig对象根据配置中Logger的声明进行创建。LoggerConfig与日志事件的实际输出源联系在一起。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/11/10/log4j/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/11/10/log4j-configuration/" itemprop="url">
                  Log4j Configuration
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-10T15:25:48+08:00" content="2016-11-10">
              2016-11-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Logging/" itemprop="url" rel="index">
                    <span itemprop="name">Logging</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文用来学习关于Log4j的配置（通过配置文件的方式），<a href="http://logging.apache.org/log4j/2.x/manual/configuration.html" title="Configuration">原文档连接</a></p>
<h1 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h1><p>将日志请求插入到application代码中需要相当多的计划和努力。观察表明，大约百分之四的代码用于记录日志。因此，即使是一般大小的application也将会有数以千计的日志片段嵌套在代码中。考虑到这个数量，如何不需要手动修改就能管理这些日志片段就显得十分重要。<br>配置Log4j 2版本，能够通过下面四种方法中的任意一种来完成：<br>1、通过一个以XML、JSON、YAML或properties格式的配置文件。<br>2、编程方式，通过创建一个ConfigurationFactory和Configuration实现。<br>3、编程方式，通过调用在Configuration接口中的APIs来添加组件到默认配置。<br>4、编程方式，通过调用内部Logger类的方法。<br>本文主要关注通过一个配置文件来配置Log4j。对于通过编程方式来配置Log4j，可以在<a href="http://logging.apache.org/log4j/2.x/manual/extending.html" title="Extending Log4j 2">Extending Log4j 2</a>和<a href="http://logging.apache.org/log4j/2.x/manual/customconfig.html" title="Programmatic Log4j Configuration">Programmatic Log4j Configuration</a>。<br>注意，不同于Log4j 1.x，Log4j 2的公共API没有公开关于添加、修改和移除appenders和filter的方法，或者以任何方式来操作配置。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/11/10/log4j-configuration/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/09/28/kafka-document/" itemprop="url">
                  Apache Kafka
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-28T15:46:13+08:00" content="2016-09-28">
              2016-09-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文是Kafka 0.10.0文档的翻译，主要用于自学。</p>
<h1 id="1-Getting-Started"><a href="#1-Getting-Started" class="headerlink" title="1 Getting Started"></a>1 Getting Started</h1><h2 id="1-1-Introduction"><a href="#1-1-Introduction" class="headerlink" title="1.1 Introduction"></a>1.1 Introduction</h2><p>Kafka是一个分布式的、分区的、备份的提交日志服务。它提供了一个消息传输系统的功能，但是使用了一个独特的设计。<br>那意味着什么？<br>首先我们浏览一下基本的消息队列术语：</p>
<ul>
<li>Kafka以一种类型持续messages的提供称为topics。</li>
<li>我们称那些publish message到一个Kafka topic的进程为producers。</li>
<li>我们称那些subscribe到topics并处理被publish的message的进程为consumers。</li>
<li>kafka作为一个集群而运行，集群由一个或多个server组成，每个server成为一个broker。</li>
</ul>
<p>因此，整体来看，producers通过网络发送messages到Kafka集群，同样Kafka又为consumers服务，像这样：<br><img src="http://oaavtz33a.bkt.clouddn.com/producer_consumer.png" alt="producer_consumer" title="producer and consumer"><br>clients和servers之间的通信是通过一个简单的、高性能的、跨语言的TCP协议完成的。我们为Kafka提供了一个Java client，但是clients在很多语言中都可用。</p>
<h3 id="Topics-and-Logs"><a href="#Topics-and-Logs" class="headerlink" title="Topics and Logs"></a>Topics and Logs</h3><p>首先我们学习由Kafka提供的高级别的抽象 - topic。<br>一个topic是一种或一个提供的名称，用来publish message。对于每个topic，Kafka集群维持着一个分区日志，看起来像这样：<br><img src="http://oaavtz33a.bkt.clouddn.com/log_anatomy.png" alt="Anatomy of a Topic" title="Anatomy of a Topic"><br>每个partition是一个顺序的、不可变的连续添加的消息队列。partitions中的每个message分配一个序列id号，称为offset，用来唯一标识partition中的每条message。<br>Kafka集群保存所有publish过来的message-不管它们是否被消费，保存时长可配置。例如，如果日志保存设置为两天，那么一个message在publish后两天内是可以被消费的，但是两天之后，它将被删除以释放空间。kafka的性能对于不同数据大小是恒定有效的，因此很多的数据不是个问题。<br>实际上每个consumer仅有被保存的元数据是consumer在日志中的位置，称为offset。这个offset由consumer控制：通常一个consumer按照它读取的message，线性的推进它的offset，但是这个位置由consumer控制并且consumer能够以任意顺序消费message。例如一个consumer可以重置到一个原来的offset来重新处理。<br>这个特征的组合意味着Kafka consumer是非常廉价的 - 它们能够自由的来去，而不会影响集群或其他consumer。例如，你可以使用我们的命令行工具来tail任何topic的内容，而不需要任何已经存在的consumers改变它所消费的内容。<br>日志中的partitions有几个用途。首先，它们允许日志扩展到单个server所能容纳的日志大小之外。一个partition必须位于它所属的server上，但是一个topic可能有很多的partitions，因此它能够持有任意数量的数据。其次，它们的行为类似一个并行单元 - 汇聚更多于一点。</p>
<h3 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h3><p>日志的partitions在Kafka集群中跨server分布，每个server为一个共享的partition处理数据和请求。每个partition为了容灾，跨server保存多个备份，备份的数量可以配置。<br>每个partition有一个server扮演”leader”的角色，并有零个或多个servers扮演”followers”的角色。leader为partition处理所有的读和写的请求，而follower只是被动的复制leader。如果leader失效了，follower中的一个将自动成为新的leader。每个server为它自己一些的partitions扮演一个leader角色，为其他的partition扮演一个follower的角色，因此每个server在集群中的负载是很均衡的。</p>
<h3 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h3><p>Producers将数据publish到它们选择的topics中。Producer负责哪些message被分配到topic的哪些partition中。这可以通过简单的轮转来完成以平衡负载，或者可以一致性的partition定义函数来完成（例如基于message的某些key）。在分区上用的更多的是第二种。</p>
<h3 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h3><p>传统的消息传输有两种模式：queuing和publish-subscribe。在队列方式中，一个consumers池从一个server中读取，每条message只会到达某个consumer；在发布-订阅方式中，message广播给所有的consumers。Kafka提供了单个consumer抽象，它概括了上面两种方式 - consumer group。<br>consumers使用一个consumer群名称来标识它们自己，每个publish到一个topic的message被传递到每个订阅了topic的consumer组的一个consumer实例。consumer实例能够在单独的进程或单独的机器上。<br>如果所有的consumer实例拥有相同的consumer组，那么工作方式与一个传统的跨consumers负载均衡的队列类似。<br>如果所有的consumer实例都有不同的consumer组，那么工作方式与发布-订阅类似，所有的message会广播给所有的consumer。<br>更常见的，尽管我们发现那些topics有少数量的consumer组，然而每个都是一个逻辑订阅者。每个组由多个consumer实例组成，这样具有扩展性和容灾性。这也是publish-subscrib的定义，只不过subscriber是一个consumer群，而不是单个进程。<br>相对于传统消息传输系统，Kafka有更强的顺序保证。<br><img src="http://oaavtz33a.bkt.clouddn.com/consumer-groups.png" alt="consumer-groups" title="一个有两个server组成的Kafka集群有四个partitions(P0-P3)和两个consumer组。consumer组A有两个consumer实例，而组B有四个实例"><br>一个传统队列在server上按顺序保存messages，如果多个consumer从队列中消费数据，那么server以message存储的顺序拿出message。然而，虽然server按照顺序拿出message，但是message以异步方式投递给consumers，因此它们可能在不同的consumer上以不同的顺序到达。这意味着在并行消费的情况中消息的顺序丢失了。消息传输系统通过一个”exclusive consumer”的概念来解决这个问题，它只允许一个进程从队列中消费，但是这意味着没有并行处理。<br>Kafka做的更好一些。通过一个并行概念-partition-在topics中，Kafka能够在一个consumer进程池上同时提供顺序保证和负载均衡。这是通过将topic中的partitions分配给consumer组中的consumers来完成的，因此每个partition有组中确切的一个consumer来消费。通过这样，我们确保consumer值读取那一个partition，并以顺序消费数据。因为有很多partitions在很多consumer实例上是均衡负载的。注意，一个consumer组中的consumer实例不能多余partitions的数量。<br>Kafka只是在一个partition中提供了一个整体的顺序，而不是在一个topic的不同partition之间。对于大多applications，每个分区的排序联合根据key划分数据的能力是充分的。如果你要求在message上有整体的顺序，这可以通过使用一个topic只有一个partition来完成，这也意味着每个consuemr组只有一个consumer进程。</p>
<h3 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h3><p>在高层次上，Kafka给了如下的保证：</p>
<ul>
<li>由一个producer发送到一个特定topic partition的Messages将会以它们被发送的顺序添加。那就是，如果一个message M1与发送message M2的producer是一个，并且M1先被发送，那么M1将有一个比M2小的offset，并且要比M2更早的添加到日志中。</li>
<li>一个consumer看到messages的顺序是messages存储的顺序。</li>
<li>对于使用了复制因子为N的topic，在不丢失任何提交到log的messages丢失，我们允许最多N-1个server故障。</li>
</ul>
<p>这些保证的更多细节在文档的design章节中给出。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/09/28/kafka-document/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/09/21/flume-install/" itemprop="url">
                  Flume Install
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-21T21:01:12+08:00" content="2016-09-21">
              2016-09-21
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Flume/" itemprop="url" rel="index">
                    <span itemprop="name">Flume</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文主要介绍自己在生产中使用flume的实际配置，以便以后查询。如果能够为他人提供参考，荣幸之至。<br>在Flume中分为三个部分source、channel和sink。source主要用于接收数据，sink用于写出数据，channel作为source和sink的连接、保存和转发使用。其中非常好用的是，channel可以使用Kafka，从而使得Flume具有了超强的存储能力，如果在加上可靠的source和sink，完全可以保证数据零丢失。<br>本文使用的例子中采用的是内存channel，这种channel的缺点是存储长度有限，重启数据丢失，有点就是速度快，低延迟。至于source，使用的是avro。最后是sink，因为我得目的是将数据写入到HDFS中，以后Hadoop集群或Spark集群进行计算，因此使用的hdfs类型的sink。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/09/21/flume-install/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2016/09/18/ganglia-installAndConfig/" itemprop="url">
                  Ganglia Install And Config
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-18T17:30:07+08:00" content="2016-09-18">
              2016-09-18
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/ganglia/" itemprop="url" rel="index">
                    <span itemprop="name">ganglia</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文是ganglia的安装和配置的笔记</p>
<h1 id="Ganglia的安装"><a href="#Ganglia的安装" class="headerlink" title="Ganglia的安装"></a>Ganglia的安装</h1><p>首先，ganglia由gmond、gmetad和gweb三部分组成。</p>
<h2 id="gmond"><a href="#gmond" class="headerlink" title="gmond"></a>gmond</h2><p>gmond（Ganglia Monitoring Daemon）是一种轻量级服务，安装在每台需要手机指标数据的节点主机上。它通过侦听/通告协议与集群内其他节点共享数据。<br>gmond的安装很简单，其所依赖的库，libconfuse、pkgconfig、PCRE和APR等在大多数现行的linux上都有安装。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install ganglia-gmond</div></pre></td></tr></table></figure></p>
<h2 id="gmetad"><a href="#gmetad" class="headerlink" title="gmetad"></a>gmetad</h2><p>gmetad （Ganglia Meta Daemon）是一种从其他gmetad或gmond源收集指标数据，并将数据以RRD格式存储到磁盘的服务。gmetad为从主机组收集的特定指标信息提供了简单的查询机制，并支持分级授权，使得创建联合检测域成为可能。<br>gmetad除了需要安装gmond所需的依赖之外，还需要RDDtool库。它用来存储和显示从其他gmetad和gmond源收集的时间序列数据。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo yum install ganglia-gmetad</div></pre></td></tr></table></figure></p>
<h2 id="gweb"><a href="#gweb" class="headerlink" title="gweb"></a>gweb</h2><p>完整的Ganglia不能缺少网络接口：gweb（Ganglia Web）。gweb是一种利用浏览器显示gmetad所存储数据的PHP前端。<br>Ganglia 3.4的Web接口是一个独立的发布包，其源代码也是独立的。gweb 3.4支持gmond/gmetad 3.4.x及以上版本；gweb未来版本可能需要与gmond/gmetad未来版本相匹配。建议安装或更新gweb的时候查看安装文档，以获取更多信息。<br>安装gweb需要如下需求：</p>
<ul>
<li>Apache Web Server</li>
<li>PHP 5.2级更新版本</li>
<li>PHP JSON扩展的安装和启用</li>
</ul>
<p>首先安装Apache和PHP<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install httpd php</div></pre></td></tr></table></figure></p>
<p>用户还需要启用PHP的JSON扩展，通过检查/etc/php.d/json.ini文件来检查JSON的扩展状态，如果已经启用扩展，文件中应该包含下面的语句：<br><figure class="highlight php"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">extension=json.ini</div></pre></td></tr></table></figure></p>
<p>下载最新的gweb(<a href="https://sourceforge.net/projects/ganglia/files/gweb/)，然后编译Makefile来安装gweb2">https://sourceforge.net/projects/ganglia/files/gweb/)，然后编译Makefile来安装gweb2</a>:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -xvzf ganglia-web-major.minor.release.tar.gz</div><div class="line"><span class="built_in">cd</span> ganglia-web-major.minor.release</div></pre></td></tr></table></figure></p>
          <div class="post-more-link text-center">
            <a class="btn" href="/blog/2016/09/18/ganglia-installAndConfig/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/blog/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/blog/">1</a><span class="page-number current">2</span><a class="page-number" href="/blog/page/3/">3</a><a class="extend next" rel="next" href="/blog/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/blog/uploads/avatar.png"
               alt="baimoon" />
          <p class="site-author-name" itemprop="name">baimoon</p>
          <p class="site-description motion-element" itemprop="description">Baimoon's blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/blog/archives">
              <span class="site-state-item-count">52</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/blog/categories">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/blog/tags">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/baimoon" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://gallery.xrange.org" title="xrange" target="_blank">xrange</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016-07 - 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">baimoon</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/blog/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/blog/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/blog/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
