<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/blog/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/blog/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/blog/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico?v=5.0.1" />






<meta name="description" content="Baimoon&apos;s blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Baimoon's Note">
<meta property="og:url" content="http://baimoon.github.io/index.html">
<meta property="og:site_name" content="Baimoon's Note">
<meta property="og:description" content="Baimoon&apos;s blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Baimoon's Note">
<meta name="twitter:description" content="Baimoon&apos;s blog">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://baimoon.github.io/"/>

  <title> Baimoon's Note </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/blog/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Baimoon's Note</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/05/05/yarn-learn/" itemprop="url">
                  yarn-learn
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-05-05T21:39:19+08:00" content="2019-05-05">
              2019-05-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用来记录自己读书的一些笔记</p>
<h1 id="YARN-组件的功能概述"><a href="#YARN-组件的功能概述" class="headerlink" title="YARN 组件的功能概述"></a>YARN 组件的功能概述</h1><p>YARN集群主要分为三个部分：ResourceManager、NodeManager和ApplicationMaster。其中ResourceManager的重要组成部分为调度器和ApplicationMaster。</p>
<p>ResourceManager作为独立的进程运行在专有的机器上，负责集群中所有应用程序的资源分配。它可以为用户提供公平的、基于容量的、本地化的资源调度。在Yarn资源的分配单位为Container，它是一组内存和cpu核数的组合（目前只有内存和cpu）。RsoueceManager和运行在每个节点上的NodeManager会进行交互以便执行和跟踪资源的分配。基于可扩展性需求，ResourceManager和NodeManager之间通过心跳进行通信。NodeManager负责本地可用资源的监控，故障报告以及Container生命周期的管理（启动或终止任务）。<br>用户将Application提交给ResourceManager，被ResourceManager接受的Applcation会被传递给Scheduler并允许其运行。一旦Scheduler有足够的资源可以满足需求，Application的状态就会从Accepted转为Running。ResourceManager会为ApplicationMaster分配一个Container，ApplicationMaster通常被称为“Container0”.<br>ApplicationMaster是每个用户作业的主进程，负责管理作业的生命周期，包括动态的增加或减少Container，管理执行流程，处理故障和计算偏差，以及执行其他的本地优化。<br>ApplicationMaster可以运行以任何编程语言实现的用户程序。通常，ApplicationMaster需要利用多台服务器的处理能力来完成一个作业，因此ApplicationMaster会向ResourceManager进行资源请求。这些资源会包含本地化优势和Container的容量（内存和cpu）。ResourceManager根据可用资源和调度策略来为每个Application分配资源。当一个Container被分配给一个ApplicationMaster时，ResourceManager为该资源生成一个租约，ApplicationMaster通过心跳会得到该租约。基于令牌的机制，保证了ApplicationMaster在NodeManager上使用Container的可靠性。Container在运行过程中，会通过特定协议与ApplicationMaster通信，来报告状态和健康信息，以及接受框架的特定指令（杀掉任务等）。通过这种方式，Yarn提供了对Container的监控和生命周期管理的基础框架，而应用程序特定语义由每个框架独立管理。</p>
<h2 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h2><p>ResourceManager是集群所有资源的仲裁者。它的主要职责就是调度，即在竞争的应用程序之间分配系统中的可用资源，但是它不关心每个应用程序的状态。调度器只处理应用程序的整体资源分配，不关心局部优化和内部流程。ResouceManager不负责的职能，它没有跟踪应用程序的执行流程，没有任务容错能力。</p>
<h2 id="Yarn调度器"><a href="#Yarn调度器" class="headerlink" title="Yarn调度器"></a>Yarn调度器</h2><p>Yarn有一个可插拔的调度器组件，根据不同的使用场景和用户需求，管理员可以选择不同的调度策略，目前支持FIFO、Capacity和Fair。具体使用哪种调度器可以在yarn-default.xml中设置。</p>
<h3 id="FIFO"><a href="#FIFO" class="headerlink" title="FIFO"></a>FIFO</h3><p>先进先出调度器，它不考虑作业的优先级和范围。FIFO比较适合低负载集群，当使用大型共享集群时，它的功能不佳。</p>
<h3 id="Capacity"><a href="#Capacity" class="headerlink" title="Capacity"></a>Capacity</h3><p>Capacity调度器允许多个组安全的共享一个大规模Hadoop集群。要使用Capacity调度器，管理员使用总槽位容量的预定值配置一个或多个队列。这种分配保证了每个队列的最小使用量。管理员为每个队列的可用资源容量配置软限制和可选的硬限制。每个队列有严格的ACL，用来控制那些用户可以向那些队列提交作业。同时也有措施来保证无法查看或修改其他用户的应用程序。<br>Capacity调度器允许共享集群，同时给每个用户或组一定的最小容量保证。这些最小值在不需要时可以放弃，超出的容量将会给予那些最饥饿的队列，饥饿程度用运行中或已用的队列容量来衡量。<br>队列的定义和属性可以由管理员以安全的方式，在运行期间修改，以尽量减少对用户的干扰。管理员可以在运行期间添加额外的队列。管理不能在运行期间删除已有队列，但是可以在运行期间停止队列，以确保现有application运行完毕后不会再有新的应用程序被提交。<br>当工作负载可预见的情况下，Capacity调度器效果最好，有助于分配最小容量。在每个队列内部，使用层次化的FIFO来调度多个Application，类似于在独立的FIFO调度器中使用的方式。</p>
<h3 id="Fair调度器"><a href="#Fair调度器" class="headerlink" title="Fair调度器"></a>Fair调度器</h3><p>Fair调度器是将资源公平分配给应用的方法，使得所有应用在平均情况下随着时间得到相等的份额。<br>在Fair调度模型中，每个Application都属于某一个队列。Yarn Container的分配是选择使用了最少资源的队列，在这个队列中，再选择使用最少资源的应用程序。默认情况下，所有的用户共享一个名为“default”的队列。应用程序可以在提交时指定想要添加的队列。另外，也可以将Fair调度器配置成根据请求中包含的用户名来分配队列。Fair调度器还支持许多功能，如队列的权重、最小份额、最大份额以及队列内FIFO策略，但基本原则就是尽可能平均共享资源。<br>Fair调度器也支持抢占的概念，从而可以从ApplicationMaster那里要回Container，并且根据配置和应用程序的设计，抢占和随后的资源分配可以是友好的或者强制的。<br>除了提供平均共享，Fair调度器还允许保证队列的最小份额，确保某些用户、组或者生产应用程序总能够得到足够的资源。当队列中有等待的Application时，它至少能够得到最小份额的资源。Fair调度器可以通过配置文件限制每个用户和每个对了中运行Application的数量。<br>Fair调度器允许Container请求一定量的内存资源。为了避免多个较小内存Application饿死一个较大内存应用，引入了“reserved Container”，如果由于内存不足，一个Applicaiton不能立即使用一个Container，可以将其保留给其他应用程序，这样，其他应用程序不能使用这个Container，直到它被释放。被保留的Container会等待其他本地Container被释放，然后使用这些额外的容量来完成这个作业。一个保留的Container只允许在一个节点上，并且一个节点只允许一个保留的Container。<br>Fair调度器也支持层次化队列，队列可以嵌套在其他队列中，每个队列将它的资源再以一种公平的调度方式分配给它的子队列。</p>
<h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><p>Container是单个节点上一组资源（内存、CPU等）的集合。单个NodeManager上可以有多个Container，Container由NodeManager监控，由ResourceManager调度。<br>每个Application都是从ApplicationMaster开始，而且这个ApplicationMaster本身也是一个Container（Container0）。启动后，ApplicationMaster会向ResourceManager请求更多的Container，在运行期间，可以动态的请求或释放Continer。</p>
<h2 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h2><p>NodeManager的职责包括：与ResourceManager保持通信、管理Container的生命周期、监控每个Container的资源使用、跟踪节点健康状态、管理日志和不同应用程序的附属服务。<br>NodeManager启动时会向ResourceManager进行注册，然后发送包含自身状态的心跳，并等待来自ResourceManager的指令。<br>Contianer使用一个Container启动上下文来描述，这个描述包含环境变量、在远程存储上的依赖、安全令牌、NodeManager服务的載荷以及创建进程的必要命令。在验证了Container租约之后，NodeManager为Container配置环境，包括根据资源限制初始化它的监控。NodeManager可以杀死由ResourceManager指定的Container，或者资源超出限制的Container。</p>
<h2 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a>ApplicationMaster</h2><p>ApplicationMaster是协调集群中应用程序执行的进程。每个Application都有自己独特的ApplicationMaster，负责与ResourceManager申请资源，并与NodeManager协同工作来执行和监控任务。<br>ApplicationMaster启动后，后周期性向ResourceManager发送心跳来报告自己的健康以及更新它资源需求。在建好需求模型后，ApplicationMaster在发送给ResourceManager的心跳中封装了它的偏好和限制。在随后的心跳应答中，ApplicationMaster会收到集群中特定节点上绑定了一定资源的container租约。根据Resourcemanager发来的租约，ApplicationMaster可以更新它的执行计划以适应资源的过剩或不足。Container可以在Application运行期间被申请或释放。</p>
<h2 id="YARN资源模型"><a href="#YARN资源模型" class="headerlink" title="YARN资源模型"></a>YARN资源模型</h2><p>YARN资源分配模型提供了更大的灵活性，解决了静态分配的低效率问题。每个Container都有一些非静态资源，这些资源目前支持内存和CPU，还可以支持带宽GPU等。</p>
<h3 id="客户端资源请求"><a href="#客户端资源请求" class="headerlink" title="客户端资源请求"></a>客户端资源请求</h3><p>Yarn应用程序是从客户端资源请求开始的。客户端先通知ResourceManager要提交一个Application，ResourceManager在应答中给出一个ApplicationID以及有助于客户端请求资源的集群容量信息。</p>
<h3 id="ApplicationMaster分配Container"><a href="#ApplicationMaster分配Container" class="headerlink" title="ApplicationMaster分配Container"></a>ApplicationMaster分配Container</h3><p>在得到ResourceManager的应答后，客户端使用“Application Submission Context”（包含ApplicationID、用户名、队列以及其他启动ApplicationMaster所需的信息）发送请求给ResourceManager，同时也会将“Container Launch Context”发送给ResourceManager。Container Launch Context中描述了资源需求（内存和CPU）、作业文件、安全令牌以及在节点上启动ApplicationMaster所需的其他信息。<br>ResourceManager收到“Application Submission Context”后，为ApplicationMaster调度一个可用的Container（Container0），然后启动ApplicationMaster，启动ApplicationMaster之后，ResourceManager会告诉ApplicationMaster当前的资源报告。<br>基于可用资源报告，ApplicationMaster会请求一定的Container。ResourceManager根据资源调度策略，尽可能最优（如本地优势）的分配Container，并作为资源请求的应答发送给ApplicationMaster。<br>在作业的执行过程中，ApplicationMaster会向ResourceManager发送心跳信息。ApplicationMaster还可以将申请和释放Container的信息包含在心跳中。当作业结束时会向RsourceManager发送完成信息并退出。</p>
<h3 id="ApplicationMaster与Container管理器的通信"><a href="#ApplicationMaster与Container管理器的通信" class="headerlink" title="ApplicationMaster与Container管理器的通信"></a>ApplicationMaster与Container管理器的通信</h3><p>在这个阶段，ResourceManager已经将启动NodeManager的控制权交给了ApplicationMaster。ApplicationMaster将单独联系NodeManager并提供Container Launch Context（包含依赖文件、安全令牌以及启动进程所需的命令）。启动Container时，所有数据文件、可执行文件以及必要的依赖文件都会拷贝到节点的本地存储上，依赖文件可以被相同节点上相同Application的Container共享。<br>一旦启动Container，ApplicationMaster会检查它们的状态，ResourceManager不参与Application的执行，只处理调度以及监控其他资源。Container可以被ResourceManager给Kill掉，当Container被Kill掉之后，NodeManager会清理它的本地工作目录。如果是Applicaiton完成，ResourceManager会通知NodeManager聚合日志病清理Container专用的文件。</p>
<h2 id="管理Application的依赖文件"><a href="#管理Application的依赖文件" class="headerlink" title="管理Application的依赖文件"></a>管理Application的依赖文件</h2><p>当启动一个Container时，ApplicationMaster可以指定该Container所需文件，因此，这些文件会被本地化处理，而Yarn负责本地化处理的所有操作。</p>
<h3 id="LocalResource的定义"><a href="#LocalResource的定义" class="headerlink" title="LocalResource的定义"></a>LocalResource的定义</h3><p>这部分包含两个操作</p>
<blockquote>
<p>Localization：拷贝/下载远程资源到本地文件系统的过程。<br>LocalResource：LocalResource代表运行Container所需的本地资源。NodeManager负责在启动Container之前将这些资源本地化。<br>LocalCache：NodeManager维护和管理所有已下载文件的几种本地缓存，这些资源基于最初拷贝该文件时使用的远程URL作为唯一标识。</p>
</blockquote>
<p>对于每种资源，应用程序都可以指定下面的信息：</p>
<blockquote>
<p>URL：待下载的LocalResource的远程地址。<br>Size：LocalResource的大小，以byte为单位。<br>Creation timestamp：资源在远程文件系统上创建的时间。<br>LocalResourceType：NodeManager本地化的资源类型，包括FILE、ARCHIVE和PATTERN。<br>Patten：用于从存档文件中提取条目的样式（只对PATTERN类型适用）。<br>LocalResourceVisibility：指定NodeManager本地化资源的可见性，包括：PUBLIC、PRIVATE和APPLICATION。</p>
</blockquote>
<h3 id="LocalResource时间戳"><a href="#LocalResource时间戳" class="headerlink" title="LocalResource时间戳"></a>LocalResource时间戳</h3><p>NodeManager在下载资源文件之前，会检查这些文件有没有被修改过，这个检查可以确保LocalResource的一致性–应用程序在整个运行期间使用相同的文件内容。<br>一旦文件从远程位置拷贝到NodeManager的本地磁盘，它失去了除了URL之外所有与原始文件的联系，不再对远程文件的修改进行跟踪。为了避免不一致的问题，Yarn会让依赖于被修改的远程文件的Container失败。<br>ApplicationMaster在一个节点上启动Container时，会向NodeManager指定资源的时间戳。</p>
<h3 id="LocalResource类型"><a href="#LocalResource类型" class="headerlink" title="LocalResource类型"></a>LocalResource类型</h3><blockquote>
<p>FILE：一个普通文件，文本或二进制文件。<br>ARCHIVE：压缩文件，会被NodeManager自动解压缩。目前可以识别jar、tar、tar.gz以及zip。<br>PATTERN：ARCHIVE和FILE类型的组合。目前只有JAR文件支持PATTERN类型。</p>
</blockquote>
<h3 id="LocalResource的可见性"><a href="#LocalResource的可见性" class="headerlink" title="LocalResource的可见性"></a>LocalResource的可见性</h3><p>由LocalResource-Visibility指定，LocalResource有三种可见性：</p>
<h4 id="PUBLIC"><a href="#PUBLIC" class="headerlink" title="PUBLIC"></a>PUBLIC</h4><p>标记为PUBLIC的LocalResource可以被任何用户的Container访问。这些文件被拷贝到公共的LocalCache，之后本地上任何Container都可以直接从这个公共的LocalCache中读取文件，在LocalCache被清除之前，都不需要再次下载文件。</p>
<h4 id="PRIVATE"><a href="#PRIVATE" class="headerlink" title="PRIVATE"></a>PRIVATE</h4><p>使用PRIVATE标记的LocalResource可以被节点上同一用户的应用程序共享。这些LocalResource被复制到特定用户的私有缓存中。由同一个用户的不同应用程序的所有Container都可以访问这些文件。</p>
<h4 id="APPLICATION"><a href="#APPLICATION" class="headerlink" title="APPLICATION"></a>APPLICATION</h4><p>使用APPLICATION标记的资源可以被同一节点上相同Application的Container所共享。这些LocalResource被复制到应用程序专有的LocalCache。</p>
<h3 id="LocalResource的生命周期"><a href="#LocalResource的生命周期" class="headerlink" title="LocalResource的生命周期"></a>LocalResource的生命周期</h3><p>不同类型的LocalResource具有不同的生命周期：</p>
<blockquote>
<p>PUBLIC LocalResource 在Container或者应用程序结束时都不会被删除，但是在磁盘容量紧张时会删除。这个阈值可以通过yarn.nodemanager.localizer.cache.target-size-mb来指定。<br>PRIVATE LocalResource 与PUBLIC LocalResource的生命周期相同。<br>APPLICATION LocalResource会在应用程序结束后立即被删除。</p>
</blockquote>
<p>注意：APPLICATION LocalResource生命周期是以Application来界定，而不是ApplicationAttempt。</p>
<h1 id="Apache-Hadoop-YARN的管理"><a href="#Apache-Hadoop-YARN的管理" class="headerlink" title="Apache Hadoop YARN的管理"></a>Apache Hadoop YARN的管理</h1><h2 id="基本的Yarn管理"><a href="#基本的Yarn管理" class="headerlink" title="基本的Yarn管理"></a>基本的Yarn管理</h2><p>Yarn环境的基本配置文件如下：</p>
<blockquote>
<p>core-default.xml 系统范围的配置<br>hdfs-default.xml 分布式文件系统的配置<br>mapred-default.xml YARN的MapReduce框架配置<br>yarn-default.xml YARN的配置</p>
</blockquote>
<h3 id="YARN的管理工具"><a href="#YARN的管理工具" class="headerlink" title="YARN的管理工具"></a>YARN的管理工具</h3><p>Yarn有一些内置管理功能，通过yarn rmadmin -help 命令行命令可以查看具体的命令说明。</p>
<h3 id="增加或关闭YARN节点"><a href="#增加或关闭YARN节点" class="headerlink" title="增加或关闭YARN节点"></a>增加或关闭YARN节点</h3><p>有两个文件决定了哪些节点属于集群内，哪些节点数据不属于集群内：yarn.resourcemanager.nodes.include-path和yarn.resourcemanager.nodes.exclude-path。当这两个文件修改之后，可以通过下面的命令行命令来刷新ResourceManager，对节点进行容纳或踢出。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshNodes</div></pre></td></tr></table></figure></p>
<p>执行刷新命令需要管理员权限，管理员是通过ResourceManager上配置项 yarn.admin.acl 来指定的。</p>
<h3 id="Capacity调度器的配置"><a href="#Capacity调度器的配置" class="headerlink" title="Capacity调度器的配置"></a>Capacity调度器的配置</h3><p>调度器的详细配置会在稍后介绍，这里我们介绍重新配置和添加队列。<br>要重新配置或添加队列，可以使用前面提到的confidence-haddoop2.sh或者直接编辑$Hadoop_conf_dir/etc/hadoop/capacity-scheduler.xml来实现。修改后，执行如下命令行命令来进行刷新：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshQueues</div></pre></td></tr></table></figure></p>
<p>注意不能够删除队列，只能增加或重新配置队列。</p>
<h3 id="YRAN的Web代理"><a href="#YRAN的Web代理" class="headerlink" title="YRAN的Web代理"></a>YRAN的Web代理</h3><p>默认情况下，代理是作为ResourceManager的一部分运行的，但是也可以通过配置项 yarn.web-proxy.address 来使其独立运行。配置项默认为空，表示在ResourceManager运行。独立运行时，通过 yarn.web-proxy.principal 和 yarn.web-proxy.keytab 两个配置项可以控制使用 Kerberos 进行安全认证。</p>
<h3 id="使用-JobHistoryServer"><a href="#使用-JobHistoryServer" class="headerlink" title="使用 JobHistoryServer"></a>使用 JobHistoryServer</h3><p>。。。</p>
<h3 id="更新用户到用户组的映射关系"><a href="#更新用户到用户组的映射关系" class="headerlink" title="更新用户到用户组的映射关系"></a>更新用户到用户组的映射关系</h3><p>配置项 hadoop.security.group.mapping 决定了 ResourceManager 中使用的用户与用户组的映射关系的定义类。默认为org.apache.hadoop.security.ShellBasedUnixGroupsMapping，如果用户想要实现自己的类，需要实现org.apache.hadoop.security.GroupMappingServiceProvider接口。如果修改了映射关系，则需要使用下面的命令来更新ResourceManager：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshUserToGroupMapping</div></pre></td></tr></table></figure></p>
<h3 id="更新超级用户代理群映射关系"><a href="#更新超级用户代理群映射关系" class="headerlink" title="更新超级用户代理群映射关系"></a>更新超级用户代理群映射关系</h3><p>通过配置 hadoop.proxyuser.&lt; proxy-user-name &gt;.groups ，可以让用户$proxy-user-name 成为具有特殊权限的用户，它可以模拟配置值中的任意用户。配置项 hadoop.proxyuser.&lt; proxy-user-name &gt;.hosts 的配置值为逗号分隔的主机列表，只有配置在这里的这些主机，才可以使用前面的 $proxy-user-name 来模拟所配置的用户。如果修改这两个配置，则需要使用下面的命令行命令来更新ResourceManager：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshSuperUserGroupsConfiguration</div></pre></td></tr></table></figure></p>
<p>$proxy-user-name用户在模拟其他用户时，自己必须使用Kerberos认证。</p>
<h3 id="更新ResourceManager管理的ACL"><a href="#更新ResourceManager管理的ACL" class="headerlink" title="更新ResourceManager管理的ACL"></a>更新ResourceManager管理的ACL</h3><p>配置项 yarn.admin.acl 指定了谁是YRAN集群的管理员。管理员可以更新队列、管理节点列表、用户-群组映射、管理列表本身以及服务级别的ACL。还可以查看任何用户的Application、访问所有的Web界面、调用任何Web服务，以及杀掉任何队列中的Application。<br>这个配置项的值是一个用逗号分隔的用户列表和一个用逗号分隔的用户组列表，用户列表和用户组列表使用空格分隔，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user1,user2 group1,group2</div></pre></td></tr></table></figure></p>
<p>当这个配置项变更后，管理员需要使用下面的命令行命令来刷新ResourceManager<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshAdminAcls</div></pre></td></tr></table></figure></p>
<h3 id="重新加载服务级授权策略文件"><a href="#重新加载服务级授权策略文件" class="headerlink" title="重新加载服务级授权策略文件"></a>重新加载服务级授权策略文件</h3><p>管理员可以使用下面的命令行命令来重新加载授权策略文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn rmadmin -refreshServiceACL</div></pre></td></tr></table></figure></p>
<h3 id="管理YARN作业"><a href="#管理YARN作业" class="headerlink" title="管理YARN作业"></a>管理YARN作业</h3><p>Yarn的作业可以通过 yarn application 命令来管理。可以使用的子命令有：kill、list、status、appTypes和help。如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn application -list</div></pre></td></tr></table></figure></p>
<p>各个子命令的作用，通过名字我们也可以看出来。</p>
<h3 id="设置Container的内存"><a href="#设置Container的内存" class="headerlink" title="设置Container的内存"></a>设置Container的内存</h3><p>通过 yarn-site.xml 中的三个重要的配置，可以控制Container的内存：</p>
<blockquote>
<p>yarn.nodemanager.resource.memory-mb 指定了NodeManager可以给Container使用的内存总量（机器上可以用来给Container分配的最大内存）。<br>yarn.scheduler.minimum-allocation-mb 是ResourceManager允许分配给Container的最小内存。如果请求的Container的内存值小于这个值，则使用这个值，默认为1024MB。<br>yarn.scheduler.maximum-allocation-mb 是ResourceManager允许分配给Container的最大内存，默认为8192MB。</p>
</blockquote>
<h3 id="设置Container核数"><a href="#设置Container核数" class="headerlink" title="设置Container核数"></a>设置Container核数</h3><p>通过 yarn-site.xml中的配置，我们可以控制Container的核数：</p>
<blockquote>
<p>yarn.scheduler.minimum-allocation-vcores 指定了Container使用的最小core数。<br>yarn.scheduler.maximum-allocation-vcores 指定了Container使用的最大core数。<br>yarn.nodemanager.resource.cpu-vcores 指定了节点上可以用来给Container分配的总core数。</p>
</blockquote>
<h3 id="用户日志管理"><a href="#用户日志管理" class="headerlink" title="用户日志管理"></a>用户日志管理</h3><p>在应用完成后，Yarn通过NodeManager提供的将日志安全的移动到HDFS上的功能，解决了日志管理问题。</p>
<h4 id="Yarn上的日志聚合"><a href="#Yarn上的日志聚合" class="headerlink" title="Yarn上的日志聚合"></a>Yarn上的日志聚合</h4><p>有了Yarn，对于同一个应用的所有Container的日志，可以聚合并写到指定文件系统的指定目录中的一个单独文件中。用户可以通过命令行工具、web用户界面或直接从文件系统来访问这些日志。 在MapReduce的JobHistoryServer中运行着一个AggregatedLogDeletionService服务，会周期性的删除聚合日志。</p>
<h4 id="Web用户界面"><a href="#Web用户界面" class="headerlink" title="Web用户界面"></a>Web用户界面</h4><p>在应用运行期间，用户可以通过ApplicationMaster的用户界面看到日志，它将用户重定向到NodeManager的用户界面。一旦Application运行结束，完整的信息就交由JobHistoryServer管理。</p>
<h4 id="命令行访问"><a href="#命令行访问" class="headerlink" title="命令行访问"></a>命令行访问</h4><p>用户还可以使用命令行工具来与日志进行交互。可以运行下面的命令来查看可用命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn logs</div></pre></td></tr></table></figure></p>
<p>命令的格式为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn logs -applicationId &lt; application ID &gt; [Options]</div></pre></td></tr></table></figure></p>
<p>常用的选项有：-appOwner、-containerId、-nodeAddress，例如下面的命令可以打印出整个Application的全部日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yarn logs -applicationId XXXXXXX</div></pre></td></tr></table></figure></p>
<p>使用命令行工具的优点是可以通过Shell工具来帮助处理日志信息。</p>
<h4 id="日志的管理和配置"><a href="#日志的管理和配置" class="headerlink" title="日志的管理和配置"></a>日志的管理和配置</h4><p>yarn.nodemanager.log-dirs 决定了在Container运行时，它的日志在节点上保存的位置。应用的本地化日志目录在{yarn.nodemanager.log-dirs}/application<em>${applicationId}下。各个Container的日志目录位于{yarn.nodemanager.log-dirs}/application</em>${applicationId}/container_{$containerId}子目录中。<br>yarn.log-aggregation-enable 指定了是否开启日志聚合功能。如果关闭了，NodeManager会本地化保存日志，不会进行聚合操作。</p>
<p>如果开启了日志聚合功能，那么下面的配置也将生效：</p>
<blockquote>
<p>yarn.nodemanager.remote-app-log-dir：指定了NodeManager将在哪里聚合日志。<br>yarn.nodemanager.remote-app-log-dir-suffix：将在${yarn.nodemanager.remote-app-log-dir}/${user}下创建远程日志的后缀,默认为log。需要注意，这里的${user}是指Container创建用户的用户名。比如一个ThriftServer，可能使用xiaomao启动的，那么这里的user就是xiaomao。<br>yarn.log-aggregation.retain-seconds：删除聚合日志的延迟，将在这个时长之后删除日志。如果为负数则表示不删除。<br>yarn.log-aggregation.retain-check-interval-seconds：定义检查日志删除的周期，如果为0或负数，那么将会按照聚合日志保留时间的十分之一来计算。<br>yarn.log.server.url：Application完成后，NodeManager用来将Web用户界面重定向的URL。</p>
</blockquote>
<p>如果关闭了日志聚合功能，那么下面的配置将生效：</p>
<blockquote>
<p>yarn.nodemanager.log.retain-seconds：日志聚合功能关闭的情况下，各个节点上保留用户日志的时长（单位：秒）。<br>yarn.nodemanager.log.deletion-threads-count：日志聚合功能关闭情况下，NodeManager用于清理日志所启动的线程数量。</p>
</blockquote>
<h4 id="日志权限"><a href="#日志权限" class="headerlink" title="日志权限"></a>日志权限</h4><p>远程日志目录需要其所有者是${NMUser}，权限为1777，并且目录和组属于${NMGroup}。每个Application级的目录都是770。</p>
<h1 id="Apache-Hadoop-YARN的架构指南"><a href="#Apache-Hadoop-YARN的架构指南" class="headerlink" title="Apache Hadoop YARN的架构指南"></a>Apache Hadoop YARN的架构指南</h1><p>Yarn将它的功能分为两层：资源管理平台和程序调度执行。ResourceManager只是简单地基于应用程序的请求做中心的资源配置，而不关心应用程序是如何使用这些资源的。它把这个职责委托给了ApplicationMaster，由ApplicationMaster来协调单个应用程序从ResourceManager请求来的资源的逻辑执行，产生应用程序自己的具体的工作计划，ApplicationMaster利用接收到的资源，协调这个具体计划的执行。</p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ApplicationMaster和响应的Container一起组成了一个YARN的应用程序。ResourceManager提供应用程序的调度。每个应用程序由一个ApplicationMaster管理，以Container的相识请求每个任务的计算资源。Container由ResourceManager调度，在NodeManager上运行。</p>
<h2 id="ResourceManager-1"><a href="#ResourceManager-1" class="headerlink" title="ResourceManager"></a>ResourceManager</h2><p>ResourceManager和如下的组件一起工作：</p>
<blockquote>
<p>每个节点上的NodeManager： 从ResourceManager中获取指令，管理单个节点上可用资源，并接收ApplicationMaster的资源请求。<br>每个应用程序的ApplicationMaster： ApplicationMaster向ResourceManager申请资源并和NodeManager一起工作，启动、监控和停止Container。</p>
</blockquote>
<h3 id="ResourceManager组件概述"><a href="#ResourceManager组件概述" class="headerlink" title="ResourceManager组件概述"></a>ResourceManager组件概述</h3><p>ResourceManager会向客户端、NodeManager、ApplicationMaster和其他内部核心组件提供服务。</p>
<h3 id="客户端与ResourceManager交互"><a href="#客户端与ResourceManager交互" class="headerlink" title="客户端与ResourceManager交互"></a>客户端与ResourceManager交互</h3><p>用户和平台的第一次交互点是客户端与ResourceManager的交互。这个交互可以分为下面几个部分：</p>
<h4 id="Client-Service"><a href="#Client-Service" class="headerlink" title="Client Service"></a>Client Service</h4><p>这个服务实现了基本的客户端到ResourceManager的接口ApplicationClientProtocol。ClientService处理来自客户端到ResourceManager的RPC通信，包括：</p>
<blockquote>
<p>Application的提交<br>Application的终止<br>获取Application队列、集群统计，用户ACL以及更多信息。</p>
</blockquote>
<p>ClientService为ResouceManager提供额外的保护。当管理员在安全模式下运行Yarn时，ClientService确保所有来自用户的请求都已经得到认证，并且通过查找Application的ACL及后续队列层的ACL对每个用户进行授权。对于不能直接通过Kerberos认证的客户端，ClientService也提供了API，包括ResourceManager代理令牌。</p>
<h4 id="Administration-Service"><a href="#Administration-Service" class="headerlink" title="Administration Service"></a>Administration Service</h4><p>为了确保管理员的请求不会被一般用户的请求饿死，提供高优先级的操作命令，Yarn为所有管理员操作服务提供了一个接口：Administation Service。管理员客户端与Administration Service之间使用ResourceManagerAdministrationProtocol协议通信。<br>一些重要的管理员操作：</p>
<blockquote>
<p>刷新队列。<br>刷新ResourceManager处理的节点列表。<br>添加新用户组，添加/更新管理员的ACL。</p>
</blockquote>
<h4 id="Application-ACL-Manager"><a href="#Application-ACL-Manager" class="headerlink" title="Application ACL Manager"></a>Application ACL Manager</h4><p>对于面向用户的API，ResourceManager需要进行控制，只有经过认证的用户才可以访问。ApplicationACLManager管理了每个Application的ACL。ResourceManager可以通过配置yarn.acl.enable为true来启用Application的ACL。<br>ACL用于控制Application的查看和修改：</p>
<blockquote>
<p>查看，决定了通过RPC接口查看一些或所有Application的相关细节，Web UI及Web服务。<br>修改，决定了哪些用户可以“修改”（杀死）应用程序。</p>
</blockquote>
<p>ACL时一个剋执行特殊操作的用户和组列表。用户可以通过他们提交的应用的ApplicationSubmissionContext信息的一部分来指定ACL，这些ACL由ACL Manager对每一个Application进行维护。所有管理员（由yarn.admin.acl属性配置的）可以忽略这些ACL来执行任意操作。<br>同样的ACL传递给ApplicationMaster，这样ApplicationMaster可以使用该信息让用户访问ApplicationMaster内部的一些服务。<br>作为ContainerLaunchContext的一部分，当启动一个Container时，也可以使用相同ACL来控制对Application和Container的请求。</p>
<h4 id="ResourceManager-Web-Application和Web-Service"><a href="#ResourceManager-Web-Application和Web-Service" class="headerlink" title="ResourceManager Web Application和Web Service"></a>ResourceManager Web Application和Web Service</h4><p>ResourceManager有一个Web应用程序来输出集群的状态信息、指标、节点活跃列表、健康/非健康的节点列表、应用程序列表以及他们的状态和结果、指向ApplicationMaster Web接口的超链接及一个调度的专用接口。</p>
<h3 id="应用程序和ResourceManager的通信"><a href="#应用程序和ResourceManager的通信" class="headerlink" title="应用程序和ResourceManager的通信"></a>应用程序和ResourceManager的通信</h3><p>一旦客户端向ResourceManager提交的服务被纳入系统，它穿过ResourceManager内部负责拉起ApplicationMaster的状态机。下面描绘了当ApplicationMaster启动后如何与ResourceManager通信。</p>
<h4 id="ApplicationMaster-Service"><a href="#ApplicationMaster-Service" class="headerlink" title="ApplicationMaster Service"></a>ApplicationMaster Service</h4><p>ApplicationMaster Service用于响应所有来自ApplicationMaster的请求。它与ApplicationMaster之间通过ApplicationMasterProtocol协议，也是唯一的协议。ApplicationMaster Service主要负责如下功能：</p>
<blockquote>
<p>注册新的ApplicationMaster。<br>来自任意正在运行的ApplicationMaster的终止／取消注册请求。<br>认证来自不同ApplicationMaster的所有请求，确保只有合法的ApplicationMaster发送的请求传递给ResourceMaster中的应用程序对象。<br>获取来自所有运行ApplicationMaster的Container的分配和释放请求，异步的转发给Yarn调度器。</p>
</blockquote>
<p>ApplicationMasterServer有额外的逻辑来保证在任意时间只有一个ApplicationMaster能够发送请求给ResourceManager。</p>
<h4 id="ApplicationMaster-存活监控"><a href="#ApplicationMaster-存活监控" class="headerlink" title="ApplicationMaster 存活监控"></a>ApplicationMaster 存活监控</h4><p>为了管理死掉的ApplicationMaster，这个监控跟踪每个ApplicationMaster以及它的最后心跳。在配置的时间间隔外，没有产生心跳的ApplicationMaster会被认为死亡切在ResourceManager中超时。所有处于运行中/分配状态且从属于这个超时的ApplicationMaster的Container也会被标记为死掉。ResourceManager重新调度这个Application，在一个新的Container上重新运行一个ApplicationMaster实例，这样的尝试最多允许两次。</p>
<h3 id="节点和ResourceManager的通信"><a href="#节点和ResourceManager的通信" class="headerlink" title="节点和ResourceManager的通信"></a>节点和ResourceManager的通信</h3><p>NodeManager会与下面的RsourceManager的组件进行通信。</p>
<h4 id="Resource-Tracker-Service"><a href="#Resource-Tracker-Service" class="headerlink" title="Resource Tracker Service"></a>Resource Tracker Service</h4><p>ResourceManagerTracker负责对NodeManager的心跳请求进行响应。它实现了ResourceTracker接口。它负责以下任务：</p>
<blockquote>
<p>注册新节点<br>接收前面注册节点的心跳<br>确保只有合法的节点可以和ResourceManager通信。</p>
</blockquote>
<p>ResouceManager会拒绝任意非法或退役的节点的需求。不满足ResourceManager最小资源配置的请求也会被拒绝。<br>一旦注册成功，ResourceManager在它的响应信息中会将用于对ApplicationMaster进行认证的相关信息发送给NodeManager。NodeManager会对ApplicationMaster提交的启动Container请求中的NodeManager令牌和Container令牌。处于安全考虑，这些令牌会在之后的心跳中进行同步更新。<br>Resource Tracker Service转发合法的心跳給YARN调度器，Yarn调度器随后根据节点的空闲可用资源对不同的资源请求作出调度响应。<br>Resource Tracker Service跟NodeManager存活监控、nodes-list-manager紧密合作。</p>
<h5 id="NodeManager-存活监控"><a href="#NodeManager-存活监控" class="headerlink" title="NodeManager 存活监控"></a>NodeManager 存活监控</h5><p>Resource Tracker Service跟踪每一个节点（通过ID）的最后心跳时间，任何没有在配置的时间间隔内发送心跳的节点认为死亡，且在ResourceManager中超时。所有运行在超时节点上的Container也会被标记为死亡，并且不再有新的Container调度到此节点。</p>
<h5 id="Nodes-List-Manager"><a href="#Nodes-List-Manager" class="headerlink" title="Nodes-List Manager"></a>Nodes-List Manager</h5><p>Node-list manager是在ResourceManager内存中的一个集合，包括有效的节点和被排除的节点。它通过读取yarn.resourcemanager.nodes.include-path和yarn.resourcemanager.nodes.exclude-path指定的文件来初始化节点列表。</p>
<h3 id="ResourceManager-核心组件"><a href="#ResourceManager-核心组件" class="headerlink" title="ResourceManager 核心组件"></a>ResourceManager 核心组件</h3><h4 id="ApplicationsMaster"><a href="#ApplicationsMaster" class="headerlink" title="ApplicationsMaster"></a>ApplicationsMaster</h4><p>ApplicationsManager负责管理已经提交的应用程序的集合。在应用程序提交后，首先检查应用程序的规格，拒绝ApplicationMaster资源请求不合法的Application，确定Applicaiton id的唯一性，最后将通过检查的Application转給调度器。<br>该组件还负责记录和管理已结束的Application，过一段时间才会从ResourceManager的存储中清除。当一个Application结束后，它将一个ApplicationSummary放到后台的日志文件中。ApplicationSummary是一个Application在结束时的信息总结。<br>ApplicationsManager保存已经结束的应用程序的缓存，以便用户请求这些应用程序的数据。yarn.resourcemanager.max-completed-applications 指定了ResourceManager存储完成的Application的个数。存储在ResourceManager中的已完成的Application是先进先出的。</p>
<h4 id="ApplicationMaster-Launcher"><a href="#ApplicationMaster-Launcher" class="headerlink" title="ApplicationMaster Launcher"></a>ApplicationMaster Launcher</h4><p>Yarn中，非运行ApplicationMaster的Container都是由ApplicationMaster启动的，而运行ApplicationMaster的Container是由ResourceManager分配并启动的。ApplicationMaster Launcher负责此任务，该组件维护一个线程池来设置环境，且和NodeManager通信启动新提交的ApplicationMaster的Container。在Application结束时，它还会通知NodeManager清理ApplicationMaster对应的Container。</p>
<h4 id="YarnScheduler"><a href="#YarnScheduler" class="headerlink" title="YarnScheduler"></a>YarnScheduler</h4><p>Yarn调度器负责为正在运行的Application分配资源，应用程序资源的调度受到容量、队列等多方面的影响。Yarn scheduler基于Application的资源申请请求来执行调度，这些资源包含内存、cpu、磁盘、网络等，当前只支持内存和cpu。</p>
<h4 id="ContainerAllocationExpirer"><a href="#ContainerAllocationExpirer" class="headerlink" title="ContainerAllocationExpirer"></a>ContainerAllocationExpirer</h4><p>该组件负责确保所有分配的Container最终都被ApplicationMaster使用，并在相应的NodeManager上启动。ContainerAllocationExpirer包含了一个已经分配但未在相应NodeManager上启动的Container的列表。对于任何一个刚分配的Container，如果在设置的时间内，指定运行Container的NodeManager没有向ResourceManager发送Container已经启动的报告，ResourceManager将会把这个Container标记为死亡且超时。<br>此外，NodeManager也会在启动Container时对上面所说的超时进行认证（超时信息绑定在Container的ContainerToken中），对于已经超时的Container，NodeManager拒绝启动。</p>
<h3 id="ResourceManager-安全相关的组件"><a href="#ResourceManager-安全相关的组件" class="headerlink" title="ResourceManager 安全相关的组件"></a>ResourceManager 安全相关的组件</h3><p>ResourceManager有一系列的组件叫做SecretManager，负责管理令牌和私钥，这些令牌和私钥用于对各个RPC接口上的请求进行认证／授权。</p>
<h4 id="ContainerToken-secretManager"><a href="#ContainerToken-secretManager" class="headerlink" title="ContainerToken secretManager"></a>ContainerToken secretManager</h4><p>SecretManager负责管理ContainerToken。ContainerToken是ResourceManager提供给ApplicationMaster的一个特殊的令牌集合，这样ApplicationMaster可以在特定的节点上使用申请到的Container。SecretManager负责对密钥进行跟踪和更新。<br>从安全角度来说，在启动一个Container之前，我们不能信任ApplicationMaster传递给NodeManager的信息是正确的，因为ApplicationMaster可能会编造的内存或CPU。为此，ResourceManager发送信息给ApplicationMaster之前，在Container令牌里加密了Container的相关信息。因此一个Container令牌由下面的字段组成：</p>
<blockquote>
<p>Container ID：Container的唯一标识。NodeManager使用此信息与特定应用程序绑定。<br>NodeManager地址：Container令牌编码了目标NodeManager的地址，这样就绑定了NodeManager与Container的关系。<br>应用程序提交者：提交Application到ResourceManager的用户。NodeManager使用这个用户身份执行所有Container相关的活动。<br>资源： 通知NodeManager给Container分配的资源。NodeManager使用这个信息计算Container的可用资源，并对Container使用的资源进行监控，超出这个分配限制，就会杀掉Container。<br>超时时间戳：NodeManager根据这个时间戳判断Container是否已经过期，过期的Container会被拒绝启动。<br>主键标识符：NodeManager用来验证发送给它们的Container令牌。ResourceManager生成密钥，并为密钥分配一个唯一标识。这个密钥和它的唯一标识会通知所有的NodeManager。在NodeManager注册时会发送给NodeManager，之后会在心跳中进行更新通知。密钥更新时，ResourceManager不会立即使用新的密钥，只有在所有NodeManager都得到新的密钥或经过密钥启动时间，才会启用新的密钥。对于NodeManager，可以同时存在两个密钥，具体使用哪个，会根据密钥的唯一标识进行区分。<br>ResourceManager标识符：ResourceManager也可能会重启，为了区分Container的分配关系，所以将ResourceManager标识符信息编码到Container令牌中。ResourceManager重启会杀掉之前分配的所有的Container，NodeManager也会拒绝之前ResourceManager分配的Container的启动。</p>
</blockquote>
<h4 id="AMRMToken-密钥管理器"><a href="#AMRMToken-密钥管理器" class="headerlink" title="AMRMToken 密钥管理器"></a>AMRMToken 密钥管理器</h4><p>只有ApplicationMaster可以以Container的形式来请求资源。为了避免恶意程序模仿ApplicationMaster，ResourceManager使用一个叫做AMRMToken的令牌，每个ApplicationAttempt对应一个令牌。密钥管理器在内存中保存每个令牌直到ApplicationMaster结束，在此期间，使用这些令牌来对ApplicationMaster的请求进行认证。<br>ApplicationMaster可以通过加载一个由YARN本地化的证书来得到这个令牌。这个本地化文件由ApplicationConstants.CONTAINER_TOKEN_FILE_ENV_NAME指定。<br>与Container的令牌不同，AMRMToken不与系统中的其他实体共享，出于安全的原因，令牌也会每隔一段时间滚动更新，但是不需要激活间隔。</p>
<h4 id="NMToken-密钥管理器"><a href="#NMToken-密钥管理器" class="headerlink" title="NMToken 密钥管理器"></a>NMToken 密钥管理器</h4><p>Container令牌用来对来自ApplicationMaster的启动Container的请求进行授权。它们只在为了启动Container而建立的ApplicationMaster到NodeManager的连接中有效。Container令牌的的关键作用是为了防止资源滥用。<br>除了启动Container时ApplicationMaster和NodeManager建立连接，NodeManager还允许ApplicationMaster停止Container或获取Container状态。但是需要注意的是，ApplicationMaster与每个Container都创建到NodeManager的持久连接是不现实的。<br>NMToken服务用来解决这个问题，ApplicationMaster使用NMToken来管理跟一个NodeManager的连接，使用这个令牌想这个节点发送请求。</p>
<blockquote>
<p>ResourceManager给每个NodeManager和每个Application的Attempt生成一个NMToken。<br>当Container创建，ResourceManager生成对应NodeManager的NMToker给applicationMaster。<br>为了优化网络，不是每分配一个Container就把对应NodeManager的NMToker发送给ApplicationMaster，只会在ApplicationMaster的Container首次在NodeManager上创建时才会发送，除此之外，就是在主密钥更新，NMToker失效的情况下才会在此发送给ApplicationMaster。<br>当ApplicationMaster接收到新的NMToken，它会将对应于NodeManager的旧令牌替换掉。ApplicationMaster内部使用NMTokenCache库来管理令牌。<br>ApplicationMaster应该始终使用最新的NMToker。如果ApplicationMaster从ResourceManager收到新的NMToken，那么ApplicationMaster应NodeManager的旧连接应该关闭并创建新的连接。如果连接是使用旧的令牌创建的，在发起请求时，NodeManager会简单的拒绝。<br>和ContainerToken一样，ApplicationMaster与NMToker也是有绑定关系的，会将Application Attempt集成到NMToken中。</p>
</blockquote>
<h4 id="RMDelegationToken密钥管理器"><a href="#RMDelegationToken密钥管理器" class="headerlink" title="RMDelegationToken密钥管理器"></a>RMDelegationToken密钥管理器</h4><p>这个组件是ResourceMananger上代理令牌的密钥管理。它负责给客户端生成代理令牌，代理令牌可以传递给想要和ResourceManager通信，但没有经过Kerberos认证的Application。</p>
<h4 id="DelegationToken-Renewer"><a href="#DelegationToken-Renewer" class="headerlink" title="DelegationToken Renewer"></a>DelegationToken Renewer</h4><p>在安全模式下，ResourceManager应该开启Kerberos认证，此组件在应用程序运行期间更新应用程序的令牌，知道令牌不能再更新。</p>
<h2 id="NodeManager-1"><a href="#NodeManager-1" class="headerlink" title="NodeManager"></a>NodeManager</h2><p>NodeManager是Hadoop YARN在每个计算节点上的代理，它根据YARN Application的要求，使用节点上的资源来运行Contianer。NodeManager本质上是Yarn的工作守护进程，主要职责如下：</p>
<blockquote>
<p>保持与ResourceManager的同步。<br>跟踪节点的健康状况。<br>管理各个Container的生命周期，监控每个Container的资源使用情况。<br>管理分布式缓存。<br>管理各个Container生成的日志。<br>不同的Yarn应用可能需要的辅助服务。</p>
</blockquote>
<h3 id="NodeManager-各个组件概述"><a href="#NodeManager-各个组件概述" class="headerlink" title="NodeManager 各个组件概述"></a>NodeManager 各个组件概述</h3><p>NodeManager的核心功能是对Container的管理。NodeManager接受来自ApplicationMaster的启动或停止Container的请求，对Container令牌进行鉴权，管理Container执行的依赖库，监控Container的执行过程。管理员</p>
<h1 id="YARN-的HA"><a href="#YARN-的HA" class="headerlink" title="YARN 的HA"></a>YARN 的HA</h1><p>参考地址：<a href="https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html" target="_blank" rel="external">https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/04/23/spark-2-11-BlockManager/" itemprop="url">
                  spark-2-11-BlockManager
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-04-23T11:28:47+08:00" content="2019-04-23">
              2019-04-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在SparkEnv中创建BlockManagerMaster和BlockManagerMasterEndpoint，在生成BlockManagerMaster的时候需要BlockManagerMasterEndpoint（作用是什么？？？？？？？？？？）<br>除此之外，BlockManager也会在SparkEnv中进行创建，并且创建BlockManager的时候，需要BlockManagerMaster的引用（作用是什么？？？？？？？），而且还需要一个BlockTransferService（作用是什么？？？？？？？）。</p>
<p>BlockManagerMaster在driver和executor上都有运行。</p>
<p>首先看一下BlockManagerMaster的实现</p>
<p>创建BlockManagerMaster的时使用的RpcEndpointRef，保持与driver的通信，接下来BlockManagerMaster中的方法，都会用到这个RpcEndpointRef。</p>
<p>BlockManagerMaster中的RpcEndpointRef用于向driver发送消息，dirver中会向其他BlockManagerMaster同步这个消息。<br>比如在BlockManagerMaster的stop方法<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (driverEndpoint != <span class="literal">null</span> &amp;&amp; isDriver) &#123;</div><div class="line">  tell(<span class="type">StopBlockManagerMaster</span>)</div><div class="line">  driverEndpoint = <span class="literal">null</span></div><div class="line">  logInfo(<span class="string">"BlockManagerMaster stopped"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>只有dirver节点的BlockMasterMaster停止时，才会向driver通知StopBlockManagerManager事件。</p>
<p>tell方法调用BlockManagerMaster的RpcEndpointRef的askSync方法发送一个事件，并期待得到true，否则抛出SparkException异常。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">private def tell(message: Any) &#123;</div><div class="line">  if (!driverEndpoint.askSync[Boolean](message)) &#123;</div><div class="line">    throw new SparkException(&quot;BlockManagerMasterEndpoint returned false, expected true.&quot;)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>需要注意的是，这里调用的方法是askSync，同步请求。除此之外，RpcEndpointRef还有ask方法，是异步执行的。</p>
<p>上面我们看到了stop方法的实现，接下来我们顺序看一下：</p>
<h2 id="removeExecutor"><a href="#removeExecutor" class="headerlink" title="removeExecutor"></a>removeExecutor</h2><p>移除Executor，其实现是向driver发送一个RemoveExecutor对象。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeExecutor</span></span>(execId: <span class="type">String</span>) &#123;</div><div class="line">  tell(<span class="type">RemoveExecutor</span>(execId))</div><div class="line">  logInfo(<span class="string">"Removed "</span> + execId + <span class="string">" successfully in removeExecutor"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="removeExecutorAsync"><a href="#removeExecutorAsync" class="headerlink" title="removeExecutorAsync"></a>removeExecutorAsync</h2><p>异步移除Executor，与removeExecutor的操作类似，只是使用的RpcEndpointRef的异步方法。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeExecutorAsync</span></span>(execId: <span class="type">String</span>) &#123;</div><div class="line">  driverEndpoint.ask[<span class="type">Boolean</span>](<span class="type">RemoveExecutor</span>(execId))</div><div class="line">  logInfo(<span class="string">"Removal of executor "</span> + execId + <span class="string">" requested"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="registerBlockManager"><a href="#registerBlockManager" class="headerlink" title="registerBlockManager"></a>registerBlockManager</h2><p>向dirver注册Blockmanager的id（可以这么理解吗？？？？？？）。输入的BlockManagerId对象，不包含拓扑信息。注册返回的BlockManagerId会用来更新BlockManagerMaster的数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">registerBlockManager</span></span>(</div><div class="line">    blockManagerId: <span class="type">BlockManagerId</span>,</div><div class="line">    maxOnHeapMemSize: <span class="type">Long</span>,</div><div class="line">    maxOffHeapMemSize: <span class="type">Long</span>,</div><div class="line">    slaveEndpoint: <span class="type">RpcEndpointRef</span>): <span class="type">BlockManagerId</span> = &#123;</div><div class="line">  logInfo(<span class="string">s"Registering BlockManager <span class="subst">$blockManagerId</span>"</span>)</div><div class="line">  <span class="keyword">val</span> updatedId = driverEndpoint.askSync[<span class="type">BlockManagerId</span>](</div><div class="line">    <span class="type">RegisterBlockManager</span>(blockManagerId, maxOnHeapMemSize, maxOffHeapMemSize, slaveEndpoint))</div><div class="line">  logInfo(<span class="string">s"Registered BlockManager <span class="subst">$updatedId</span>"</span>)</div><div class="line">  updatedId</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>其实现就是通过RpcEndpointRef向driver发送一个RegisterBlockManager事件，事件中包含BlockManagerId、最大堆内内存和slaveEndpoint（RpcEndpointRef）。</p>
<h2 id="updateBlockInfo"><a href="#updateBlockInfo" class="headerlink" title="updateBlockInfo"></a>updateBlockInfo</h2><p>updateBlockInfo方法用于向driver发送某个Block的最新信息，信息包括存储级别、内存大小和磁盘大小。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateBlockInfo</span></span>(</div><div class="line">    blockManagerId: <span class="type">BlockManagerId</span>,</div><div class="line">    blockId: <span class="type">BlockId</span>,</div><div class="line">    storageLevel: <span class="type">StorageLevel</span>,</div><div class="line">    memSize: <span class="type">Long</span>,</div><div class="line">    diskSize: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">val</span> res = driverEndpoint.askSync[<span class="type">Boolean</span>](</div><div class="line">    <span class="type">UpdateBlockInfo</span>(blockManagerId, blockId, storageLevel, memSize, diskSize))</div><div class="line">  logDebug(<span class="string">s"Updated info of block <span class="subst">$blockId</span>"</span>)</div><div class="line">  res</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实现是通过RpcEndpointRef向dirver发送UpdateBlockInfo事件。</p>
<h2 id="getLocations"><a href="#getLocations" class="headerlink" title="getLocations"></a>getLocations</h2><p>获取指定BlockId的位置。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLocations</span></span>(blockId: <span class="type">BlockId</span>): <span class="type">Seq</span>[<span class="type">BlockManagerId</span>] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Seq</span>[<span class="type">BlockManagerId</span>]](<span class="type">GetLocations</span>(blockId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实现是通过RpcEndpointRef向driver发送一个GetLocations事件。</p>
<h2 id="getLocations-1"><a href="#getLocations-1" class="headerlink" title="getLocations"></a>getLocations</h2><p>获取多个BlockId的位置<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLocations</span></span>(blockIds: <span class="type">Array</span>[<span class="type">BlockId</span>]): <span class="type">IndexedSeq</span>[<span class="type">Seq</span>[<span class="type">BlockManagerId</span>]] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">IndexedSeq</span>[<span class="type">Seq</span>[<span class="type">BlockManagerId</span>]]](</div><div class="line">    <span class="type">GetLocationsMultipleBlockIds</span>(blockIds))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实现是通过RpcEndpointRef向driver发送一个GetLocationsMultipleBlockIds事件。</p>
<h2 id="contains"><a href="#contains" class="headerlink" title="contains"></a>contains</h2><p>判断当前BlockManagerMaster中是否包含指定的Block<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">contains</span></span>(blockId: <span class="type">BlockId</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  !getLocations(blockId).isEmpty</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实现为，通过RpcEndpointRef向driver发送一个获取BlockId位置的请求，如果可以获得表示Block存在。</p>
<h2 id="getPeers"><a href="#getPeers" class="headerlink" title="getPeers"></a>getPeers</h2><p>从driver那里获取集群中其他BlockManagerId<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPeers</span></span>(blockManagerId: <span class="type">BlockManagerId</span>): <span class="type">Seq</span>[<span class="type">BlockManagerId</span>] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Seq</span>[<span class="type">BlockManagerId</span>]](<span class="type">GetPeers</span>(blockManagerId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpoint向driver发送一个GetPeers事件</p>
<h2 id="getExecutorEndpointRef"><a href="#getExecutorEndpointRef" class="headerlink" title="getExecutorEndpointRef"></a>getExecutorEndpointRef</h2><p>获取指定executor的RpcEndpointRef信息。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getExecutorEndpointRef</span></span>(executorId: <span class="type">String</span>): <span class="type">Option</span>[<span class="type">RpcEndpointRef</span>] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Option</span>[<span class="type">RpcEndpointRef</span>]](<span class="type">GetExecutorEndpointRef</span>(executorId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实现是，通过RpcEndpointRef向driver发送一个GetExecutorEndpointRef事件。</p>
<h2 id="removeBlock"><a href="#removeBlock" class="headerlink" title="removeBlock"></a>removeBlock</h2><p>移除指定的Block，只有driver知道的Block才能够被移除。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeBlock</span></span>(blockId: <span class="type">BlockId</span>) &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Boolean</span>](<span class="type">RemoveBlock</span>(blockId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送RemoveBlock事件来实现。</p>
<h2 id="removeRdd"><a href="#removeRdd" class="headerlink" title="removeRdd"></a>removeRdd</h2><p>移除所有归属于指定RDD的Block<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeRdd</span></span>(rddId: <span class="type">Int</span>, blocking: <span class="type">Boolean</span>) &#123;</div><div class="line">  <span class="keyword">val</span> future = driverEndpoint.askSync[<span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Int</span>]]](<span class="type">RemoveRdd</span>(rddId))</div><div class="line">  future.onFailure &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">      logWarning(<span class="string">s"Failed to remove RDD <span class="subst">$rddId</span> - <span class="subst">$&#123;e.getMessage&#125;</span>"</span>, e)</div><div class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread)</div><div class="line">  <span class="keyword">if</span> (blocking) &#123;</div><div class="line">    timeout.awaitResult(future)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送RemoveRdd来实现，第二个参数决定是否要等到结果返回。</p>
<h2 id="removeShuffle"><a href="#removeShuffle" class="headerlink" title="removeShuffle"></a>removeShuffle</h2><p>移除所有属于指定Shuffle的Block。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeShuffle</span></span>(shuffleId: <span class="type">Int</span>, blocking: <span class="type">Boolean</span>) &#123;</div><div class="line">  <span class="keyword">val</span> future = driverEndpoint.askSync[<span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Boolean</span>]]](<span class="type">RemoveShuffle</span>(shuffleId))</div><div class="line">  future.onFailure &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">      logWarning(<span class="string">s"Failed to remove shuffle <span class="subst">$shuffleId</span> - <span class="subst">$&#123;e.getMessage&#125;</span>"</span>, e)</div><div class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread)</div><div class="line">  <span class="keyword">if</span> (blocking) &#123;</div><div class="line">    timeout.awaitResult(future)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送RemoveShuffle事件来实现，第二个参数决定是否要等到结果返回。</p>
<h2 id="removeBroadcast"><a href="#removeBroadcast" class="headerlink" title="removeBroadcast"></a>removeBroadcast</h2><p>移除所有归属于指定Broadcast的Block。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeBroadcast</span></span>(broadcastId: <span class="type">Long</span>, removeFromMaster: <span class="type">Boolean</span>, blocking: <span class="type">Boolean</span>) &#123;</div><div class="line">  <span class="keyword">val</span> future = driverEndpoint.askSync[<span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Int</span>]]](</div><div class="line">    <span class="type">RemoveBroadcast</span>(broadcastId, removeFromMaster))</div><div class="line">  future.onFailure &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">      logWarning(<span class="string">s"Failed to remove broadcast <span class="subst">$broadcastId</span>"</span> +</div><div class="line">        <span class="string">s" with removeFromMaster = <span class="subst">$removeFromMaster</span> - <span class="subst">$&#123;e.getMessage&#125;</span>"</span>, e)</div><div class="line">  &#125;(<span class="type">ThreadUtils</span>.sameThread)</div><div class="line">  <span class="keyword">if</span> (blocking) &#123;</div><div class="line">    timeout.awaitResult(future)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送RemoveBroadcast事件来实现。第三个参数blocking决定是否要等到结果返回。</p>
<h2 id="getMemoryStatus"><a href="#getMemoryStatus" class="headerlink" title="getMemoryStatus"></a>getMemoryStatus</h2><p>获取每个BlockManager的内存状态，返回每个BlockManager所分配的最大内存以及内存的剩余。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMemoryStatus</span></span>: <span class="type">Map</span>[<span class="type">BlockManagerId</span>, (<span class="type">Long</span>, <span class="type">Long</span>)] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Map</span>[<span class="type">BlockManagerId</span>, (<span class="type">Long</span>, <span class="type">Long</span>)]](<span class="type">GetMemoryStatus</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送GetMemoryStatus对象来实现。</p>
<h2 id="getStorageStatus"><a href="#getStorageStatus" class="headerlink" title="getStorageStatus"></a>getStorageStatus</h2><p>获取存储存储状态<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getStorageStatus</span></span>: <span class="type">Array</span>[<span class="type">StorageStatus</span>] = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Array</span>[<span class="type">StorageStatus</span>]](<span class="type">GetStorageStatus</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送GetStorageStatus对象来实现。</p>
<h2 id="getBlockStatus"><a href="#getBlockStatus" class="headerlink" title="getBlockStatus"></a>getBlockStatus</h2><p>获取所有Block Manager上的block的状态。该操作开销昂贵，仅用于测试。<br>通过RpcEndpointRef向driver发送GetBlockStatus事件来实现。</p>
<h2 id="getMatchingBlockIds"><a href="#getMatchingBlockIds" class="headerlink" title="getMatchingBlockIds"></a>getMatchingBlockIds</h2><p>返回符合过滤器的BlockId<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMatchingBlockIds</span></span>(</div><div class="line">    filter: <span class="type">BlockId</span> =&gt; <span class="type">Boolean</span>,</div><div class="line">    askSlaves: <span class="type">Boolean</span>): <span class="type">Seq</span>[<span class="type">BlockId</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> msg = <span class="type">GetMatchingBlockIds</span>(filter, askSlaves)</div><div class="line">  <span class="keyword">val</span> future = driverEndpoint.askSync[<span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">BlockId</span>]]](msg)</div><div class="line">  timeout.awaitResult(future)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送GetMatchingBlockIds事件来实现。</p>
<h2 id="hasCachedBlock"><a href="#hasCachedBlock" class="headerlink" title="hasCachedBlock"></a>hasCachedBlock</h2><p>判断指定Executor是否缓存了Block，不包括broadcast block。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hasCachedBlocks</span></span>(executorId: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  driverEndpoint.askSync[<span class="type">Boolean</span>](<span class="type">HasCachedBlocks</span>(executorId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>通过RpcEndpointRef向driver发送HasCachedBlocks事件来实现。</p>
<p>通过对上面方法的了解我们知道，BlockManagerMaster不一定是运行在driver上的，也会运行在Executor上。它内部持有与driver进行沟通的RpcEndpointRef。在SparkEnv中，生成BlockManager的时候，会将BlockManagerMaster传递给BlockManager。</p>
<h1 id="接下来看一下BlockManagerMasterEndpoint"><a href="#接下来看一下BlockManagerMasterEndpoint" class="headerlink" title="接下来看一下BlockManagerMasterEndpoint"></a>接下来看一下BlockManagerMasterEndpoint</h1><p>上面我们已经知道了BlockManagerMaster会通过BlockManagerMasterEndpoint来请求相关的操作。BlockManagerMasterEndpoint就是用来对BlockManagerMaster的请求进行响应的。</p>
<h2 id="首先看一下BlockManagerMasterEndpoint的成员"><a href="#首先看一下BlockManagerMasterEndpoint的成员" class="headerlink" title="首先看一下BlockManagerMasterEndpoint的成员"></a>首先看一下BlockManagerMasterEndpoint的成员</h2><blockquote>
<p>blockManagerInfo 存储了BlockManagerId到BlockManagerInfo的映射关系。<br>blockManagerIdByExecutor 存储了executor id 到 BlockManagerId的映射关系。<br>blockLocations 存储了BlockId到BlockManagerId的映射关系。<br>topologyMapper 拓扑映射的实现类。</p>
</blockquote>
<p>上面topologyMapper的定义，首先读取配置项“spark.storage.replication.topologyMapper”的值，如果没有配置则使用默认的拓扑管理DefaultTopologyMapper。然后使用SparkConf进行实例化。</p>
<h2 id="接下来针对BlockManagerMasterEndpoint对BlockManagerMaster的应答进行解析"><a href="#接下来针对BlockManagerMasterEndpoint对BlockManagerMaster的应答进行解析" class="headerlink" title="接下来针对BlockManagerMasterEndpoint对BlockManagerMaster的应答进行解析"></a>接下来针对BlockManagerMasterEndpoint对BlockManagerMaster的应答进行解析</h2><h3 id="RegisterBlockManager的应答register"><a href="#RegisterBlockManager的应答register" class="headerlink" title="RegisterBlockManager的应答register"></a>RegisterBlockManager的应答register</h3><p>register方法是对RegisterBlockManager事件的应答，它的定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">private def register(</div><div class="line">    idWithoutTopologyInfo: BlockManagerId,</div><div class="line">    maxOnHeapMemSize: Long,</div><div class="line">    maxOffHeapMemSize: Long,</div><div class="line">    slaveEndpoint: RpcEndpointRef): BlockManagerId = &#123;</div><div class="line">  val id = BlockManagerId(</div><div class="line">    idWithoutTopologyInfo.executorId,</div><div class="line">    idWithoutTopologyInfo.host,</div><div class="line">    idWithoutTopologyInfo.port,</div><div class="line">    topologyMapper.getTopologyForHost(idWithoutTopologyInfo.host))</div><div class="line"></div><div class="line">  val time = System.currentTimeMillis()</div><div class="line">  if (!blockManagerInfo.contains(id)) &#123;</div><div class="line">    blockManagerIdByExecutor.get(id.executorId) match &#123;</div><div class="line">      case Some(oldId) =&gt;</div><div class="line">        // A block manager of the same executor already exists, so remove it (assumed dead)</div><div class="line">        logError(&quot;Got two different block manager registrations on same executor - &quot;</div><div class="line">            + s&quot; will replace old one $oldId with new one $id&quot;)</div><div class="line">        removeExecutor(id.executorId)</div><div class="line">      case None =&gt;</div><div class="line">    &#125;</div><div class="line">    logInfo(&quot;Registering block manager %s with %s RAM, %s&quot;.format(</div><div class="line">      id.hostPort, Utils.bytesToString(maxOnHeapMemSize + maxOffHeapMemSize), id))</div><div class="line"></div><div class="line">    blockManagerIdByExecutor(id.executorId) = id</div><div class="line"></div><div class="line">    blockManagerInfo(id) = new BlockManagerInfo(</div><div class="line">      id, System.currentTimeMillis(), maxOnHeapMemSize, maxOffHeapMemSize, slaveEndpoint)</div><div class="line">  &#125;</div><div class="line">  listenerBus.post(SparkListenerBlockManagerAdded(time, id, maxOnHeapMemSize + maxOffHeapMemSize,</div><div class="line">      Some(maxOnHeapMemSize), Some(maxOffHeapMemSize)))</div><div class="line">  id</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该方法返回的是一个BlockManagerId，与输入参数不同，返回的对象中包含了拓扑信息。而这个拓扑信息就是从topologyManager中得到的。接下来，判断BlockManagerId到BlockManagerInfo的信息中是否含有当前BlockManagerId的信息，如果含有，则跳过执行，只有在不含有的时候，才会继续处理。<br>接着判断是否在blockManagerIdByExecutor中，如果有，则说明相同executor的BlockManager已经存在了，需要将这个executor的老的BlockManager移除掉，然后将新的BlockManager添加到blockManagerIdByExecutor中。并且根据BlockManagerId.id、最大堆内内存、最大堆外内存、以及要注册的BlockManagerId的RpcEndpointRef生成BlockManagerInfo对象，添加到BlockManagerId到BlockManagerInfo的映射关系中。</p>
<h3 id="UpdateBlockInfo的应答updateBlockInfo"><a href="#UpdateBlockInfo的应答updateBlockInfo" class="headerlink" title="UpdateBlockInfo的应答updateBlockInfo"></a>UpdateBlockInfo的应答updateBlockInfo</h3><p>updateBlockInf是对UpdateBlockInfo事件的应答，它的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateBlockInfo</span></span>(</div><div class="line">    blockManagerId: <span class="type">BlockManagerId</span>,</div><div class="line">    blockId: <span class="type">BlockId</span>,</div><div class="line">    storageLevel: <span class="type">StorageLevel</span>,</div><div class="line">    memSize: <span class="type">Long</span>,</div><div class="line">    diskSize: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (!blockManagerInfo.contains(blockManagerId)) &#123;</div><div class="line">    <span class="keyword">if</span> (blockManagerId.isDriver &amp;&amp; !isLocal) &#123;</div><div class="line">      <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// 更新BlockManagerInfo最后操作时间</span></div><div class="line">  <span class="keyword">if</span> (blockId == <span class="literal">null</span>) &#123;</div><div class="line">    blockManagerInfo(blockManagerId).updateLastSeenMs()</div><div class="line">    <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  blockManagerInfo(blockManagerId).updateBlockInfo(blockId, storageLevel, memSize, diskSize)</div><div class="line"></div><div class="line">  <span class="keyword">var</span> locations: mutable.<span class="type">HashSet</span>[<span class="type">BlockManagerId</span>] = <span class="literal">null</span></div><div class="line">  <span class="keyword">if</span> (blockLocations.containsKey(blockId)) &#123;</div><div class="line">    locations = blockLocations.get(blockId)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    locations = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">BlockManagerId</span>]</div><div class="line">    blockLocations.put(blockId, locations)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (storageLevel.isValid) &#123;</div><div class="line">    locations.add(blockManagerId)</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    locations.remove(blockManagerId)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Remove the block from master tracking if it has been removed on all slaves.</span></div><div class="line">  <span class="keyword">if</span> (locations.size == <span class="number">0</span>) &#123;</div><div class="line">    blockLocations.remove(blockId)</div><div class="line">  &#125;</div><div class="line">  <span class="literal">true</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>因为该方法的功能为更新，所以如果参数给定的BlockManagerId不存在会返回false（driver除外）。然后调用BlockManagerInfo中的updateBlockInfo方法来更新BlockManagerInfo，这个方法稍后介绍BlockManagerInfo的时候再看。接着，记录BlockId到BlockManagerId的映射关系，因为一个BlockId的数据可能存在多个BlockManager中（或者分散存储，或者有多个副本），因此BlockId对应的是一个HashSet，HashSet中存放的是BlockManagerId，但是需要注意的是，BlockManagerId是否可以加到上面的HashSet中，取决于参数的storageLevel，只有storageLevel有效时（存储级别为内存或磁盘，且副本个数大于0）才会存储。最后对blockLocations进行清理，对于没有存储位置的BlockId，从blockLocations中删除。</p>
<h3 id="GetLocations的应答getLocations"><a href="#GetLocations的应答getLocations" class="headerlink" title="GetLocations的应答getLocations"></a>GetLocations的应答getLocations</h3><p>getLocations是对GetLocations事件的应答，它的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getLocations</span></span>(blockId: <span class="type">BlockId</span>): <span class="type">Seq</span>[<span class="type">BlockManagerId</span>] = &#123;</div><div class="line">  <span class="keyword">if</span> (blockLocations.containsKey(blockId)) blockLocations.get(blockId).toSeq <span class="keyword">else</span> <span class="type">Seq</span>.empty</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在updateBlockInfo方法中我们已经知道blockLocations存储的是BlockId到BlockManagerId的映射。因此，只要有BlockId，就可以找到BlockManagerId的列表。</p>
<h3 id="GetLocationsMultipleBlockIds的应答getLocationsMultipleBlockIds"><a href="#GetLocationsMultipleBlockIds的应答getLocationsMultipleBlockIds" class="headerlink" title="GetLocationsMultipleBlockIds的应答getLocationsMultipleBlockIds"></a>GetLocationsMultipleBlockIds的应答getLocationsMultipleBlockIds</h3><p>getLocationsMultipleBlockIds是对GetLocationsMultipleBlockIds事件的应答，它的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getLocationsMultipleBlockIds</span></span>(</div><div class="line">    blockIds: <span class="type">Array</span>[<span class="type">BlockId</span>]): <span class="type">IndexedSeq</span>[<span class="type">Seq</span>[<span class="type">BlockManagerId</span>]] = &#123;</div><div class="line">  blockIds.map(blockId =&gt; getLocations(blockId))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>相对于getLocations，这个方法传输的参数是BlockId列表，因此只需要迭代获取每个BlockId的位置，返回一个映射关系即可。</p>
<h3 id="GetPeers的应答getPeers"><a href="#GetPeers的应答getPeers" class="headerlink" title="GetPeers的应答getPeers"></a>GetPeers的应答getPeers</h3><p>getPeers是对GetPeers事件的应答，它的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getPeers</span></span>(blockManagerId: <span class="type">BlockManagerId</span>): <span class="type">Seq</span>[<span class="type">BlockManagerId</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> blockManagerIds = blockManagerInfo.keySet</div><div class="line">  <span class="keyword">if</span> (blockManagerIds.contains(blockManagerId)) &#123;</div><div class="line">    blockManagerIds.filterNot &#123; _.isDriver &#125;.filterNot &#123; _ == blockManagerId &#125;.toSeq</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="type">Seq</span>.empty</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该方法就是获取BlockManagerId节点上其他非driver的BlockManagerId的列表。从BlockManagerId到BlockManagerInfo的映射关系中得到KeySet，就是当前节点上所有的BlockManagerId，只要过滤到driver以及与当前BlockManagerId相同id的BlockManagerId即可。</p>
<h3 id="GetExecutorEndpointRef的应答getExecutorEndpointRef"><a href="#GetExecutorEndpointRef的应答getExecutorEndpointRef" class="headerlink" title="GetExecutorEndpointRef的应答getExecutorEndpointRef"></a>GetExecutorEndpointRef的应答getExecutorEndpointRef</h3><p>getExecutorEndpointRef是GetExecutorEndpointRef事件的应答，它的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getExecutorEndpointRef</span></span>(executorId: <span class="type">String</span>): <span class="type">Option</span>[<span class="type">RpcEndpointRef</span>] = &#123;</div><div class="line">  <span class="keyword">for</span> (</div><div class="line">    blockManagerId &lt;- blockManagerIdByExecutor.get(executorId);</div><div class="line">    info &lt;- blockManagerInfo.get(blockManagerId)</div><div class="line">  ) <span class="keyword">yield</span> &#123;</div><div class="line">    info.slaveEndpoint</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们在register方法中生成BlockManagerInfo时，BlockManagerInfo的最后一个参数就是slaveEndpoint（一个RpcEndpointRef对象）。所以调用getExecutorEndpointRef方法，只要根据executorId得到BlockManagerId，然后根据BlockManagerId得到BlockManagerInfo，就可以得到这个slaveEndpoint了。</p>
<h3 id="GetMemoryStatus的应答memoryStatus"><a href="#GetMemoryStatus的应答memoryStatus" class="headerlink" title="GetMemoryStatus的应答memoryStatus"></a>GetMemoryStatus的应答memoryStatus</h3><p>memoryStatus是GetMemoryStatus事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">memoryStatus</span></span>: <span class="type">Map</span>[<span class="type">BlockManagerId</span>, (<span class="type">Long</span>, <span class="type">Long</span>)] = &#123;</div><div class="line">  blockManagerInfo.map &#123; <span class="keyword">case</span>(blockManagerId, info) =&gt;</div><div class="line">    (blockManagerId, (info.maxMem, info.remainingMem))</div><div class="line">  &#125;.toMap</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法逻辑也很简单，BlockManagerInfo中已经存着最大内存了（最大堆内内存和最大堆外内存），并且在每次执行updateBlockInfo方法时会对剩余内存进行操作，只要拿到BlockManagerInfo，就拿到了内存状态，但是缺点是无法知道具体的堆内内存和堆外内存的状态。</p>
<h3 id="GetStorageStatus的应答storageStatus"><a href="#GetStorageStatus的应答storageStatus" class="headerlink" title="GetStorageStatus的应答storageStatus"></a>GetStorageStatus的应答storageStatus</h3><p>storageStatus方法是对GetStorageStatus事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">storageStatus</span></span>: <span class="type">Array</span>[<span class="type">StorageStatus</span>] = &#123;</div><div class="line">  blockManagerInfo.map &#123; <span class="keyword">case</span> (blockManagerId, info) =&gt;</div><div class="line">    <span class="keyword">new</span> <span class="type">StorageStatus</span>(blockManagerId, info.maxMem, <span class="type">Some</span>(info.maxOnHeapMem),</div><div class="line">      <span class="type">Some</span>(info.maxOffHeapMem), info.blocks.asScala)</div><div class="line">  &#125;.toArray</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>StorageStatus，我们理解为存储状态，也就是每个BlockManager（用BlockManagerId表示）的存储状态，包括最大内存、最大堆内内存、最大堆外内存和Block列表（BlockId-&gt;BlockStatus的对应关系集合）。这些信息都存储在BlockManagerInfo中，只要拿到BlockManagerInfo就OK了。</p>
<h3 id="GetBlockStatus的应答blockStatus"><a href="#GetBlockStatus的应答blockStatus" class="headerlink" title="GetBlockStatus的应答blockStatus"></a>GetBlockStatus的应答blockStatus</h3><p>blockStatus方法是对GetBlockStatus事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">blockStatus</span></span>(</div><div class="line">    blockId: <span class="type">BlockId</span>,</div><div class="line">    askSlaves: <span class="type">Boolean</span>): <span class="type">Map</span>[<span class="type">BlockManagerId</span>, <span class="type">Future</span>[<span class="type">Option</span>[<span class="type">BlockStatus</span>]]] = &#123;</div><div class="line">  <span class="keyword">val</span> getBlockStatus = <span class="type">GetBlockStatus</span>(blockId)</div><div class="line">  <span class="comment">/*</span></div><div class="line">   * Rather than blocking on the block status query, master endpoint should simply return</div><div class="line">   * Futures to avoid potential deadlocks. This can arise if there exists a block manager</div><div class="line">   * that is also waiting for this master endpoint's response to a previous message.</div><div class="line">   */</div><div class="line">  blockManagerInfo.values.map &#123; info =&gt;</div><div class="line">    <span class="keyword">val</span> blockStatusFuture =</div><div class="line">      <span class="keyword">if</span> (askSlaves) &#123;</div><div class="line">        info.slaveEndpoint.ask[<span class="type">Option</span>[<span class="type">BlockStatus</span>]](getBlockStatus)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Future</span> &#123; info.getStatus(blockId) &#125;</div><div class="line">      &#125;</div><div class="line">    (info.blockManagerId, blockStatusFuture)</div><div class="line">  &#125;.toMap</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>获取BlockId的状态，如果askSlaves，则会调用info中的RpcEndpointRef取获取最新的BlockSatus，否则就使用BlockManagerInfo中当前的。一个BlockId可能会对应多个BlockManagerId。</p>
<h3 id="GetMatchingBlockIds的应答getMatchingBlockIds"><a href="#GetMatchingBlockIds的应答getMatchingBlockIds" class="headerlink" title="GetMatchingBlockIds的应答getMatchingBlockIds"></a>GetMatchingBlockIds的应答getMatchingBlockIds</h3><p>getMatchingBlockIds方法是对GetMatchingBlockIds事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMatchingBlockIds</span></span>(</div><div class="line">    filter: <span class="type">BlockId</span> =&gt; <span class="type">Boolean</span>,</div><div class="line">    askSlaves: <span class="type">Boolean</span>): <span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">BlockId</span>]] = &#123;</div><div class="line">  <span class="keyword">val</span> getMatchingBlockIds = <span class="type">GetMatchingBlockIds</span>(filter)</div><div class="line">  <span class="type">Future</span>.sequence(</div><div class="line">    blockManagerInfo.values.map &#123; info =&gt;</div><div class="line">      <span class="keyword">val</span> future =</div><div class="line">        <span class="keyword">if</span> (askSlaves) &#123;</div><div class="line">          info.slaveEndpoint.ask[<span class="type">Seq</span>[<span class="type">BlockId</span>]](getMatchingBlockIds)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="type">Future</span> &#123; info.blocks.asScala.keys.filter(filter).toSeq &#125;</div><div class="line">        &#125;</div><div class="line">      future</div><div class="line">    &#125;</div><div class="line">  ).map(_.flatten.toSeq)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们已经知道BlockManager的具体信息是使用BlockManagerInfo对象来表示的，在BlockManagerInfo中的blocks就存储了BlockId到BlockStatus的映射关系，filter就是对BlockId对象进行过滤，并得到符合条件的BlockId。</p>
<h3 id="RemoveRdd的应答removeRdd"><a href="#RemoveRdd的应答removeRdd" class="headerlink" title="RemoveRdd的应答removeRdd"></a>RemoveRdd的应答removeRdd</h3><p>removeRdd方法是对RemoveRdd事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeRdd</span></span>(rddId: <span class="type">Int</span>): <span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Int</span>]] = &#123;</div><div class="line">  <span class="keyword">val</span> blocks = blockLocations.asScala.keys.flatMap(_.asRDDId).filter(_.rddId == rddId)</div><div class="line">  blocks.foreach &#123; blockId =&gt;</div><div class="line">    <span class="keyword">val</span> bms: mutable.<span class="type">HashSet</span>[<span class="type">BlockManagerId</span>] = blockLocations.get(blockId)</div><div class="line">    bms.foreach(bm =&gt; blockManagerInfo.get(bm).foreach(_.removeBlock(blockId)))</div><div class="line">    blockLocations.remove(blockId)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> removeMsg = <span class="type">RemoveRdd</span>(rddId)</div><div class="line">  <span class="type">Future</span>.sequence(</div><div class="line">    blockManagerInfo.values.map &#123; bm =&gt;</div><div class="line">      bm.slaveEndpoint.ask[<span class="type">Int</span>](removeMsg)</div><div class="line">    &#125;.toSeq</div><div class="line">  )</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们已经blockLocatins中存储的是BlockId到Set[BlockManagerId]的映射关系。一个BlockId是否是RDD，可以通过asRDDId得到，这样就可以得到符合条件的RDD的BlockId。通过BlockId能够得到BlockManagerId的列表，通过blockManagerInfo对象，我们可以得到BlockManagerId所对应的BlockManagerInfo。调用BlockManagerInfo中的removeBlock方法移除对RDD所对应的block的操作（空间使用的记录的释放）。然后告诉所有的BlockManager，要删除RDD（通过BlockManagerInfo中的slaveEndpointRef）。</p>
<h3 id="RemoveShuffle的应答removeShuffle"><a href="#RemoveShuffle的应答removeShuffle" class="headerlink" title="RemoveShuffle的应答removeShuffle"></a>RemoveShuffle的应答removeShuffle</h3><p>removeShuffle方法是对RemoveShuffle事件的应答，其定义如下：<br>·<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeShuffle</span></span>(shuffleId: <span class="type">Int</span>): <span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Boolean</span>]] = &#123;</div><div class="line">  <span class="comment">// Nothing to do in the BlockManagerMasterEndpoint data structures</span></div><div class="line">  <span class="keyword">val</span> removeMsg = <span class="type">RemoveShuffle</span>(shuffleId)</div><div class="line">  <span class="type">Future</span>.sequence(</div><div class="line">    blockManagerInfo.values.map &#123; bm =&gt;</div><div class="line">      bm.slaveEndpoint.ask[<span class="type">Boolean</span>](removeMsg)</div><div class="line">    &#125;.toSeq</div><div class="line">  )</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法的实现和RemoveRdd方法类似，直接对blockManagerInfo中的values（BlockManagerInfo集合）扫描，调用info的rpcEndpointRef，请求移除Shuffle（发送RemoveShuffle事件）。</p>
<h3 id="RemoveBroadcast的响应removeBroadcast"><a href="#RemoveBroadcast的响应removeBroadcast" class="headerlink" title="RemoveBroadcast的响应removeBroadcast"></a>RemoveBroadcast的响应removeBroadcast</h3><p>removeBroadcast方法是对RemoveBroadcast事件的响应，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeBroadcast</span></span>(broadcastId: <span class="type">Long</span>, removeFromDriver: <span class="type">Boolean</span>): <span class="type">Future</span>[<span class="type">Seq</span>[<span class="type">Int</span>]] = &#123;</div><div class="line">  <span class="keyword">val</span> removeMsg = <span class="type">RemoveBroadcast</span>(broadcastId, removeFromDriver)</div><div class="line">  <span class="keyword">val</span> requiredBlockManagers = blockManagerInfo.values.filter &#123; info =&gt;</div><div class="line">    removeFromDriver || !info.blockManagerId.isDriver</div><div class="line">  &#125;</div><div class="line">  <span class="type">Future</span>.sequence(</div><div class="line">    requiredBlockManagers.map &#123; bm =&gt;</div><div class="line">      bm.slaveEndpoint.ask[<span class="type">Int</span>](removeMsg)</div><div class="line">    &#125;.toSeq</div><div class="line">  )</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法的实现与removeShuffle方法类似，直接对BlockManagerInfo中的values(BlockManagerInfo集合)扫描，然后调用info的repEndpointRef，请求移除广播变量。</p>
<h3 id="RemoveBlock的应答removeBlockFromWorkers"><a href="#RemoveBlock的应答removeBlockFromWorkers" class="headerlink" title="RemoveBlock的应答removeBlockFromWorkers"></a>RemoveBlock的应答removeBlockFromWorkers</h3><p>removeBlockFromWorkers方法是对RemoveBlock事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeBlockFromWorkers</span></span>(blockId: <span class="type">BlockId</span>) &#123;</div><div class="line">  <span class="keyword">val</span> locations = blockLocations.get(blockId)</div><div class="line">  <span class="keyword">if</span> (locations != <span class="literal">null</span>) &#123;</div><div class="line">    locations.foreach &#123; blockManagerId: <span class="type">BlockManagerId</span> =&gt;</div><div class="line">      <span class="keyword">val</span> blockManager = blockManagerInfo.get(blockManagerId)</div><div class="line">      <span class="keyword">if</span> (blockManager.isDefined) &#123;</div><div class="line">        <span class="comment">// Remove the block from the slave's BlockManager.</span></div><div class="line">        <span class="comment">// Doesn't actually wait for a confirmation and the message might get lost.</span></div><div class="line">        <span class="comment">// If message loss becomes frequent, we should add retry logic here.</span></div><div class="line">        blockManager.get.slaveEndpoint.ask[<span class="type">Boolean</span>](<span class="type">RemoveBlock</span>(blockId))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法的实现逻辑与removeShuffle方法类似，blockLocations中保存了BlockId到Set[BlockManagerId]的映射关系，能够得到BlockId存放在哪些BlockManager中。blockManagerInfo中保存着BlockManagerId到BlockManagerInfo的映射关系，从BlockManagerInfo中就可以得到slave的RpcEndpointRef，从而用来对slave发送Block移除请求。</p>
<h3 id="RemoveExecutor的应答removeExecutor"><a href="#RemoveExecutor的应答removeExecutor" class="headerlink" title="RemoveExecutor的应答removeExecutor"></a>RemoveExecutor的应答removeExecutor</h3><p>removeExecutor方法是对RemoveExecutor事件的应答，其定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeExecutor</span></span>(execId: <span class="type">String</span>) &#123;</div><div class="line">  logInfo(<span class="string">"Trying to remove executor "</span> + execId + <span class="string">" from BlockManagerMaster."</span>)</div><div class="line">  blockManagerIdByExecutor.get(execId).foreach(removeBlockManager)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>移除Executor所有的Block，blockManagerIdByExecutor中记录executor上的BlockManager，然后调用removeBlockManager方法来移除BlockManager。</p>
<p>removeBlockManager方法的实现<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">removeBlockManager</span></span>(blockManagerId: <span class="type">BlockManagerId</span>) &#123;</div><div class="line">  <span class="keyword">val</span> info = blockManagerInfo(blockManagerId)</div><div class="line"></div><div class="line">  blockManagerIdByExecutor -= blockManagerId.executorId</div><div class="line"></div><div class="line">  blockManagerInfo.remove(blockManagerId)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> iterator = info.blocks.keySet.iterator</div><div class="line">  <span class="keyword">while</span> (iterator.hasNext) &#123;</div><div class="line">    <span class="keyword">val</span> blockId = iterator.next</div><div class="line">    <span class="keyword">val</span> locations = blockLocations.get(blockId)</div><div class="line">    locations -= blockManagerId</div><div class="line">    <span class="keyword">if</span> (locations.size == <span class="number">0</span>) &#123;</div><div class="line">      blockLocations.remove(blockId)</div><div class="line">      logWarning(<span class="string">s"No more replicas available for <span class="subst">$blockId</span> !"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (proactivelyReplicate &amp;&amp; (blockId.isRDD || blockId.isInstanceOf[<span class="type">TestBlockId</span>])) &#123;</div><div class="line">      <span class="keyword">val</span> maxReplicas = locations.size + <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> i = (<span class="keyword">new</span> <span class="type">Random</span>(blockId.hashCode)).nextInt(locations.size)</div><div class="line">      <span class="keyword">val</span> blockLocations = locations.toSeq</div><div class="line">      <span class="keyword">val</span> candidateBMId = blockLocations(i)</div><div class="line">      blockManagerInfo.get(candidateBMId).foreach &#123; bm =&gt;</div><div class="line">        <span class="keyword">val</span> remainingLocations = locations.toSeq.filter(bm =&gt; bm != candidateBMId)</div><div class="line">        <span class="keyword">val</span> replicateMsg = <span class="type">ReplicateBlock</span>(blockId, remainingLocations, maxReplicas)</div><div class="line">        bm.slaveEndpoint.ask[<span class="type">Boolean</span>](replicateMsg)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  listenerBus.post(<span class="type">SparkListenerBlockManagerRemoved</span>(<span class="type">System</span>.currentTimeMillis(), blockManagerId))</div><div class="line">  logInfo(<span class="string">s"Removing block manager <span class="subst">$blockManagerId</span>"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法的逻辑很简单，根据BlockManagerId可以找到对应的BlockManagerInfo，BlockManagerInfo中保存着它所管理的Block列表，在blockLocations中，可以根据BlockId找到Block所分布的BlockManagerId（比如副本的分布）。然后调用分布的BlockManager的RpcEndpointRef，来发送ReplicateBlock事件，确保Block数据的副本数。最后利用listenerBus，广播对应的BlockManagerId已经被移除。</p>
<h3 id="StopBlockManagerMaster的应答"><a href="#StopBlockManagerMaster的应答" class="headerlink" title="StopBlockManagerMaster的应答"></a>StopBlockManagerMaster的应答</h3><p>StopBlockManagerMaster的应答很多简单，返回true，然后直接调用stop方法。</p>
<h3 id="BlockManagerHeartbeat的应答heartbeatReceived"><a href="#BlockManagerHeartbeat的应答heartbeatReceived" class="headerlink" title="BlockManagerHeartbeat的应答heartbeatReceived"></a>BlockManagerHeartbeat的应答heartbeatReceived</h3><p>heartbeatReceived方法用来对BlockManagerHeartbeat事件进行响应，其实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">heartbeatReceived</span></span>(blockManagerId: <span class="type">BlockManagerId</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (!blockManagerInfo.contains(blockManagerId)) &#123;</div><div class="line">    blockManagerId.isDriver &amp;&amp; !isLocal</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    blockManagerInfo(blockManagerId).updateLastSeenMs()</div><div class="line">    <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在每个BlockManagerInfo中有一个变量_lastSeenMs，用来记录BlockManagerInfo的最后的心跳。通过updateLastSeenMs方法更新这个心跳。</p>
<p>通过上面，我就把BlockManagerMasterEndpoint都梳理了一遍，因此我们也了解到，这些操作，都是基于blockId到BlockManagerId的映射关系、BlockManagerId到BlockMangerInfo的映射关系来实现的。其中BlockManagerInfo保存了有关Block的详细信息。因此有必要对BlockManagerInfo进行一下简单的了解。</p>
<h1 id="BlockManagerInfo"><a href="#BlockManagerInfo" class="headerlink" title="BlockManagerInfo"></a>BlockManagerInfo</h1><p>BlockManagerInfo存储了BlockManager的详细信息，如BlockManagerId、最大堆内内存、最大堆外内存、链接BlockManager的rpcEndpointRef、最后心跳时间、最大内存、剩余内存以及BlockManager所管理的BlockId信息。其中管理BlockId信息的集合存储的是BlockId到BlockStatus的映射。<br>其中最重要的方法是removeBlock和updateBlockInfo。这两个方法会影响BlockManager的内存使用和相关Block的映射关系。<br>接下来我们对这两个方法进行分析：</p>
<h2 id="removeBlock-1"><a href="#removeBlock-1" class="headerlink" title="removeBlock"></a>removeBlock</h2><p>removeBlock的定义很简单：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeBlock</span></span>(blockId: <span class="type">BlockId</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (_blocks.containsKey(blockId)) &#123;</div><div class="line">    _remainingMem += _blocks.get(blockId).memSize</div><div class="line">    _blocks.remove(blockId)</div><div class="line">  &#125;</div><div class="line">  _cachedBlocks -= blockId</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>_blocks是BlockId到BlockStatus的映射关系。因此在remove的实现中，就是将指定的BlockId从_blocks中移除，并将BlockId所占用的内存释放。这里没有对Block的实际移除进行操作，应该是slave节点执行删除完成后再调用，更BlockManagerMaster中的信息。</p>
<h2 id="updateBlockInfo-1"><a href="#updateBlockInfo-1" class="headerlink" title="updateBlockInfo"></a>updateBlockInfo</h2><p>updateBlockInfo方法用来更新BlockManagerInfo中对BlockManager的状态，也就是开始说的那些状态。_blocks是BlockId到BlockStatus的映射关系，至于BlockId与BlockManagerId的映射关系，保存在BlockManagerMasterEndpoint中的blockManagerInfo中了。<br>下面是updateBlockInfo的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateBlockInfo</span></span>(</div><div class="line">    blockId: <span class="type">BlockId</span>,</div><div class="line">    storageLevel: <span class="type">StorageLevel</span>,</div><div class="line">    memSize: <span class="type">Long</span>,</div><div class="line">    diskSize: <span class="type">Long</span>) &#123;</div><div class="line"></div><div class="line">  updateLastSeenMs()</div><div class="line"></div><div class="line">  <span class="keyword">val</span> blockExists = _blocks.containsKey(blockId)</div><div class="line">  <span class="keyword">var</span> originalMemSize: <span class="type">Long</span> = <span class="number">0</span></div><div class="line">  <span class="keyword">var</span> originalDiskSize: <span class="type">Long</span> = <span class="number">0</span></div><div class="line">  <span class="keyword">var</span> originalLevel: <span class="type">StorageLevel</span> = <span class="type">StorageLevel</span>.<span class="type">NONE</span></div><div class="line"></div><div class="line">  <span class="keyword">if</span> (blockExists) &#123;</div><div class="line">    <span class="comment">// The block exists on the slave already.</span></div><div class="line">    <span class="keyword">val</span> blockStatus: <span class="type">BlockStatus</span> = _blocks.get(blockId)</div><div class="line">    originalLevel = blockStatus.storageLevel</div><div class="line">    originalMemSize = blockStatus.memSize</div><div class="line">    originalDiskSize = blockStatus.diskSize</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (originalLevel.useMemory) &#123;</div><div class="line">      _remainingMem += originalMemSize</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (storageLevel.isValid) &#123;</div><div class="line">    <span class="comment">/* isValid means it is either stored in-memory or on-disk.</span></div><div class="line">     * The memSize here indicates the data size in or dropped from memory,</div><div class="line">     * externalBlockStoreSize here indicates the data size in or dropped from externalBlockStore,</div><div class="line">     * and the diskSize here indicates the data size in or dropped to disk.</div><div class="line">     * They can be both larger than 0, when a block is dropped from memory to disk.</div><div class="line">     * Therefore, a safe way to set BlockStatus is to set its info in accurate modes. */</div><div class="line">    <span class="keyword">var</span> blockStatus: <span class="type">BlockStatus</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">if</span> (storageLevel.useMemory) &#123;</div><div class="line">      blockStatus = <span class="type">BlockStatus</span>(storageLevel, memSize = memSize, diskSize = <span class="number">0</span>)</div><div class="line">      _blocks.put(blockId, blockStatus)</div><div class="line">      _remainingMem -= memSize</div><div class="line">      <span class="keyword">if</span> (blockExists) &#123;</div><div class="line">        logInfo(<span class="string">s"Updated <span class="subst">$blockId</span> in memory on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span>"</span> +</div><div class="line">          <span class="string">s" (current size: <span class="subst">$&#123;Utils.bytesToString(memSize)&#125;</span>,"</span> +</div><div class="line">          <span class="string">s" original size: <span class="subst">$&#123;Utils.bytesToString(originalMemSize)&#125;</span>,"</span> +</div><div class="line">          <span class="string">s" free: <span class="subst">$&#123;Utils.bytesToString(_remainingMem)&#125;</span>)"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        logInfo(<span class="string">s"Added <span class="subst">$blockId</span> in memory on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span>"</span> +</div><div class="line">          <span class="string">s" (size: <span class="subst">$&#123;Utils.bytesToString(memSize)&#125;</span>,"</span> +</div><div class="line">          <span class="string">s" free: <span class="subst">$&#123;Utils.bytesToString(_remainingMem)&#125;</span>)"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (storageLevel.useDisk) &#123;</div><div class="line">      blockStatus = <span class="type">BlockStatus</span>(storageLevel, memSize = <span class="number">0</span>, diskSize = diskSize)</div><div class="line">      _blocks.put(blockId, blockStatus)</div><div class="line">      <span class="keyword">if</span> (blockExists) &#123;</div><div class="line">        logInfo(<span class="string">s"Updated <span class="subst">$blockId</span> on disk on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span>"</span> +</div><div class="line">          <span class="string">s" (current size: <span class="subst">$&#123;Utils.bytesToString(diskSize)&#125;</span>,"</span> +</div><div class="line">          <span class="string">s" original size: <span class="subst">$&#123;Utils.bytesToString(originalDiskSize)&#125;</span>)"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        logInfo(<span class="string">s"Added <span class="subst">$blockId</span> on disk on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span>"</span> +</div><div class="line">          <span class="string">s" (size: <span class="subst">$&#123;Utils.bytesToString(diskSize)&#125;</span>)"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!blockId.isBroadcast &amp;&amp; blockStatus.isCached) &#123;</div><div class="line">      _cachedBlocks += blockId</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (blockExists) &#123;</div><div class="line">    <span class="comment">// If isValid is not true, drop the block.</span></div><div class="line">    _blocks.remove(blockId)</div><div class="line">    _cachedBlocks -= blockId</div><div class="line">    <span class="keyword">if</span> (originalLevel.useMemory) &#123;</div><div class="line">      logInfo(<span class="string">s"Removed <span class="subst">$blockId</span> on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span> in memory"</span> +</div><div class="line">        <span class="string">s" (size: <span class="subst">$&#123;Utils.bytesToString(originalMemSize)&#125;</span>,"</span> +</div><div class="line">        <span class="string">s" free: <span class="subst">$&#123;Utils.bytesToString(_remainingMem)&#125;</span>)"</span>)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (originalLevel.useDisk) &#123;</div><div class="line">      logInfo(<span class="string">s"Removed <span class="subst">$blockId</span> on <span class="subst">$&#123;blockManagerId.hostPort&#125;</span> on disk"</span> +</div><div class="line">        <span class="string">s" (size: <span class="subst">$&#123;Utils.bytesToString(originalDiskSize)&#125;</span>)"</span>)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>_blocks中保存了BlockId到BlockStatus的映射关系。BlockStatus中包含的信息有：存储级别、使用的内存size和使用的磁盘size。方法首先对心跳时间进行更新，接着获取判断当前BlockManagerInfo中是否已经包含了要更新的BlockId的信息，如果有，将以存在的BlockStatus从BlockManagerInfo中移除（主要是内存，从剩余内存中恢复占用的内存，因为使用更新数据重新计算剩余内存）。然后，判断存储级别是否有效（内存和磁盘级别的存储并且副本数大于0，才认为有效），如果无效，并且blockId以前存在，则说明BlockId改变了存储级别，则将BlockId从BlockManagerInfo中移除，包括_blocks和_cachedBlocks（存储了当前BlockManagerInfo所管理的所有BlockId）；如果存储级别有效，则使用使用新的存储级别、内存size和磁盘size创建一个BlockStatus，然后将BlockStatus存入到_blocks中，对于非广播变量且已经使用了内存或磁盘的BlockId，添加到_cachedBlocks中。<br>总体来说BlockManagerInfo的updateManagerInfo方法就是用新的BlockId的信息来更新BlockManagerInfo中缓存的信息，只是这种更新不是增长式的是替换式的。</p>
<h1 id="BlockManager"><a href="#BlockManager" class="headerlink" title="BlockManager"></a>BlockManager</h1><p>通过上面，我们已经了解到了BlockManagerMaster和BlockManagerMasterEndpoint之间的操作。接下来了解一下另外一部份：BlockManager。<br>BlockManager相较于BlockManagerMaster，它的功能就复杂多了。它会涉及SerializerManager、MemoryManager、MapOutputTracker、ShuffleManager、BlockTransferService、SecurityManager的联合操作。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/04/23/spark-2-11-SparkUiKillJob/" itemprop="url">
                  Spark 2.11 Spark Ui中 Kill Job
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-04-23T11:25:35+08:00" content="2019-04-23">
              2019-04-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文记录在Spark Applications UI中Kill job时的流程，其实也就是cancel Job的流程。</p>
<p>界面点击kill链接，会执行/jobs/job/kill?id=${jobId}。首先看看SparkUI中对于这个链接的注册：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">attachHandler(createRedirectHandler(</div><div class="line">    <span class="string">"/jobs/job/kill"</span>, <span class="string">"/jobs/"</span>, jobsTab.handleKillRequest, httpMethods = <span class="type">Set</span>(<span class="string">"GET"</span>, <span class="string">"POST"</span>)))</div><div class="line">attachHandler(createRedirectHandler(</div><div class="line">    <span class="string">"/stages/stage/kill"</span>, <span class="string">"/stages/"</span>, stagesTab.handleKillRequest, httpMethods = <span class="type">Set</span>(<span class="string">"GET"</span>, <span class="string">"POST"</span>)))</div></pre></td></tr></table></figure></p>
<p>从上面我们可以看出，在点击了/jobs/job/kill链接后，会交由 jobsTab.handleKillRequest来进行响应处理。<br>JobsTab.handleKillRequest方法定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleKillRequest</span></span>(request: <span class="type">HttpServletRequest</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">if</span> (killEnabled &amp;&amp; parent.securityManager.checkModifyPermissions(request.getRemoteUser)) &#123;</div><div class="line">      <span class="comment">// stripXSS is called first to remove suspicious characters used in XSS attacks</span></div><div class="line">      <span class="keyword">val</span> jobId = <span class="type">Option</span>(<span class="type">UIUtils</span>.stripXSS(request.getParameter(<span class="string">"id"</span>))).map(_.toInt)</div><div class="line">      jobId.foreach &#123; id =&gt;</div><div class="line">        <span class="keyword">if</span> (jobProgresslistener.activeJobs.contains(id)) &#123;</div><div class="line">          sc.foreach(_.cancelJob(id))</div><div class="line">          <span class="type">Thread</span>.sleep(<span class="number">100</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上面的代码首先验证用户权限，然后获取job的id，最后调用SparkContext的cancelJob方法来取消Job。<br>在SparkContext中，cancel方法只是简单的调用了DAGScheduler的scancelJob方法。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cancelJob</span></span>(jobId: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  dagScheduler.cancelJob(jobId, <span class="type">None</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>而DAGScheduler的scancelJob方法，只是将一个JobCancelled对象加入到DAGScheduler的eventProcessLoop（具体实现为DAGSchedulerEventProcessLoop对象）队列中。于是我们转到DAGSchedulerEventProcessLoop的doOnReceive方法中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">case</span> <span class="type">JobCancelled</span>(jobId, reason) =&gt;</div><div class="line">      dagScheduler.handleJobCancellation(jobId, reason)</div></pre></td></tr></table></figure>
<p>于是，又将事件交给 DAGScheduler的handleJobCancellation方法处理了。handleJobCancellation的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobCancellation</span></span>(jobId: <span class="type">Int</span>, reason: <span class="type">Option</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="keyword">if</span> (!jobIdToStageIds.contains(jobId)) &#123;</div><div class="line">      logDebug(<span class="string">"Trying to cancel unregistered job "</span> + jobId)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      failJobAndIndependentStages(</div><div class="line">        jobIdToActiveJob(jobId), <span class="string">"Job %d cancelled %s"</span>.format(jobId, reason.getOrElse(<span class="string">""</span>)))</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>方法中，首先会检测jobId是否归属与某个Stage，只有Job归属于某个Stage，才会将job进行处理，调用failJobAndIndependentStages方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">failJobAndIndependentStages</span></span>(</div><div class="line">    job: <span class="type">ActiveJob</span>,</div><div class="line">    failureReason: <span class="type">String</span>,</div><div class="line">    exception: <span class="type">Option</span>[<span class="type">Throwable</span>] = <span class="type">None</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> error = <span class="keyword">new</span> <span class="type">SparkException</span>(failureReason, exception.getOrElse(<span class="literal">null</span>))</div><div class="line">  <span class="keyword">var</span> ableToCancelStages = <span class="literal">true</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> shouldInterruptThread =</div><div class="line">    <span class="keyword">if</span> (job.properties == <span class="literal">null</span>) <span class="literal">false</span></div><div class="line">    <span class="keyword">else</span> job.properties.getProperty(<span class="type">SparkContext</span>.<span class="type">SPARK_JOB_INTERRUPT_ON_CANCEL</span>, <span class="string">"false"</span>).toBoolean</div><div class="line"></div><div class="line">  <span class="comment">// Cancel all independent, running stages.</span></div><div class="line">  <span class="keyword">val</span> stages = jobIdToStageIds(job.jobId)</div><div class="line">  <span class="keyword">if</span> (stages.isEmpty) &#123;</div><div class="line">    logError(<span class="string">"No stages registered for job "</span> + job.jobId)</div><div class="line">  &#125;</div><div class="line">  stages.foreach &#123; stageId =&gt;</div><div class="line">    <span class="keyword">val</span> jobsForStage: <span class="type">Option</span>[<span class="type">HashSet</span>[<span class="type">Int</span>]] = stageIdToStage.get(stageId).map(_.jobIds)</div><div class="line">    <span class="keyword">if</span> (jobsForStage.isEmpty || !jobsForStage.get.contains(job.jobId)) &#123;</div><div class="line">      logError(</div><div class="line">        <span class="string">"Job %d not registered for stage %d even though that stage was registered for the job"</span></div><div class="line">          .format(job.jobId, stageId))</div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (jobsForStage.get.size == <span class="number">1</span>) &#123;</div><div class="line">      <span class="keyword">if</span> (!stageIdToStage.contains(stageId)) &#123;</div><div class="line">        logError(<span class="string">s"Missing Stage for stage with id <span class="subst">$stageId</span>"</span>)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// This is the only job that uses this stage, so fail the stage if it is running.</span></div><div class="line">        <span class="keyword">val</span> stage = stageIdToStage(stageId)</div><div class="line">        <span class="keyword">if</span> (runningStages.contains(stage)) &#123;</div><div class="line">          <span class="keyword">try</span> &#123; <span class="comment">// cancelTasks will fail if a SchedulerBackend does not implement killTask</span></div><div class="line">            taskScheduler.cancelTasks(stageId, shouldInterruptThread)</div><div class="line">            markStageAsFinished(stage, <span class="type">Some</span>(failureReason))</div><div class="line">          &#125; <span class="keyword">catch</span> &#123;</div><div class="line">            <span class="keyword">case</span> e: <span class="type">UnsupportedOperationException</span> =&gt;</div><div class="line">              logInfo(<span class="string">s"Could not cancel tasks for stage <span class="subst">$stageId</span>"</span>, e)</div><div class="line">            ableToCancelStages = <span class="literal">false</span></div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (ableToCancelStages) &#123;</div><div class="line">    <span class="comment">// SPARK-15783 important to cleanup state first, just for tests where we have some asserts</span></div><div class="line">    <span class="comment">// against the state.  Otherwise we have a *little* bit of flakiness in the tests.</span></div><div class="line">    cleanupStateForJobAndIndependentStages(job)</div><div class="line">    job.listener.jobFailed(error)</div><div class="line">    listenerBus.post(<span class="type">SparkListenerJobEnd</span>(job.jobId, clock.getTimeMillis(), <span class="type">JobFailed</span>(error)))</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这块的逻辑大概如下：首先从配置中获取spark.job.interruptOnCancel参数的值，用于决定在cancel task的时候是否要中断线程。然后根据jobId，获取它所处于的Stage。根据Stage的id，调用taskScheduler取消task，并将Stage标记为完成。<br>其中取消task的代码为：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">taskScheduler.cancelTasks(stageId, shouldInterruptThread) <span class="comment">//shouldInterruptThread用于表示是否要中断线程，如果不中断，则使用其他的方式来结束线程。稍后介绍。</span></div></pre></td></tr></table></figure></p>
<p>继续跳转到TaskScheduler的cancelTasks方法，这个方法是抽象方法，具体的实现是由TaskSchedulerImpl来实现的。那么我们看一下 TashSchedulerImpl的cancelTasks方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancelTasks</span></span>(stageId: <span class="type">Int</span>, interruptThread: <span class="type">Boolean</span>): <span class="type">Unit</span> = synchronized &#123;</div><div class="line">    logInfo(<span class="string">"Cancelling stage "</span> + stageId)</div><div class="line">    taskSetsByStageIdAndAttempt.get(stageId).foreach &#123; attempts =&gt;</div><div class="line">      attempts.foreach &#123; <span class="keyword">case</span> (_, tsm) =&gt;</div><div class="line">        <span class="comment">// There are two possible cases here:</span></div><div class="line">        <span class="comment">// 1. The task set manager has been created and some tasks have been scheduled.</span></div><div class="line">        <span class="comment">//    In this case, send a kill signal to the executors to kill the task and then abort</span></div><div class="line">        <span class="comment">//    the stage.</span></div><div class="line">        <span class="comment">// 2. The task set manager has been created but no tasks has been scheduled. In this case,</span></div><div class="line">        <span class="comment">//    simply abort the stage.</span></div><div class="line">        tsm.runningTasksSet.foreach &#123; tid =&gt;</div><div class="line">            taskIdToExecutorId.get(tid).foreach(execId =&gt;</div><div class="line">              backend.killTask(tid, execId, interruptThread, reason = <span class="string">"Stage cancelled"</span>))</div><div class="line">        &#125;</div><div class="line">        tsm.abort(<span class="string">"Stage %s cancelled"</span>.format(stageId))</div><div class="line">        logInfo(<span class="string">"Stage %d was cancelled"</span>.format(stageId))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>cancelTasks的实现逻辑是：根据stageId得到运行task set的TaskSetManager，然后根据TaskSetManager得到正在运行的task集合，根据task的id从taskIdToExecutorId映射关系中得到运行task的Executor的id，这样调用SchedulerBackend的killTask方法，将executorId和taskId作为参数，杀掉task。<br>对于SchedulerBackend的实现，我们在启动executor的时候就知道了，对应的实现为CoarseGrainedSchedulerBackend。<br>CoarseGrainedSchedulerBackend.killTask<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">killTask</span></span>(</div><div class="line">  taskId: <span class="type">Long</span>, executorId: <span class="type">String</span>, interruptThread: <span class="type">Boolean</span>, reason: <span class="type">String</span>) &#123;</div><div class="line">  driverEndpoint.send(<span class="type">KillTask</span>(taskId, executorId, interruptThread, reason))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>于是，就向driver发送了一个 KillTask对象。driver会通过endpoint向executorId所对应的Executor发送kill task的命令。我们跳到Executor中killTask的实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">killTask</span></span>(taskId: <span class="type">Long</span>, interruptThread: <span class="type">Boolean</span>, reason: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> taskRunner = runningTasks.get(taskId)</div><div class="line">  <span class="keyword">if</span> (taskRunner != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="keyword">if</span> (taskReaperEnabled) &#123;</div><div class="line">      <span class="keyword">val</span> maybeNewTaskReaper: <span class="type">Option</span>[<span class="type">TaskReaper</span>] = taskReaperForTask.synchronized &#123;</div><div class="line">        <span class="keyword">val</span> shouldCreateReaper = taskReaperForTask.get(taskId) <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="literal">true</span></div><div class="line">          <span class="keyword">case</span> <span class="type">Some</span>(existingReaper) =&gt; interruptThread &amp;&amp; !existingReaper.interruptThread</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (shouldCreateReaper) &#123;</div><div class="line">          <span class="keyword">val</span> taskReaper = <span class="keyword">new</span> <span class="type">TaskReaper</span>(</div><div class="line">            taskRunner, interruptThread = interruptThread, reason = reason)</div><div class="line">          taskReaperForTask(taskId) = taskReaper</div><div class="line">          <span class="type">Some</span>(taskReaper)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="type">None</span></div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// Execute the TaskReaper from outside of the synchronized block.</span></div><div class="line">      maybeNewTaskReaper.foreach(taskReaperPool.execute)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      taskRunner.kill(interruptThread = interruptThread, reason = reason)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里就是kill task的具体实现，从代码中我们可以知道，kill task有两种逻辑：</p>
<blockquote>
<p>直接调用TaskRunner对象的kill，什么也不操作。<br>除了调用TaskRunner对象的kill，还会使用Reaper对Task进行dump操作。</p>
</blockquote>
<p>如果要是启用Reaper，需要开启spark.task.reaper.enabled参数。</p>
<p>对于Reaper的实现逻辑：调用TaskRunner的kill，然后对Task对应的线程进行dump操作。关于reaper还有好几个参数，用来定义Reaper的逻辑：</p>
<p>直接调用TaskRunner的kill，就是不进行Reaper监控。而且我们也知道了，使用Reaper进行监控，其内部也会调用TaskRunner的kill，所以下面我们进行TaskRunner.kill方法的逻辑分析：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kill</span></span>(interruptThread: <span class="type">Boolean</span>, reason: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  logInfo(<span class="string">s"Executor is trying to kill <span class="subst">$taskName</span> (TID <span class="subst">$taskId</span>), reason: <span class="subst">$reason</span>"</span>)</div><div class="line">  reasonIfKilled = <span class="type">Some</span>(reason)</div><div class="line">  <span class="keyword">if</span> (task != <span class="literal">null</span>) &#123;</div><div class="line">    synchronized &#123;</div><div class="line">      <span class="keyword">if</span> (!finished) &#123;</div><div class="line">        task.kill(interruptThread, reason)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>TaskRunner中保存着Task的引用，调用Task的kill方法。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kill</span></span>(interruptThread: <span class="type">Boolean</span>, reason: <span class="type">String</span>) &#123;</div><div class="line">  require(reason != <span class="literal">null</span>)</div><div class="line">  _reasonIfKilled = reason</div><div class="line">  <span class="keyword">if</span> (context != <span class="literal">null</span>) &#123;</div><div class="line">    context.markInterrupted(reason)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (interruptThread &amp;&amp; taskThread != <span class="literal">null</span>) &#123;</div><div class="line">    taskThread.interrupt()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里有三个逻辑：</p>
<blockquote>
<p>设置_reasonIfKilled，如果Task还没有运行，设置了这个值后，task运行时会直接退出。一旦task运行了，设置这个值是不会停止的，因此需要第二个方式。<br>设置context.markInterrupted(reason)，一旦Task运行了，就会在其内部构建一个TaskContext，调用这个方法，进行状态标记。在执行RDD中数据读取（调用InterruptibleIterator的next方法）的时候会调用TaskContext的killTaskIfInterrupted方法进行中断验证，如果已经调用过markInterrupted方法，killTaskIfInterrupted方法就会抛出异常，终止Task的运行。<br>参数指定要中断线程，直接执行线程中断。</p>
</blockquote>
<p>这里在附加一下InterruptibleIterator的实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">InterruptibleIterator</span>[+<span class="type">T</span>](<span class="params">val context: <span class="type">TaskContext</span>, val delegate: <span class="type">Iterator</span>[<span class="type">T</span>]</span>)</span></div><div class="line">  <span class="keyword">extends</span> <span class="type">Iterator</span>[<span class="type">T</span>] &#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = &#123;</div><div class="line">    context.killTaskIfInterrupted()</div><div class="line">    delegate.hasNext</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">T</span> = delegate.next()</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其实就是对dlegate所指定的Iterator进行了一层包装。查找InterruptibleIterator的使用，RDD的getOrCompute方法返回的Iterator就是InterruptibleIterator类型。<br>我们知道Task读取数据时，就会用到RDD的getOrCompute方法，因此就可以让task中断啦。对于InterruptibleIterator的使用，不只是RDD，还有BlockStoreShuffleReader、NewHadoopRDD等都在使用。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/02/19/spark-2-11-submit/" itemprop="url">
                  Spark 2.11 Submit的流程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-02-19T19:02:07+08:00" content="2019-02-19">
              2019-02-19
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用于整理在使用spark-submit提交任务的流程</p>
<h1 id="spark-submit脚本的定义"><a href="#spark-submit脚本的定义" class="headerlink" title="spark-submit脚本的定义"></a>spark-submit脚本的定义</h1><p>使用spark-submit提交任务的时候，实际上调用的是${SPARK_HOME}/bin/spark-submit来提交的。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit \</div><div class="line">  --class &lt;main-class&gt; \</div><div class="line">  --master &lt;master-url&gt; \</div><div class="line">  --deploy-mode &lt;deploy-mode&gt; \</div><div class="line">  --conf &lt;key&gt;=&lt;value&gt; \</div><div class="line">  ... # other options</div><div class="line">  &lt;application-jar&gt; \</div><div class="line">  [application-arguments]</div></pre></td></tr></table></figure></p>
<p>如下是${SPARK_HOME}/bin/spark-submit脚本的定义：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">exec &quot;$&#123;SPARK_HOME&#125;&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;$@&quot;</div></pre></td></tr></table></figure></p>
<p>从代码可以看出，实际上执行的是 org.apache.spark.deploy.SparkSubmit类。因此我们具体看看这个类的实现。</p>
<h1 id="SparkSubmit的启动流程"><a href="#SparkSubmit的启动流程" class="headerlink" title="SparkSubmit的启动流程"></a>SparkSubmit的启动流程</h1><p>如下是SparkSubmit主函数的定义：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> appArgs = <span class="keyword">new</span> <span class="type">SparkSubmitArguments</span>(args)</div><div class="line">  <span class="keyword">if</span> (appArgs.verbose) &#123;</div><div class="line">    <span class="comment">// scalastyle:off println</span></div><div class="line">    printStream.println(appArgs)</div><div class="line">    <span class="comment">// scalastyle:on println</span></div><div class="line">  &#125;</div><div class="line">  appArgs.action <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs)</div><div class="line">    <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)</div><div class="line">    <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>进入主函数后，会使用SparkSubmitArguments类对SparkSubmit的命令行参数进行解析。然后根据参数中的action信息进行具体的操作。<br>由此也可以看出，SparkSubmit支持三种action：–submit、–kill和–status。</p>
<h2 id="SparkSubmitArguments"><a href="#SparkSubmitArguments" class="headerlink" title="SparkSubmitArguments"></a>SparkSubmitArguments</h2><h3 id="SparkSubmitArgument的继承关系"><a href="#SparkSubmitArgument的继承关系" class="headerlink" title="SparkSubmitArgument的继承关系"></a>SparkSubmitArgument的继承关系</h3><p><img src="/attach/5c6bb98cb92e4.png" alt="image.png"><br>其中SparkSubmitArgumentsParser是没有具体实现，SparkSubmitOptionParser主要用来解析option。</p>
<h3 id="SparkSubmitArguments实例化执行"><a href="#SparkSubmitArguments实例化执行" class="headerlink" title="SparkSubmitArguments实例化执行"></a>SparkSubmitArguments实例化执行</h3><p>在SparkSubmit中会利用main的参数生成一个SparkSubmitArguments的，生成SparkSubmitArguments对象的时候就会执行如下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  parse(args.asJava)</div><div class="line">&#125; <span class="keyword">catch</span> &#123;</div><div class="line">  <span class="keyword">case</span> e: <span class="type">IllegalArgumentException</span> =&gt;</div><div class="line">    <span class="type">SparkSubmit</span>.printErrorAndExit(e.getMessage())</div><div class="line">&#125;</div><div class="line"><span class="comment">// Populate `sparkProperties` map from properties file</span></div><div class="line">mergeDefaultSparkProperties()</div><div class="line"><span class="comment">// Remove keys that don't start with "spark." from `sparkProperties`.</span></div><div class="line">ignoreNonSparkProperties()</div><div class="line"><span class="comment">// Use `sparkProperties` map along with env vars to fill in any missing parameters</span></div><div class="line">loadEnvironmentArguments()</div><div class="line"></div><div class="line">validateArguments()</div></pre></td></tr></table></figure></p>
<p>首先调用的是parse方法，而SparkSubmitArguments本身是没有这个方法的，但是它会从父类SparkSubmitOptionParser那里继承，因此调用的父类的parse方法。</p>
<h4 id="SparkSubmitOptionParser"><a href="#SparkSubmitOptionParser" class="headerlink" title="SparkSubmitOptionParser"></a>SparkSubmitOptionParser</h4><p>SparkSbumitOptionParser用来解析命令行提供的参数，从SparkSubmitOptionParser中我们可以看出，可以使用的参数列表如下：</p>
<h5 id="标准参数"><a href="#标准参数" class="headerlink" title="标准参数"></a>标准参数</h5><table>
<thead>
<tr>
<th>option的定义</th>
<th>意义</th>
<th>例如</th>
</tr>
</thead>
<tbody>
<tr>
<td>–class</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–conf</td>
<td>‘’，可以使用“-c”来代替</td>
<td>–</td>
</tr>
<tr>
<td>–deploy-mode</td>
<td>部署模式，有两种模式：client和cluster</td>
<td>–</td>
</tr>
<tr>
<td>–driver-class-path</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–driver-cores</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–driver-java-options</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–driver-library-path</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–driver-memory</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–executor-memory</td>
<td>执行application的内存大小</td>
<td>–</td>
</tr>
<tr>
<td>–jars</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–kill</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–master</td>
<td>‘’</td>
<td>–master yarn-client</td>
</tr>
<tr>
<td>–name</td>
<td>提交的application的名字</td>
<td>–name spark_thrift_server_test</td>
</tr>
<tr>
<td>–packages</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–exclude-packages</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–properties-file</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–proxy-user</td>
<td>提交任务所用的代理用户</td>
<td>–proxy-user myUser</td>
</tr>
<tr>
<td>–py-files</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–repositories</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–status</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–total-executor-cores</td>
<td>执行application的最大executor的数量</td>
<td>–total-executor-cores 20</td>
</tr>
</tbody>
</table>
<h5 id="标识型参数。"><a href="#标识型参数。" class="headerlink" title="标识型参数。"></a>标识型参数。</h5><p>这些option只会作为检测，不会取值。<br>|option的定义|意义|例如|<br>|-|-|-|<br>|–help|‘’，可以使用“-h”代替|–|<br>|–supervise|‘’|–|<br>|–usage-error|‘’|–|<br>|–verbose|‘’，可以使用“-v”代替|–|<br>|–version|‘’|–|</p>
<h5 id="Yarn独享参数"><a href="#Yarn独享参数" class="headerlink" title="Yarn独享参数"></a>Yarn独享参数</h5><table>
<thead>
<tr>
<th>option的定义</th>
<th>意义</th>
<th>例如</th>
</tr>
</thead>
<tbody>
<tr>
<td>–archives</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–executor-cores</td>
<td>执行任务的executor的core的数量</td>
<td>–executor-cores 3</td>
</tr>
<tr>
<td>–keytab</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–num-executors</td>
<td>执行任务的executor的个数</td>
<td>–num-executors 10</td>
</tr>
<tr>
<td>–principal</td>
<td>‘’</td>
<td>–</td>
</tr>
<tr>
<td>–queue</td>
<td>执行任务的资源队列</td>
<td>–queue test_queue</td>
</tr>
</tbody>
</table>
<h5 id="option的定义和解析"><a href="#option的定义和解析" class="headerlink" title="option的定义和解析"></a>option的定义和解析</h5><h6 id="非标识型参数"><a href="#非标识型参数" class="headerlink" title="非标识型参数"></a>非标识型参数</h6><p>parse方法，实现了对命令行参数的解析。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Pattern eqSeparatedOpt = Pattern.compile(<span class="string">"(--[^=]+)=(.+)"</span>);</div></pre></td></tr></table></figure></p>
<p>定义了获取参数的模式，必须以“–”开头，然后是不能为“=”的任意字符，接着是“=”号，最后是任意字符，例如：–name=testName。<br>但是这也不是必须的格式，在解析参数的代码中还包含了另外一种逻辑：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Matcher m = eqSeparatedOpt.matcher(arg);</div><div class="line"></div><div class="line"><span class="keyword">if</span> (m.matches()) &#123;</div><div class="line">  arg = m.group(<span class="number">1</span>);</div><div class="line">  value = m.group(<span class="number">2</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Look for options with a value.</span></div><div class="line">String name = findCliOption(arg, opts);</div><div class="line"><span class="keyword">if</span> (name != <span class="keyword">null</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</div><div class="line">    <span class="keyword">if</span> (idx == args.size() - <span class="number">1</span>) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</div><div class="line">        String.format(<span class="string">"Missing argument for option '%s'."</span>, arg));</div><div class="line">    &#125;</div><div class="line">    idx++;</div><div class="line">    value = args.get(idx);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (!handle(name, value)) &#123;</div><div class="line">    <span class="keyword">break</span>;</div><div class="line">  &#125;</div><div class="line"><span class="keyword">continue</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以第一个参数为key，第二个参数为value。<br>也就是说命令行参数中包含的参数，要么是key=value的格式，要么是key value的模式。也可以是两种格式的组合，但是必须要保证key value的匹配，如果key key=value，那么后面的这个key=value将会作为前面key的value来解析。另外，如果参数的最后一个为key，还会抛出IllegalArgumentException异常。<br>如下传递是正确的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">key1 value1 key2=value2 key3 value3</div></pre></td></tr></table></figure></p>
<p>如下传递是错误的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">key1 key2=value2  -- 会把key2=value2当做key1的value</div><div class="line">key1=value2 key2  -- 抛出IllegalArgumentException，无法获取key2的value</div></pre></td></tr></table></figure></p>
<p>还有一个需要注意的是，如果提供了不在上面列表中的参数，会抛出UnsupportedOperationException异常，并退出程序的执行。</p>
<h5 id="标识型参数"><a href="#标识型参数" class="headerlink" title="标识型参数"></a>标识型参数</h5><p>标志性参数只会检测这个参数是否存在，不会从命令行中读取值。</p>
<h5 id="参数的处理"><a href="#参数的处理" class="headerlink" title="参数的处理"></a>参数的处理</h5><p>上面参数解析后，就会得到key和value。然后调用handle方法做进一步处理。SparkSubmitOptionParser要求子类必须实现handle方法，如果子类未实现handle方法，就会调用自身的handle方法，从而抛出UnsupportedOperationException异常。因此，我们看一下子类SplarkSubmitArguments的handle方法。</p>
<h5 id="SparkSubmitArgumnet-handle"><a href="#SparkSubmitArgumnet-handle" class="headerlink" title="SparkSubmitArgumnet.handle"></a>SparkSubmitArgumnet.handle</h5><p>方法逻辑很简单，就是检测上面的key是否合法（规定的），如果合法，就设置相应属性的值。如下是合法参数名的值，以及value存储对应SparkSubmitArgumengt中变量，以及value的合法性要求：<br>|key的定义|value的存储变量|value的合法性要求|<br>|-|-|-|<br>|–name|name|-|<br>|–master|master|-|<br>|–class|mainClass|-|<br>|–deploy-mode|deployMode|client或cluster|<br>|–num-executors|numExecutors|-|<br>|–total-executor-cores|totalExecutorCores|-|<br>|–executor-cores|executorCores|-|<br>|–executor-memory|executorMemory|-|<br>|–driver-memory|driverMemory|-|<br>|–driver-cores|driverCores|-|<br>|–driver-class-path|driverExtraClassPath|-|<br>|–driver-java-options|driverExtraJavaOptions|-|<br>|–driver-library-path|driverExtraLibraryPath|-|<br>|–properties-file|propertiesFile|-|<br>|–kill|value保存在submissionToKill中，同时设置action = KILL|-|<br>|–status|value保存在submissionToRequestStatusFor中，同时设置action = REQUEST_STATUS|-|<br>|–supervise|设置supervise=true|-|<br>|–queue|queue|-|<br>|–files|files|-|<br>|–py-files|pyFiles|-|<br>|–archives|archives|-|<br>|–jars|jars|-|<br>|–packages|packages|-|<br>|–exclude-packages|packagesExclusions|-|<br>|–repositories|repositories|-|<br>|–conf或-c|解析properties文件后保存在sparkProperties中|-|<br>|–proxy-user|proxyUser|-|<br>|–principal|principal|-|<br>|–keytab|keytab|-|<br>|–help|执行printUsageAndExit(0)，打印用法并退出|-|<br>|–verbose|设置verbose为true|-|<br>|–version|调用printVersionAndExit()方法，打印版本并退出|-|<br>|–usage-error|执行printUsageAndExit(1)，打印用法并退出|-|</p>
<h3 id="参数的解析流程"><a href="#参数的解析流程" class="headerlink" title="参数的解析流程"></a>参数的解析流程</h3><p>parse方法定义在SparkSubmitOptionParser类中，用于解析命令行传递过来的参数。参考上面的“option的定义和解析”部分。</p>
<h4 id="合并默认的Spark属性"><a href="#合并默认的Spark属性" class="headerlink" title="合并默认的Spark属性"></a>合并默认的Spark属性</h4><p>合并默认的Spark属性，调用的是mergeDefaultSparkProperties方法。<br>该方法将会从两个位置读取配置文件：</p>
<blockquote>
<p>命令行中-–properties-file参数指定的属性文件。<br>SPARK_CONF_DIR目录或SPARK_HOME/conf下的spark-default.properties文件</p>
</blockquote>
<p>其中优先使用–properties-file参数所指定的文件。<br>根据这里确定的属性文件，将属性加载到内存中作为默认属性与命令行中使用–conf或–c配置的属性进行合并，优先使用–conf或–c指定的属性。</p>
<h4 id="驳回非Spark属性"><a href="#驳回非Spark属性" class="headerlink" title="驳回非Spark属性"></a>驳回非Spark属性</h4><p>什么属于非Spark属性呢？就是那些不以“spark”开头的属性。将上面合并后的属性进行遍历，将不是以“spark”开头的属性，从属性集合中移除。</p>
<h4 id="加载环境参数"><a href="#加载环境参数" class="headerlink" title="加载环境参数"></a>加载环境参数</h4><p>加载环境参数的意思就是对于那些通过上面操作，依然没有被设置的属性，从环境配置中再加在一次。基本上的思路就是判断属性是否已经有值，如果没有则从上面的属性中加在一次，如果还没有则再从环境中加在一次。所以参数的优先级如下：命令行中指定 -&gt; 属性中配置(–conf-&gt; –properties-file -&gt; spark_home/conf/spark-default.properties) -&gt; 环境</p>
<table>
<thead>
<tr>
<th>变量</th>
<th>属性中的配置项</th>
<th>环境中的配置项</th>
</tr>
</thead>
<tbody>
<tr>
<td>master</td>
<td>spark.master</td>
<td>MASTER</td>
</tr>
<tr>
<td>driverExtraClassPath</td>
<td>spark.driver.extraClassPath</td>
<td>Null</td>
</tr>
<tr>
<td>driverExtraJavaOptions</td>
<td>spark.driver.extraJavaOptions</td>
<td>Null</td>
</tr>
<tr>
<td>driverExtraLibraryPath</td>
<td>spark.driver.extraLibraryPath</td>
<td>Null</td>
</tr>
<tr>
<td>driverMemory</td>
<td>spark.driver.memory</td>
<td>SPARK_DRIVER_MEMORY</td>
</tr>
<tr>
<td>driverCores</td>
<td>spark.driver.cores</td>
<td>Null</td>
</tr>
<tr>
<td>executorMemory</td>
<td>spark.executor.memory</td>
<td>SPARK_EXECUTOR_MEMORY</td>
</tr>
<tr>
<td>executorCores</td>
<td>spark.executor.cores</td>
<td>SPARK_EXECUTOR_CORES</td>
</tr>
<tr>
<td>totalExecutorCores</td>
<td>spark.cores.max</td>
<td>Null</td>
</tr>
<tr>
<td>name</td>
<td>spark.app.name</td>
<td>Null</td>
</tr>
<tr>
<td>jars</td>
<td>spark.jars</td>
<td>Null</td>
</tr>
<tr>
<td>files</td>
<td>spark.files</td>
<td>Null</td>
</tr>
<tr>
<td>ivyRepoPath(新增)</td>
<td>spark.jars.ivy</td>
<td>Null</td>
</tr>
<tr>
<td>packages</td>
<td>spark.jars.packages</td>
<td>Null</td>
</tr>
<tr>
<td>packagesExclusions</td>
<td>spark.jars.excludes</td>
<td>Null</td>
</tr>
<tr>
<td>deployMode</td>
<td>spark.submit.deployMode</td>
<td>DEPLOY_MODE</td>
</tr>
<tr>
<td>numExecutors</td>
<td>spark.executor.instances</td>
<td>Null</td>
</tr>
<tr>
<td>queue</td>
<td>spark.yarn.queue</td>
<td>Null</td>
</tr>
<tr>
<td>keytab</td>
<td>spark.yarn.keytab</td>
<td>Null</td>
</tr>
<tr>
<td>principal</td>
<td>spark.yarn.principal</td>
<td>Null</td>
</tr>
</tbody>
</table>
<p>基本的设置就是以上这些，但是除了这些，还有其他一些逻辑：</p>
<h5 id="主类的确定"><a href="#主类的确定" class="headerlink" title="主类的确定"></a>主类的确定</h5><p>当没有通过mainClass指定主类，且不是python或R时，会从jar包中读取主类：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (mainClass == <span class="literal">null</span> &amp;&amp; !isPython &amp;&amp; !isR &amp;&amp; primaryResource != <span class="literal">null</span>) &#123;</div><div class="line">  <span class="keyword">val</span> uri = <span class="keyword">new</span> <span class="type">URI</span>(primaryResource)</div><div class="line">  <span class="keyword">val</span> uriScheme = uri.getScheme()</div><div class="line"></div><div class="line">  uriScheme <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="string">"file"</span> =&gt;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">val</span> jar = <span class="keyword">new</span> <span class="type">JarFile</span>(uri.getPath)</div><div class="line">        <span class="comment">// Note that this might still return null if no main-class is set; we catch that later</span></div><div class="line">        mainClass = jar.getManifest.getMainAttributes.getValue(<span class="string">"Main-Class"</span>)</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">          <span class="type">SparkSubmit</span>.printErrorAndExit(<span class="string">s"Cannot load main class from JAR <span class="subst">$primaryResource</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    <span class="keyword">case</span> _ =&gt;</div><div class="line">      <span class="type">SparkSubmit</span>.printErrorAndExit(</div><div class="line">        <span class="string">s"Cannot load main class from JAR <span class="subst">$primaryResource</span> with URI <span class="subst">$uriScheme</span>. "</span> +</div><div class="line">        <span class="string">"Please specify a class through --class."</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h5 id="master的确定"><a href="#master的确定" class="headerlink" title="master的确定"></a>master的确定</h5><p>如果没有设置master，则将master设置为local[*]</p>
<h5 id="name的确定"><a href="#name的确定" class="headerlink" title="name的确定"></a>name的确定</h5><p>如果master是以“yarn”开头的，则使用当前的name，如果没有设置，则从环境变量SPARK_YARN_APP_NAME中获取；如果环境中也没有，则从主类中获取，如果主类中也没有，则从primaryResource中获取。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (master.startsWith(<span class="string">"yarn"</span>)) &#123;</div><div class="line">  name = <span class="type">Option</span>(name).orElse(env.get(<span class="string">"SPARK_YARN_APP_NAME"</span>)).orNull</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Set name from main class if not given</span></div><div class="line">name = <span class="type">Option</span>(name).orElse(<span class="type">Option</span>(mainClass)).orNull</div><div class="line"><span class="keyword">if</span> (name == <span class="literal">null</span> &amp;&amp; primaryResource != <span class="literal">null</span>) &#123;</div><div class="line">  name = <span class="type">Utils</span>.stripDirectory(primaryResource)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h5 id="action的确定"><a href="#action的确定" class="headerlink" title="action的确定"></a>action的确定</h5><p>如果没有设置action，则将action默认设置为submit。</p>
<h4 id="验证参数"><a href="#验证参数" class="headerlink" title="验证参数"></a>验证参数</h4><p>验证参数是要根据action，进行区分验证，不同的action有不同的参数要求。</p>
<h5 id="submit"><a href="#submit" class="headerlink" title="submit"></a>submit</h5><p>对于提交参数的验证，要求如下</p>
<blockquote>
<p>必须指定主要资源：也就是说jar、python或R不能同时为空。<br>主类必须通过–class指定或者在Jar中包含。<br>如果指定了pyFile，则要求主资源必须是Python脚本。<br>如果master是yarn，则要求环境变量中必须包含HADOOP_CONF_DIR或YARN_CONF_DIR<br>配置中不能同时存在 proxyUser和principal。</p>
</blockquote>
<p>为什么proxyUser和principal不能同时存在呢？因为这是两种不同的认证方式，只能使用一种。对于proxyUser方式，会调用Hadoop的相关API创建代理用户，然后用代理用户执行runMain方法。如果设置了principal，就必须设置–keytab来指定keytab文件，然后会使用keytab信息进行登录。</p>
<h5 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h5><p>对于kill参数的验证，要求如下</p>
<blockquote>
<p>master必须是以spark://或mesos://开头的，其他的不支持kill<br>submissionToKill必须指定，也就是必须指定要kill的submission。</p>
</blockquote>
<h5 id="status"><a href="#status" class="headerlink" title="status"></a>status</h5><p>对于请求状态的验证，要求如下</p>
<blockquote>
<p>master必须是以spark://或mesos://开头的，其他的不支持status查询<br>submissionToRequestStatusFor必须指定，也就是必须说明要查询状态的信息。</p>
</blockquote>
<p>至此SparkSubmitArguments对参数的加载（从命令行、配置文件、环境变量）和验证就完成。我们继续回到SparkSubmit中。</p>
<h2 id="Spark-Submit"><a href="#Spark-Submit" class="headerlink" title="Spark Submit"></a>Spark Submit</h2><p>我们已经知道SparkSubmit类支持三种action，现在我们先看看当action为submit时的相关操作。<br>用来处理action为“submit”的是submit方法，在submit方法中，大体分为三个步骤：提交环境准备、根据代理用户进行操作、根据部署模式进行操作。<br>对于代理用户的相关操作，就是判断是否指定了代理用户，如果指定了代理用户，则使用代理用户的身份执行runMain，如果没有指定代理用户，则直接执行runMain（相当于使用当前用户）。<br>对于部署模式的相关操作，基本上都是调用doRunMain方法，只是对于standalone模式下，如果出现异常会做一些其他操作。doRunMain方法，就是根据代理用户进行操作。<br>所以，这里会将主要任务落到两个方法上：runMain和prepareSubmitEnvironment。</p>
<h3 id="prepareSubmitEnvironment"><a href="#prepareSubmitEnvironment" class="headerlink" title="prepareSubmitEnvironment"></a>prepareSubmitEnvironment</h3><p>提交前会进行环境的准备，环境准备通过prepareSubmitEnvironment方法实现。该方法的代码量很大，但是基本上就是验证参数的正确性、参数的合法性、某些未写参数的补充、以及执行类的确定。<br>这里需要注意下参数的变换，我们上面已经知道配置参数可以通过命令行、命令行的配置文件、默认配置文件和环境变量中得到。这里再生成下一个主类使用的参数时，参数只会包含三个类型：–class、–jar、–arg（对于python会包含–primary-py-file，对于R会包含–primary-r-file）。所以那些属性会作为–arg进行提供。</p>
<h3 id="runMain"><a href="#runMain" class="headerlink" title="runMain"></a>runMain</h3><p>runMain就是使用prepareSubmitEnvironment确定的环境变量和属性来执行prepareSubmitEnvironment中确定的主类，直接执行主类的main方法。</p>
<p>例如，对于Yarn集群模式，执行的就是org.apache.spark.deploy.yarn.Client。</p>
<h1 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h1><h2 id="Client-submitApplication"><a href="#Client-submitApplication" class="headerlink" title="Client.submitApplication"></a>Client.submitApplication</h2><p>org.apache.spark.deploy.yarn.Client类中submitApplication方法实现了application的提交逻辑，基本流程如图：<br><img src="/attach/5c75fccb59b23.png" alt="image.png"></p>
<h3 id="创建证书"><a href="#创建证书" class="headerlink" title="创建证书"></a>创建证书</h3><p>创建证书是通过setupCredentials方法实现的，其定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">setupCredentials</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="comment">// 判断是否是使用Kerberos进行登录，如果配置中设置了principal就表示使用kerberos，而且要求配置了Keytab信息</span></div><div class="line">  loginFromKeytab = sparkConf.contains(<span class="type">PRINCIPAL</span>.key)</div><div class="line">  <span class="keyword">if</span> (loginFromKeytab) &#123;</div><div class="line">    principal = sparkConf.get(<span class="type">PRINCIPAL</span>).get</div><div class="line">    keytab = sparkConf.get(<span class="type">KEYTAB</span>).orNull</div><div class="line"></div><div class="line">    require(keytab != <span class="literal">null</span>, <span class="string">"Keytab must be specified when principal is specified."</span>)</div><div class="line">    <span class="comment">// 加载Keytab文件，并对文件名</span></div><div class="line">    <span class="keyword">val</span> f = <span class="keyword">new</span> <span class="type">File</span>(keytab)</div><div class="line">    amKeytabFileName = f.getName + <span class="string">"-"</span> + <span class="type">UUID</span>.randomUUID().toString</div><div class="line">    sparkConf.set(<span class="type">PRINCIPAL</span>.key, principal)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 创建当前用户的证书的拷贝</span></div><div class="line">  credentials = <span class="keyword">new</span> <span class="type">Credentials</span>(<span class="type">UserGroupInformation</span>.getCurrentUser.getCredentials)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="创建yarnClient并创建Application"><a href="#创建yarnClient并创建Application" class="headerlink" title="创建yarnClient并创建Application"></a>创建yarnClient并创建Application</h3><p>submitApplication方法在设置完证书后，就会使用yarnClient来创建Application，并得到Applcation的相关信息（包括application id、application submission context等）以供后面使用，其代码实现如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 初始化yarnClient，并启动</span></div><div class="line">yarnClient.init(yarnConf)</div><div class="line">yarnClient.start()</div><div class="line"></div><div class="line">logInfo(<span class="string">"Requesting a new application from cluster with %d NodeManagers"</span></div><div class="line">        .format(yarnClient.getYarnClusterMetrics.getNumNodeManagers))</div><div class="line"></div><div class="line"><span class="comment">// 并得到新application的响应信息，并从响应信息中得到application的id</span></div><div class="line"><span class="keyword">val</span> newApp = yarnClient.createApplication()</div><div class="line"><span class="keyword">val</span> newAppResponse = newApp.getNewApplicationResponse()</div><div class="line">appId = newAppResponse.getApplicationId()</div></pre></td></tr></table></figure></p>
<h3 id="资源验证"><a href="#资源验证" class="headerlink" title="资源验证"></a>资源验证</h3><p>资源验证的目的就是检查Yarn集群中是否有足够的内存来运行Application Master，该功能通过verifyClusterResources方法来实现，AM所需的内存资源为内存和负载内存之和。<br>对于内存和负载内存的配置值，会根据集群模式的不同而取值不同。<br>对于集群模式，会从spark.driver.memory和spark.yarn.driver.memoryOverhead配置中读取，对于非集群模式，则会从spark.yarn.am.memory和spark.yarn.am.memoryOverhead中读取。<br>如果没有设置负载内存，负载内存还有一个推算公式：max((0.10 * 内存), 384L)</p>
<h3 id="创建Container启动上下文"><a href="#创建Container启动上下文" class="headerlink" title="创建Container启动上下文"></a>创建Container启动上下文</h3><p>创建Container启动上下文是通过createContainerLaunchContext方法实现。对于这个方法，其功能大致分为三个部分：启动环境准备、资源准备和启动命令的拼接。</p>
<h4 id="启动环境准备"><a href="#启动环境准备" class="headerlink" title="启动环境准备"></a>启动环境准备</h4><p>启动环境的准备是通过setupLaunchEnv方法实现的。 – 以后补充</p>
<h4 id="资源准备"><a href="#资源准备" class="headerlink" title="资源准备"></a>资源准备</h4><p>资源的准备是通过prepareLocalResources方法实现的。下面将详细介绍这个方法。</p>
<h5 id="证书的管理"><a href="#证书的管理" class="headerlink" title="证书的管理"></a>证书的管理</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 从证书管理器那里获得证书下一次更新的时间</span></div><div class="line"><span class="keyword">val</span> nearestTimeOfNextRenewal = credentialManager.obtainCredentials(hadoopConf, credentials)</div><div class="line"></div><div class="line"><span class="comment">// 如果已经有证书了，则将证书设置给当前用户</span></div><div class="line"><span class="keyword">if</span> (credentials != <span class="literal">null</span>) &#123;</div><div class="line">  <span class="type">UserGroupInformation</span>.getCurrentUser.addCredentials(credentials)</div><div class="line">  logDebug(<span class="type">YarnSparkHadoopUtil</span>.get.dumpTokens(credentials).mkString(<span class="string">"\n"</span>))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 如果我们使用principal和keytab登录，那么证书需要在之后的时间被重新构建，我们应当将下一次的重构和更新时间传递给构建者和更新者</span></div><div class="line"><span class="keyword">if</span> (loginFromKeytab &amp;&amp; nearestTimeOfNextRenewal &gt; <span class="type">System</span>.currentTimeMillis() &amp;&amp;</div><div class="line">  nearestTimeOfNextRenewal != <span class="type">Long</span>.<span class="type">MaxValue</span>) &#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> currTime = <span class="type">System</span>.currentTimeMillis()</div><div class="line">  <span class="keyword">val</span> renewalTime = (nearestTimeOfNextRenewal - currTime) * <span class="number">0.75</span> + currTime</div><div class="line">  <span class="keyword">val</span> updateTime = (nearestTimeOfNextRenewal - currTime) * <span class="number">0.8</span> + currTime</div><div class="line"></div><div class="line">  sparkConf.set(<span class="type">CREDENTIALS_RENEWAL_TIME</span>, renewalTime.toLong)</div><div class="line">  sparkConf.set(<span class="type">CREDENTIALS_UPDATE_TIME</span>, updateTime.toLong)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>证书管理的功能就是：如果证书存在，将证书添加到当前用户中；根据时间设置证书的重新生成时间和更新时间。</p>
<h5 id="资源添加和验证"><a href="#资源添加和验证" class="headerlink" title="资源添加和验证"></a>资源添加和验证</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 用于保存添加到分发缓存的URI列表，如果同一个URI被添加多次，YARN将以内部错误使container启动失败</span></div><div class="line"><span class="keyword">val</span> distributedUris = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]</div><div class="line"><span class="comment">// 用于保存添加到分发缓存的URI是否有相同的名字，如果有相同的名字的被提交多次，但是文件路径不同，Yarn将以内部错误是container启动失败</span></div><div class="line"><span class="keyword">val</span> distributedNames = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]</div><div class="line"></div><div class="line"><span class="keyword">val</span> replication = sparkConf.get(<span class="type">STAGING_FILE_REPLICATION</span>).map(_.toShort)</div><div class="line">  .getOrElse(fs.getDefaultReplication(destDir))</div><div class="line"><span class="comment">// 用来保存本地资源的集合</span></div><div class="line"><span class="keyword">val</span> localResources = <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">LocalResource</span>]()</div><div class="line"><span class="comment">// 在HDFS上创建 staging目录，并将目录的访问权限设置为700</span></div><div class="line"><span class="type">FileSystem</span>.mkdirs(fs, destDir, <span class="keyword">new</span> <span class="type">FsPermission</span>(<span class="type">STAGING_DIR_PERMISSION</span>))</div><div class="line"></div><div class="line"><span class="comment">// 保存文件的文件状态，不是以文件为key而是一个文件的URI作为key</span></div><div class="line"><span class="keyword">val</span> statCache: <span class="type">Map</span>[<span class="type">URI</span>, <span class="type">FileStatus</span>] = <span class="type">HashMap</span>[<span class="type">URI</span>, <span class="type">FileStatus</span>]()</div><div class="line"><span class="keyword">val</span> symlinkCache: <span class="type">Map</span>[<span class="type">URI</span>, <span class="type">Path</span>] = <span class="type">HashMap</span>[<span class="type">URI</span>, <span class="type">Path</span>]()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">addDistributedUri</span></span>(uri: <span class="type">URI</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">  <span class="keyword">val</span> uriStr = uri.toString()</div><div class="line">  <span class="comment">// 获取要分发的文件名</span></div><div class="line">  <span class="keyword">val</span> fileName = <span class="keyword">new</span> <span class="type">File</span>(uri.getPath).getName</div><div class="line">  <span class="comment">// 如果URI已经被添加多次，添加失败，如果文件名也被添加多次，添加失败，否则添加成功</span></div><div class="line">  <span class="keyword">if</span> (distributedUris.contains(uriStr)) &#123;</div><div class="line">    logWarning(<span class="string">s"Same path resource <span class="subst">$uri</span> added multiple times to distributed cache."</span>)</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (distributedNames.contains(fileName)) &#123;</div><div class="line">    logWarning(<span class="string">s"Same name resource <span class="subst">$uri</span> added multiple times to distributed cache"</span>)</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    distributedUris += uriStr</div><div class="line">    distributedNames += fileName</div><div class="line">    <span class="literal">true</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>distributedUris和distributedNames用来进行资源添加的验证（在addDistributedUri中使用），在添加资源的时候，资源是以URI的方式来添加，对于同一个URI只允许添加一次，并且如果URI不同，但是文件名相同的情况，也会验证，同一个文件名的文件也只允许添加一次。另外代码中还设置了资源文件的存放位置（(spark.yarn.stagingDir|～)/.sparkStaging/application_id）、资源文件的副本数（3）以及资源文件目录的权限（700）。addDistributedUri方法用来进行验证。</p>
<h5 id="资源分发操作"><a href="#资源分发操作" class="headerlink" title="资源分发操作"></a>资源分发操作</h5><p>distribute方法是资源分发的实现。具体定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">distribute</span></span>(</div><div class="line">    path: <span class="type">String</span>,</div><div class="line">    resType: <span class="type">LocalResourceType</span> = <span class="type">LocalResourceType</span>.<span class="type">FILE</span>,</div><div class="line">    destName: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span>,</div><div class="line">    targetDir: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span>,</div><div class="line">    appMasterOnly: <span class="type">Boolean</span> = <span class="literal">false</span>): (<span class="type">Boolean</span>, <span class="type">String</span>) = &#123;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> trimmedPath = path.trim()</div><div class="line">  <span class="keyword">val</span> localURI = <span class="type">Utils</span>.resolveURI(trimmedPath)</div><div class="line">  <span class="comment">// 判断URI是否是以local开头的</span></div><div class="line">  <span class="keyword">if</span> (localURI.getScheme != <span class="type">LOCAL_SCHEME</span>) &#123;</div><div class="line">    <span class="comment">// 将URI添加到分发缓存，同时会对URI和FileName进行验证，不允许重复添加</span></div><div class="line">    <span class="keyword">if</span> (addDistributedUri(localURI)) &#123;</div><div class="line">      <span class="keyword">val</span> localPath = getQualifiedLocalPath(localURI, hadoopConf)</div><div class="line">      <span class="comment">// 拼接在混存中保存的名字</span></div><div class="line">      <span class="keyword">val</span> linkname = targetDir.map(_ + <span class="string">"/"</span>).getOrElse(<span class="string">""</span>) +</div><div class="line">        destName.orElse(<span class="type">Option</span>(localURI.getFragment())).getOrElse(localPath.getName())</div><div class="line">      <span class="comment">// 保存文件的缓存子目录</span></div><div class="line">      <span class="keyword">val</span> destPath = copyFileToRemote(destDir, localPath, replication, symlinkCache)</div><div class="line">      <span class="comment">// 目标文件系统，HDFS</span></div><div class="line">      <span class="keyword">val</span> destFs = <span class="type">FileSystem</span>.get(destPath.toUri(), hadoopConf)</div><div class="line">      <span class="comment">// 将文件添加到缓存</span></div><div class="line">      <span class="comment">// destFs 是HDFS文件系统</span></div><div class="line">      distCacheMgr.addResource(</div><div class="line">        destFs, hadoopConf, destPath, localResources, resType, linkname, statCache,</div><div class="line">        appMasterOnly = appMasterOnly)</div><div class="line">      (<span class="literal">false</span>, linkname)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      (<span class="literal">false</span>, <span class="literal">null</span>)</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    (<span class="literal">true</span>, trimmedPath)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个方法的作用就是将不是以“local”开头的文件添加到分发缓存中（调用addDistributedUri方法），添加的时候会进行验证。copyFileToRemote方法的作用，就是将本地的文件（file://）上传到HDFS上，copyFileToRemote方法中会进行两个文件系统的对比，只有当源文件系统和目标文件系统不同（不同的HDFS或一个是HDFS一个是普通文件系统）才会进行复制文件。最后调用ClientDistributedCacheManager的addResource方法将文件加入到Resource列表中供后面启动container使用。</p>
<h5 id="分发Keytab文件"><a href="#分发Keytab文件" class="headerlink" title="分发Keytab文件"></a>分发Keytab文件</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (loginFromKeytab) &#123;</div><div class="line">  logInfo(<span class="string">"To enable the AM to login from keytab, credentials are being copied over to the AM"</span> +</div><div class="line">    <span class="string">" via the YARN Secure Distributed Cache."</span>)</div><div class="line">  <span class="keyword">val</span> (_, localizedPath) = distribute(keytab,</div><div class="line">    destName = <span class="type">Some</span>(amKeytabFileName),</div><div class="line">    appMasterOnly = <span class="literal">true</span>)</div><div class="line">  require(localizedPath != <span class="literal">null</span>, <span class="string">"Keytab file already distributed."</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>amKeytabFileName是添加了UUID后缀的名字，作用就是调用distribute方法，将keytab文件分发，但是只是分发给Application Master。</p>
<h5 id="jar文件的分发逻辑"><a href="#jar文件的分发逻辑" class="headerlink" title="jar文件的分发逻辑"></a>jar文件的分发逻辑</h5><p>在对Jar进行分发的时候，会有三种情况：</p>
<blockquote>
<p>设置了spark.yarn.archive<br>设置了spark.yarn.jars<br>spark.yarn.archeive和spark.yarn.jars都没有设设置</p>
</blockquote>
<p>当同时设置了spark.yarn.archive和spark.yarn.jars时，spark.yarn.archive优先级高。</p>
<h6 id="spark-yarn-archive"><a href="#spark-yarn-archive" class="headerlink" title="spark.yarn.archive"></a>spark.yarn.archive</h6><p>如果配置了spark.yarn.archive（目录，且要求必须不是以local开头的文件系统），则将spark.yarn.archive配置的目录作为ARCHIVE类型的资源分发到“<strong>spark_libs</strong>”目录中。</p>
<h6 id="spark-yarn-jars"><a href="#spark-yarn-jars" class="headerlink" title="spark.yarn.jars"></a>spark.yarn.jars</h6><p>如果配置了spark.yarn.jars（必须是文件，多个文件用逗号分隔），则将spark.yarn.jars中的每个文件作为FILE类型资源分发到“<strong>spark_libs</strong>”目录中。<br>对于local文件（以local://）开头的文件，会将其重新设置到sparkConf中的“spark.yarn.jars”配置项中。</p>
<h6 id="上传-SPARK-HOME-下的jars"><a href="#上传-SPARK-HOME-下的jars" class="headerlink" title="上传${SPARK_HOME}下的jars"></a>上传${SPARK_HOME}下的jars</h6><p>对于既没有配置spark.yarn.archive又没有配置spark.yarn.jars，那么系统会将环境变量${SPARK_HOME}中指定的目录下的jars或assembly/target/scala-%{scala_version}}/jars目录中的jar打包为一个“<strong>spark_libs</strong>.zip”文件，然后将这个文件作为ARCHIVE类型分发到“<strong>spark_libs</strong>”目录。</p>
<p>看了三种情况，这里有一个问题，对于配置了spark,yarn.archive和什么都没有配置的情况，都是将URI作为ARCHIVE类型资源分发到“<strong>spark_libs</strong>”目录中，那么这两个参数还有什么作用么？其实最主要的区别就是在进行文件拷本的时候，也就是调用copyFileToRemote方法的时候，可以减少上传操作。</p>
<p>如下是jar文件分发的逻辑实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sparkArchive = sparkConf.get(<span class="type">SPARK_ARCHIVE</span>)</div><div class="line"><span class="comment">// 如果定义了 spark.yarn.archive</span></div><div class="line"><span class="keyword">if</span> (sparkArchive.isDefined) &#123;</div><div class="line">  <span class="keyword">val</span> archive = sparkArchive.get</div><div class="line">  <span class="comment">// 要求 spark.yarn.archive 的value不是是本地目录（local://开头）</span></div><div class="line">  require(!isLocalUri(archive), <span class="string">s"<span class="subst">$&#123;SPARK_ARCHIVE.key&#125;</span> cannot be a local URI."</span>)</div><div class="line">  distribute(<span class="type">Utils</span>.resolveURI(archive).toString,</div><div class="line">    resType = <span class="type">LocalResourceType</span>.<span class="type">ARCHIVE</span>,</div><div class="line">    destName = <span class="type">Some</span>(<span class="type">LOCALIZED_LIB_DIR</span>))</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">  sparkConf.get(<span class="type">SPARK_JARS</span>) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(jars) =&gt;</div><div class="line">      <span class="comment">// Break the list of jars to upload, and resolve globs.</span></div><div class="line">      <span class="comment">// 将spark.yarn.jars中配置的jar（非本地jar）进行分发</span></div><div class="line">      <span class="keyword">val</span> localJars = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</div><div class="line">      jars.foreach &#123; jar =&gt;</div><div class="line">        <span class="keyword">if</span> (!isLocalUri(jar)) &#123;</div><div class="line">          <span class="comment">// 得到jar的路径</span></div><div class="line">          <span class="keyword">val</span> path = getQualifiedLocalPath(<span class="type">Utils</span>.resolveURI(jar), hadoopConf)</div><div class="line">          <span class="comment">// 得到文件系统</span></div><div class="line">          <span class="keyword">val</span> pathFs = <span class="type">FileSystem</span>.get(path.toUri(), hadoopConf)</div><div class="line">          pathFs.globStatus(path).filter(_.isFile()).foreach &#123; entry =&gt;</div><div class="line">            <span class="keyword">val</span> uri = entry.getPath().toUri()</div><div class="line">            statCache.update(uri, entry)</div><div class="line">            <span class="comment">// 分发jar</span></div><div class="line">            distribute(uri.toString(), targetDir = <span class="type">Some</span>(<span class="type">LOCALIZED_LIB_DIR</span>))</div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          localJars += jar</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      sparkConf.set(<span class="type">SPARK_JARS</span>, localJars)</div><div class="line"></div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">      <span class="comment">// No configuration, so fall back to uploading local jar files.</span></div><div class="line">      <span class="comment">// 没有配置 spark.yarn.archive和spark.yarn.jars 需要上传本地的jar包</span></div><div class="line">      logWarning(<span class="string">s"Neither <span class="subst">$&#123;SPARK_JARS.key&#125;</span> nor <span class="subst">$&#123;SPARK_ARCHIVE.key&#125;</span> is set, falling back "</span> +</div><div class="line">        <span class="string">"to uploading libraries under SPARK_HOME."</span>)</div><div class="line">      <span class="comment">// 在Spark home目录下查找存放jar的目录</span></div><div class="line">      <span class="keyword">val</span> jarsDir = <span class="keyword">new</span> <span class="type">File</span>(<span class="type">YarnCommandBuilderUtils</span>.findJarsDir(</div><div class="line">        sparkConf.getenv(<span class="string">"SPARK_HOME"</span>)))</div><div class="line">      <span class="comment">// 创建一个名为 __spark_libs__.zip的</span></div><div class="line">      <span class="keyword">val</span> jarsArchive = <span class="type">File</span>.createTempFile(<span class="type">LOCALIZED_LIB_DIR</span>, <span class="string">".zip"</span>,</div><div class="line">        <span class="keyword">new</span> <span class="type">File</span>(<span class="type">Utils</span>.getLocalDir(sparkConf)))</div><div class="line">      <span class="comment">// 利用 __spark_libs__.zip创建输出流</span></div><div class="line">      <span class="keyword">val</span> jarsStream = <span class="keyword">new</span> <span class="type">ZipOutputStream</span>(<span class="keyword">new</span> <span class="type">FileOutputStream</span>(jarsArchive))</div><div class="line"></div><div class="line">      <span class="comment">// 将jar目录下的所有jar文件，添加到__spark_libs__.zip的输出流中，这里其实就是将 jar打包成一个 __spark_libs__.zip的文件</span></div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        jarsStream.setLevel(<span class="number">0</span>)</div><div class="line">        jarsDir.listFiles().foreach &#123; f =&gt;</div><div class="line">          <span class="keyword">if</span> (f.isFile &amp;&amp; f.getName.toLowerCase(<span class="type">Locale</span>.<span class="type">ROOT</span>).endsWith(<span class="string">".jar"</span>) &amp;&amp; f.canRead) &#123;</div><div class="line">            jarsStream.putNextEntry(<span class="keyword">new</span> <span class="type">ZipEntry</span>(f.getName))</div><div class="line">            <span class="type">Files</span>.copy(f, jarsStream)</div><div class="line">            jarsStream.closeEntry()</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        jarsStream.close()</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 将打包好的__spark_libs__.zip进行分发， 分发到__spark_libs__目录下</span></div><div class="line">      distribute(jarsArchive.toURI.getPath,</div><div class="line">        resType = <span class="type">LocalResourceType</span>.<span class="type">ARCHIVE</span>,</div><div class="line">        destName = <span class="type">Some</span>(<span class="type">LOCALIZED_LIB_DIR</span>))</div><div class="line">      jarsArchive.delete()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>看到代码的实现，这里还有一个问题，对于配置spark.yarn.jars的情况，如果其中的jar是以“local://”开头的，会将这些文件加入到列表中，然后用这个列表来重新设置spark.yarn.jars的配置，那么后续还会怎么处理呢？也就是说对于以local://开头配置的文件，要怎么处理呢？</p>
<h5 id="分发用户Jar包"><a href="#分发用户Jar包" class="headerlink" title="分发用户Jar包"></a>分发用户Jar包</h5><p>对于用户的jar包（通过–jar参数指定的），会将其以“<strong>app</strong>.jar”进行分发<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="type">Option</span>(args.userJar).filter(_.trim.nonEmpty).foreach &#123; jar =&gt;</div><div class="line">  <span class="keyword">val</span> (isLocal, localizedPath) = distribute(jar, destName = <span class="type">Some</span>(<span class="type">APP_JAR_NAME</span>))</div><div class="line">  <span class="keyword">if</span> (isLocal) &#123;</div><div class="line">    require(localizedPath != <span class="literal">null</span>, <span class="string">s"Path <span class="subst">$jar</span> already distributed"</span>)</div><div class="line">    <span class="comment">// If the resource is intended for local use only, handle this downstream</span></div><div class="line">    <span class="comment">// by setting the appropriate property</span></div><div class="line">    sparkConf.set(<span class="type">APP_JAR</span>, localizedPath)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h5 id="其他需要分发的"><a href="#其他需要分发的" class="headerlink" title="其他需要分发的"></a>其他需要分发的</h5><p>除了上面那些分发的内容，用户还可以设置spark.yarn.dist.jars、spark.yarn.dist.files或spark.yarn.dist.archives配置项来制定自己要分发的文件，对于spark.yarn.dist.jars指定的jar，会被添加到classPath中，另外两个不会。需要注意的是这些文件不能和之前上传的URI或文件名相同，否则不会分发。然后这些值会作为配置项“spark.yarn.secondary.jars”的信息进行设置。对于那些AM不需要，但是executor需要的jar，可以通过这种方式来配置。</p>
<h5 id="配置项的上传"><a href="#配置项的上传" class="headerlink" title="配置项的上传"></a>配置项的上传</h5><p>除了上面的jar包、文件的分发，系统还会上传，配置项会被上传到(spark.yarn.stagingDir|～)/.sparkStaging/application_id/<strong>spark_conf</strong>.zip位置。<br>上传的内容配置内容如下，“spark.overlay.hadoop.conf.filenames”配置项中指定的配置文件、log4j.properties、metrics.properties、环境变量“HADOOP_CONF_DIR”目录中的文件、环境变量“YARN_CONF_DIR”目录中的文件。其中如果有相同的配置文件，那么最后两个环境变量中的文件优先级最低。除了这些文件，系统还会将内存中sparkConf的属性和Keytab文件中的属性，以“<strong>spark_conf</strong>.properties”进行保存，一起添加到压缩文件<strong>spark_conf</strong>.zip中，一起上传到spark.yarn.stagingDir|～)/.sparkStaging/application_id/<strong>spark_conf</strong>.zip位置。</p>
<p>这些资源如何传递给container呢？答案是生成ContainerLaunchContext时（Records.newRecord(classOf[ContainerLaunchContext])–这样创建），作为localResources属性设置的。除了localResource，还有一个environment需要设置，环境信息和资源信息一样，也会上传到“(spark.yarn.stagingDir|～)/.sparkStaging/application_id/”目录下。</p>
<h4 id="启动命令的拼接"><a href="#启动命令的拼接" class="headerlink" title="启动命令的拼接"></a>启动命令的拼接</h4><p>启动命令的拼接就是为了要拼成 /bin/java -server ${-javaOpts} ${amArg}这样的命令来启动另外一个java类。对于要启动哪个类，如下判断：</p>
<p>对于集群模式将会启动org.apache.spark.deploy.yarn.ApplicationMaster对象，赋予非集群模式将启动org.apache.spark.deploy.yarn.ExecutorLauncher对象。</p>
<p>对于集群模式，启动ApplicationManster，这样就与之前ApplicationMaster的运行流程连接起来。</p>
<h3 id="创建Application提交上下文"><a href="#创建Application提交上下文" class="headerlink" title="创建Application提交上下文"></a>创建Application提交上下文</h3><p>创建Container提交上下文是通过createApplicationSubmissionContext方法实现的。与其说是创建不如说设置，因为这个上下文是通过newApp.getApplicationSubmissionContext得到的，而newApp是通过yarn客户端调用createApplication得到的。<br>这个方法对Context设置的信息如下</p>
<table>
<thead>
<tr>
<th>context属性</th>
<th>取值</th>
</tr>
</thead>
<tbody>
<tr>
<td>applicationName</td>
<td>spark.app.name配置项，默认为Spark</td>
</tr>
<tr>
<td>queue</td>
<td>spark.yarn.queue配置项</td>
</tr>
<tr>
<td>AMContainerSpec</td>
<td>上面生成的ContainerLaunchContext</td>
</tr>
<tr>
<td>applcationType</td>
<td>“SPARK”</td>
</tr>
<tr>
<td>applicationTags</td>
<td>spark.yarn.tags配置项，如果是多值，逐个设置</td>
</tr>
<tr>
<td>maxAppAttempts</td>
<td>spark.yarn.maxAppAttempts配置项</td>
</tr>
<tr>
<td>attemptFailuresValidityInterval</td>
<td>spark.yarn.am.attemptFailuresValidityInterval配置项</td>
</tr>
<tr>
<td>AMContainerResourceRequest</td>
<td>新生成的ResourceRequest对象，ResourceRequest对象包含的信息，如下表，该配置只有在spark.yarn.am.nodeLabelExpression设置时有效</td>
</tr>
<tr>
<td>resource</td>
<td>新生成的Resource对象，包括所需的内存和CPU，该配置只有在spark.yarn.am.nodeLabelExpression没有设置时有效</td>
</tr>
<tr>
<td>logAggregationContext</td>
<td>新生成的LogAggregationContext，只有在spark.yarn.rolledLog.includePattern设置时有效</td>
</tr>
</tbody>
</table>
<p>ResourceRequest包含的信息如下<br>|属性|取值|<br>|-|-|<br>|resourceName|*，等|<br>|priority|Priority对象，默认为0|<br>|capability|Resource对象，包含内存和cpu|<br>|numContainers|所需container的数量|<br>|nodeLableExpression|节点标签表达式 —- 这个在申请资源时有什么作用|</p>
<p>将上面补充好的ApplicationSubmissionContext对象作为参数，通过yarn客户端的submitApplication方法，就完成了application的提交。</p>
<p>得到Application提交上下文之后，便可以调用yarnClient来提交Application。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/01/31/spark-2-11-metircs/" itemprop="url">
                  spark-2-11-metircs
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-01-31T16:05:32+08:00" content="2019-01-31">
              2019-01-31
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文按照Metric的基本认识、Spark对Metrics system的配置、源码分析MetricsSystem的顺序进行学习</p>
<h1 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h1><p>目前最流行的metrics库是dropwizard/metircs，spark使用的也是这个库。下面我们介绍一下dropwizard/metircs的概念和用法。</p>
<h2 id="Maven依赖"><a href="#Maven依赖" class="headerlink" title="Maven依赖"></a>Maven依赖</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;metrics-core&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h2 id="Metric的基本使用"><a href="#Metric的基本使用" class="headerlink" title="Metric的基本使用"></a>Metric的基本使用</h2><p>MetricRegistry类是Metrics的核心，他是存放应用中所有metrics的容器，也是我们使用Metrics的第一步：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MetricRegistry metricRegistry = <span class="keyword">new</span> MetricsRegistry();</div></pre></td></tr></table></figure></p>
<p>每个Metrics都有一个唯一的名字，我们可以通过MetricRegistry.name来生成：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">metricName = MetricRegistry.name(<span class="string">"name"</span>, <span class="string">"namesecond"</span>, <span class="string">"namethrid"</span>); <span class="comment">//生成name.namescond.namethrid</span></div></pre></td></tr></table></figure></p>
<p>有了MetricRegistry和Metric之后，接下来需要进行注册<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">metricRegistry.register(metricName, MetricType)</div></pre></td></tr></table></figure></p>
<p>注册的时候，需要指定Metric的类型，详细的类型，后面会介绍。<br>以下是Spark中的一些使用参考：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="keyword">val</span> metricRegistry = <span class="keyword">new</span> <span class="type">MetricRegistry</span>()</div><div class="line"></div><div class="line">metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"threadpool"</span>, <span class="string">"activeTasks"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = threadPool.getActiveCount()</div><div class="line">&#125;)</div></pre></td></tr></table></figure></p>
<h2 id="Metrics类型"><a href="#Metrics类型" class="headerlink" title="Metrics类型"></a>Metrics类型</h2><p>Metrics有五种类型，分别是Gauges、Counters、Meters、Histograms和Timers。</p>
<h3 id="Gauges"><a href="#Gauges" class="headerlink" title="Gauges"></a>Gauges</h3><p>Gauges是最简单的Metrics类型，该对象中只有一个方法getValue用于返回统计的值，下面是Gauges接口的定义：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Gauge</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Metric</span> </span>&#123;</div><div class="line">    <span class="function">T <span class="title">getValue</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从方法可以看出，Gauge中的getValue可以返回与Gauge定义类型相同的任意类型。<br>以下是Spark中Gauges类型Metric的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"threadpool"</span>, <span class="string">"activeTasks"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = threadPool.getActiveCount()</div><div class="line">&#125;)</div><div class="line"></div><div class="line"><span class="comment">// Gauge for executor thread pool's approximate total number of tasks that have been completed</span></div><div class="line">metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"threadpool"</span>, <span class="string">"completeTasks"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Long</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Long</span> = threadPool.getCompletedTaskCount()</div><div class="line">&#125;)</div></pre></td></tr></table></figure></p>
<p>分别定义了一个Int类型和一个Long类型的Gauges。</p>
<h3 id="Counters"><a href="#Counters" class="headerlink" title="Counters"></a>Counters</h3><p>Counter是计数器，既然是计数器，因此可增可减。Counter其实是对AtomicLong的封装。</p>
<h4 id="Meters支持的方法"><a href="#Meters支持的方法" class="headerlink" title="Meters支持的方法"></a>Meters支持的方法</h4><p>inc(): 计数器自加。<br>dec(): 计数器自减。</p>
<h4 id="生成方法"><a href="#生成方法" class="headerlink" title="生成方法"></a>生成方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pendingJobs = registry.counter(MetricRegistry.name(Queue.class,<span class="string">"pending-jobs"</span>,<span class="string">"size"</span>));</div></pre></td></tr></table></figure>
<h3 id="Meters"><a href="#Meters" class="headerlink" title="Meters"></a>Meters</h3><p>Meters用来计算事件发生的速率。Meters会统计近1分钟、5分钟、15分钟以及全部时间的速率。</p>
<h4 id="Meters可用的方法"><a href="#Meters可用的方法" class="headerlink" title="Meters可用的方法"></a>Meters可用的方法</h4><p>mark()方法：表示发生一次事件。</p>
<h4 id="生成方法-1"><a href="#生成方法-1" class="headerlink" title="生成方法"></a>生成方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Meter meterTps = registry.meter(MetricRegistry.name(MeterTest.class,<span class="string">"request"</span>,<span class="string">"tps"</span>));</div></pre></td></tr></table></figure>
<h3 id="Histograms"><a href="#Histograms" class="headerlink" title="Histograms"></a>Histograms</h3><p>Histograms统计数据的分布情况。比如最大值、最小值、中间值、中位数、75百分位、90百分位、98百分位、99百分位和99.9百分位的值。</p>
<h4 id="Histograms可用的方法"><a href="#Histograms可用的方法" class="headerlink" title="Histograms可用的方法"></a>Histograms可用的方法</h4><p>histogram.update(…): 更新一个数</p>
<h4 id="生成方法-2"><a href="#生成方法-2" class="headerlink" title="生成方法"></a>生成方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Histogram histogram - <span class="keyword">new</span> Histogram(...)</div><div class="line">registery.register(MetricRegistry.name(...), histogram)</div></pre></td></tr></table></figure>
<h3 id="Timers"><a href="#Timers" class="headerlink" title="Timers"></a>Timers</h3><p>Timer可以理解为Histogram和Meter的结合。</p>
<h4 id="Timer可用的方法"><a href="#Timer可用的方法" class="headerlink" title="Timer可用的方法"></a>Timer可用的方法</h4><p>timer.time(): 记录时间</p>
<h4 id="生成方法-3"><a href="#生成方法-3" class="headerlink" title="生成方法"></a>生成方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Timer timer = registry.timer(MetricRegistry.name(...))</div></pre></td></tr></table></figure>
<h2 id="Metrics的输出"><a href="#Metrics的输出" class="headerlink" title="Metrics的输出"></a>Metrics的输出</h2><h3 id="通过JMX"><a href="#通过JMX" class="headerlink" title="通过JMX"></a>通过JMX</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">final</span> JmxReporter reporter = jmxReporter.forRegistry(registry).build()</div><div class="line">reporter.start()</div></pre></td></tr></table></figure>
<p>一旦reporter被启动，所有在registry中的metrics可以通过JConsole或VisualVM（如果安装了MBeans插件）可见。</p>
<h3 id="其他方式"><a href="#其他方式" class="headerlink" title="其他方式"></a>其他方式</h3><p>除了JMX，Metrics还能够以HTTP、STDOUT、CSV、SLFJ、Ganglia和Graphite的方式输出。 详细可以参考：<a href="https://metrics.dropwizard.io/3.1.0/getting-started" target="_blank" rel="external">https://metrics.dropwizard.io/3.1.0/getting-started</a> 和 <a href="https://metrics.dropwizard.io/3.1.0/manual/core/" target="_blank" rel="external">https://metrics.dropwizard.io/3.1.0/manual/core/</a></p>
<h1 id="Spark中Metrics的配置"><a href="#Spark中Metrics的配置" class="headerlink" title="Spark中Metrics的配置"></a>Spark中Metrics的配置</h1><p>Spark的Metrics的配置，在$SPARK_HOME/conf/metrics.properties文件中配置。如果用户需要制定自己的配置文件，可以通过spark.metrics.conf来指定。默认情况下，driver或executor的root命名空间为spark.app.id，但是在某些情况下，用户想要跨driver或executor跟踪Metrics，对于这种情况，可以使用spark.metrics.namespace来自定义命名空间。</p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>在Spark中，Metrics根据Spark的组建被划分中不同的实例。对于每个实例，可以配置一组sinks来报告metrics。如下是当前支持的实例：</p>
<table>
<thead>
<tr>
<th style="text-align:left">实例名</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">master</td>
<td style="text-align:left">standalone模式Spark的master进程</td>
</tr>
<tr>
<td style="text-align:left">application</td>
<td style="text-align:left">master中的组件，对不同applications进行报告</td>
</tr>
<tr>
<td style="text-align:left">worker</td>
<td style="text-align:left">standalone模式Spark的worker进程</td>
</tr>
<tr>
<td style="text-align:left">executor</td>
<td style="text-align:left">一个Spark executor</td>
</tr>
<tr>
<td style="text-align:left">driver</td>
<td style="text-align:left">Spark的driver进程</td>
</tr>
<tr>
<td style="text-align:left">shuffleService</td>
<td style="text-align:left">Spark的Shuffle服务</td>
</tr>
<tr>
<td style="text-align:left">applicationMaster</td>
<td style="text-align:left">当在Yarn上运行时，Spark的application master</td>
</tr>
</tbody>
</table>
<h2 id="Sinks"><a href="#Sinks" class="headerlink" title="Sinks"></a>Sinks</h2><p>每个实例能够汇报给0个或多个sink。Sinks包含在org.apache.spark.metrics.sink包中，有如下sink：</p>
<table>
<thead>
<tr>
<th style="text-align:left">sink</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ConsoleSink</td>
<td style="text-align:left">记录metrics信息到 console</td>
</tr>
<tr>
<td style="text-align:left">CSVSink</td>
<td style="text-align:left">以一定的间隔，将metrics数据导出到CSV文件</td>
</tr>
<tr>
<td style="text-align:left">JmxSink</td>
<td style="text-align:left">将metrics注册到JMX console</td>
</tr>
<tr>
<td style="text-align:left">MetricsServlet</td>
<td style="text-align:left">在已有的Spark UI中添加一个Servlet，以JONS数据格式来服务metrics数据</td>
</tr>
<tr>
<td style="text-align:left">GraphiteSink</td>
<td style="text-align:left">将metrics发送给Graphite节点</td>
</tr>
<tr>
<td style="text-align:left">Slf4jSink</td>
<td style="text-align:left">将metrics发送给slf4j</td>
</tr>
<tr>
<td style="text-align:left">StatsdSink</td>
<td style="text-align:left">将metrics发送给StatsD节点</td>
</tr>
<tr>
<td style="text-align:left">GangliaSink</td>
<td style="text-align:left">将metrics发送给Ganglia节点，需要重新编译Spark，将gangliaSink打包进去，默认不包含</td>
</tr>
</tbody>
</table>
<h2 id="metrics-properties"><a href="#metrics-properties" class="headerlink" title="metrics.properties"></a>metrics.properties</h2><p>可以参考：$SPARK_HOME/conf/metrics.properties.template文件，在这个文件中对source、sink等作了详细的解释，并提供了例子。</p>
<h1 id="从Spark源码看Metrics的使用"><a href="#从Spark源码看Metrics的使用" class="headerlink" title="从Spark源码看Metrics的使用"></a>从Spark源码看Metrics的使用</h1><p>Spark中对于Metrics的处理集中在core模块下的org.apache.spark.metrics包中。<br>包结构如下：<br><img src="/attach/5c52acc1de555.png" alt="image.png"><br>其中MetricsSystem是该模块的入口，MetricsConfig为模块的配置管理，Source是Metric系统的数据源，Sink是Metrics的量输出。</p>
<h2 id="MetricsConfig"><a href="#MetricsConfig" class="headerlink" title="MetricsConfig"></a>MetricsConfig</h2><p>MetricsConfig用来加载metrics的配置，并对MetricsSystem进行相关的配置。在MetricsSystem类中，会生成MetricsConfig对象，并进行初始化操作。</p>
<h3 id="首先看看MetricsConfig的一些属性"><a href="#首先看看MetricsConfig的一些属性" class="headerlink" title="首先看看MetricsConfig的一些属性"></a>首先看看MetricsConfig的一些属性</h3><p>正如Spark文档说的，默认的Metrics配置文件为 metrics.properties</p>
<h3 id="initialize方法"><a href="#initialize方法" class="headerlink" title="initialize方法"></a>initialize方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>() &#123;</div><div class="line">  <span class="comment">// 添加默认属性，用于没有配置文件的情况</span></div><div class="line">  setDefaultProperties(properties)</div><div class="line">  <span class="comment">// 从metrics配置文件中加载metrics配置</span></div><div class="line">  loadPropertiesFromFile(conf.getOption(<span class="string">"spark.metrics.conf"</span>))</div><div class="line"></div><div class="line">  <span class="comment">// 从Spark配置文件中加载metrics配置</span></div><div class="line">  <span class="keyword">val</span> prefix = <span class="string">"spark.metrics.conf."</span></div><div class="line">  conf.getAll.foreach &#123;</div><div class="line">    <span class="keyword">case</span> (k, v) <span class="keyword">if</span> k.startsWith(prefix) =&gt;</div><div class="line">      properties.setProperty(k.substring(prefix.length()), v)</div><div class="line">    <span class="keyword">case</span> _ =&gt;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  perInstanceSubProperties = subProperties(properties, <span class="type">INSTANCE_REGEX</span>)</div><div class="line">  <span class="comment">// 判断是否以 * 开始的实例配置，这种表示是所有实例的配置（称为默认实例配置）</span></div><div class="line">  <span class="keyword">if</span> (perInstanceSubProperties.contains(<span class="type">DEFAULT_PREFIX</span>)) &#123;</div><div class="line">    <span class="comment">// 获取默认实例配置</span></div><div class="line">    <span class="keyword">val</span> defaultSubProperties = perInstanceSubProperties(<span class="type">DEFAULT_PREFIX</span>).asScala</div><div class="line">    <span class="comment">// 循环所有非默认实例配置，将实例配置添加到非实例配置中（注意，实例配置已有的属性不会被覆盖）</span></div><div class="line">    <span class="keyword">for</span> ((instance, prop) &lt;- perInstanceSubProperties <span class="keyword">if</span> (instance != <span class="type">DEFAULT_PREFIX</span>);</div><div class="line">         (k, v) &lt;- defaultSubProperties <span class="keyword">if</span> (prop.get(k) == <span class="literal">null</span>)) &#123;</div><div class="line">      prop.put(k, v)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在initialize方法中，首先会调用setDefaultProperties方法来加载默认配置，这是为了应对没有设置Metrics配置文件的情况（连默认的metrics.properties都没有提供）。<br>然后会调用loadPropertiesFromFile方法，从指定的配置文件中加载Metrics配置。<br>再然后，会读取Spark的所有配置项，从中筛选以”spark.metrics.conf.”为前缀的配置项，并将配置项添加到属性中。需要注意的是，在添加属性的时候，并非以配置项的全名作为属性，而是以子名作为属性名，例如：spark.metrics.conf.xxx，那么会使用xxx作为属性名，而spark.metrics.conf.xxx.x1则会使用xxx.x1作为属性名。<br>最后，该方法还会对实例属性（指定了实例的配置）进行整理。实例属性的配置类似driver.path这样的，driver就是实例，因此这里就有一个问题，对于所有实例通用的配置应该怎么设置呢？答案是<em>.path这样的。有</em>的则表示通用的默认值，没有<em>的配置，第一个dot（.）前的为实例。有实例的配置会覆盖没有实例的配置。代码中的属性private val INSTANCE_REGEX = “^(\</em>|[a-zA-Z]+)\.(.+)”.r，就解释了实例配置的模式，要不就是以“<em>”开头，要么就以字母开头，以字母开头的表示具体实例，以“</em>”开头的表示所有实例通用。<br>因此也就可以理解setDefaultProperties方法中设置默认值的作用。整理的作用就是将默认实例配置（以“*”开头的实例配置）添加到非默认实例配置中（不会覆盖非默认实例配置已有的属性）。<br>比如，有如下属性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;\\*.class&quot;-&gt;&quot;default_class&quot;, &quot;\\*.path&quot;-&gt;&quot;default_path, &quot;driver.path&quot;-&gt;&quot;driver_path&quot;&#125;</div></pre></td></tr></table></figure></p>
<p>对于driver实例，他最后得到的属性为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&#123;&quot;driver&quot;-&gt;Map(&quot;path&quot;-&gt;&quot;driver_path&quot;, &quot;class&quot;-&gt;&quot;default_class&quot;&#125;&#125;</div></pre></td></tr></table></figure></p>
<h3 id="setDefaultProperties"><a href="#setDefaultProperties" class="headerlink" title="setDefaultProperties"></a>setDefaultProperties</h3><p>当没有配置metrics配置文件时（是指连默认的配置文件都不存在），采取的默认Metrics配置。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">setDefaultProperties</span></span>(prop: <span class="type">Properties</span>) &#123;</div><div class="line">  <span class="comment">// 默认开启了servlet类型的sink，指定servlet的class为org.apache.spark.metrics.sink.MetricsServlet</span></div><div class="line">  prop.setProperty(<span class="string">"*.sink.servlet.class"</span>, <span class="string">"org.apache.spark.metrics.sink.MetricsServlet"</span>)</div><div class="line">  <span class="comment">// 先为所有实例设置，再为master和applications类型的实例设置</span></div><div class="line">  prop.setProperty(<span class="string">"*.sink.servlet.path"</span>, <span class="string">"/metrics/json"</span>)</div><div class="line">  prop.setProperty(<span class="string">"master.sink.servlet.path"</span>, <span class="string">"/metrics/master/json"</span>)</div><div class="line">  prop.setProperty(<span class="string">"applications.sink.servlet.path"</span>, <span class="string">"/metrics/applications/json"</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="loadPropertiesFromFile"><a href="#loadPropertiesFromFile" class="headerlink" title="loadPropertiesFromFile"></a>loadPropertiesFromFile</h3><p>方法需要path参数（配置文件的名字-从Spark的配置项spark.metrics.conf中读取），如果给定的path存在，则从这个文件中加载，如果path不存在，则从classPath目录中加载默认配置文件metrics.properties。</p>
<h2 id="MetricsSystem"><a href="#MetricsSystem" class="headerlink" title="MetricsSystem"></a>MetricsSystem</h2><p>MetricsSystem类是对外提供的一个对象，从调用来看，在Master、SparkEnv和Work中都有创建MetricsSystem的代码。其中Master和Work是对于standalone模式下创建的。SparkEnv中是对driver和executor进行创建的。生成MetricsSystem的时候是需要指定instance参数的。因此从创建MetricsSystem的代码我们也能够知道MetricsSystem都支持哪些instance。<br>TODO 对于applications的创建，有时间再找<br>这里，我们先抛开对MetricsSystem的操作，我们先看看MetricsSystem的实现</p>
<h3 id="创建MetricsSystem"><a href="#创建MetricsSystem" class="headerlink" title="创建MetricsSystem"></a>创建MetricsSystem</h3><p>从所有的生成MetricsSyste的代码来看，MetricsSystem都是通过如下代码创建的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">val</span> metricsSystem = <span class="type">MetricsSystem</span>.createMetricsSystem(<span class="string">"worker"</span>, conf, securityMgr) <span class="comment">// 这里创建的一个work实例的MetricsSystem</span></div></pre></td></tr></table></figure>
<p>而对于createMetricsSystem方法的定义也很多简单，就是new了一个MetricsSystem对象：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createMetricsSystem</span></span>(</div><div class="line">    instance: <span class="type">String</span>, conf: <span class="type">SparkConf</span>, securityMgr: <span class="type">SecurityManager</span>): <span class="type">MetricsSystem</span> = &#123;</div><div class="line">  <span class="keyword">new</span> <span class="type">MetricsSystem</span>(instance, conf, securityMgr)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="注册Source"><a href="#注册Source" class="headerlink" title="注册Source"></a>注册Source</h3><p>创建了MetricsSystem，接下来就需要向它注册source。我们以Worker中MetricsSystem的使用来作为参考。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">metricsSystem.registerSource(workerSource)</div><div class="line">metricsSystem.start()</div><div class="line">metricsSystem.getServletHandlers.foreach(webUi.attachHandler)</div></pre></td></tr></table></figure></p>
<p>因此，我们来看一下MetricsSystem的registerSource方法<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">registerSource</span></span>(source: <span class="type">Source</span>) &#123;</div><div class="line">  sources += source</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="keyword">val</span> regName = buildRegistryName(source)</div><div class="line">    registry.register(regName, source.metricRegistry)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">IllegalArgumentException</span> =&gt; logInfo(<span class="string">"Metrics already registered"</span>, e)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>将source添加Source列表中，然后调用buildRegistryName方法生成source注册使用的名字，然后进行注册，那么需要看一下buildRegistryName方法<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">buildRegistryName</span></span>(source: <span class="type">Source</span>): <span class="type">String</span> = &#123;</div><div class="line">  <span class="keyword">val</span> metricsNamespace = conf.get(<span class="type">METRICS_NAMESPACE</span>).orElse(conf.getOption(<span class="string">"spark.app.id"</span>))</div><div class="line"></div><div class="line">  <span class="keyword">val</span> executorId = conf.getOption(<span class="string">"spark.executor.id"</span>)</div><div class="line">  <span class="keyword">val</span> defaultName = <span class="type">MetricRegistry</span>.name(source.sourceName)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (instance == <span class="string">"driver"</span> || instance == <span class="string">"executor"</span>) &#123;</div><div class="line">    <span class="keyword">if</span> (metricsNamespace.isDefined &amp;&amp; executorId.isDefined) &#123;</div><div class="line">      <span class="type">MetricRegistry</span>.name(metricsNamespace.get, executorId.get, source.sourceName)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// Only Driver and Executor set spark.app.id and spark.executor.id.</span></div><div class="line">      <span class="comment">// Other instance types, e.g. Master and Worker, are not related to a specific application.</span></div><div class="line">      <span class="keyword">if</span> (metricsNamespace.isEmpty) &#123;</div><div class="line">        logWarning(<span class="string">s"Using default name <span class="subst">$defaultName</span> for source because neither "</span> +</div><div class="line">          <span class="string">s"<span class="subst">$&#123;METRICS_NAMESPACE.key&#125;</span> nor spark.app.id is set."</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (executorId.isEmpty) &#123;</div><div class="line">        logWarning(<span class="string">s"Using default name <span class="subst">$defaultName</span> for source because spark.executor.id is "</span> +</div><div class="line">          <span class="string">s"not set."</span>)</div><div class="line">      &#125;</div><div class="line">      defaultName</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123; defaultName &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>buildRegistryName方法，就是根据Source，构建一个向MetricRegistry注册的名字。这个名字是唯一的。其基本思路就是根据namespace（从spark.metrics.namespace或spark.app.id中取）和executorId（从spark.executor.id中取）构建一个注册用的名字，但是需要注意的是，是否使用这两个值作为构建的条件，要依赖实例是否是drvier或executor，否则一律使用source的名字生成。<br>注册好Source，调用MetricsSystem的start方法启动MetricsSystem。</p>
<h3 id="启动start方法"><a href="#启动start方法" class="headerlink" title="启动start方法"></a>启动start方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</div><div class="line">  require(!running, <span class="string">"Attempting to start a MetricsSystem that is already running"</span>)</div><div class="line">  running = <span class="literal">true</span></div><div class="line">  <span class="type">StaticSources</span>.allSources.foreach(registerSource)</div><div class="line">  registerSources()</div><div class="line">  registerSinks()</div><div class="line">  sinks.foreach(_.start)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>start方法代码很少，但是包含的东西却挺多。注册静态Source，所谓的静态Source，其实就是不依赖用户配置的Source。接着调用registerSources方法，这个注册是读取配置的文件中当前实例（instance）的配置，对Source的class进行实例化并注册。然后是调用registerSinks方法来注册Sink，也是将配置文件中当前实例（instance）的配置进行操作，对Sink的class进行实例化，并加入到Sink集合中等待调用（调用sink的report方法）；最后启动所有的sink。</p>
<h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><p>Source就是Metrics的数据源，我们对Source中的统计数据进行操作，Metrics系统会从已经注册的Source中获取这些数据，然后由Sink报告出去。下面我们以WorkSource来进行分析，看看如何自定义一个Source。</p>
<h3 id="WorkSource"><a href="#WorkSource" class="headerlink" title="WorkSource"></a>WorkSource</h3><p>先看一下WorkSource的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[worker] <span class="class"><span class="keyword">class</span> <span class="title">WorkerSource</span>(<span class="params">val worker: <span class="type">Worker</span></span>) <span class="keyword">extends</span> <span class="title">Source</span> </span>&#123;</div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> sourceName = <span class="string">"worker"</span></div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> metricRegistry = <span class="keyword">new</span> <span class="type">MetricRegistry</span>()</div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"executors"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = worker.executors.size</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  <span class="comment">// Gauge for cores used of this worker</span></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"coresUsed"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = worker.coresUsed</div><div class="line">  &#125;)</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>WorkSource中metric的类型只涉及到了Gauge，也就是这些值不需要用户参与。对于需要用户参与的我们可以参考StaticSources，稍后也会看到。WorkSource的逻辑很简单，就是注册了一些metric，并制定了这些metric如何取值。</p>
<h3 id="StaticSources-HiveCatalogMetrics"><a href="#StaticSources-HiveCatalogMetrics" class="headerlink" title="StaticSources$HiveCatalogMetrics"></a>StaticSources$HiveCatalogMetrics</h3><p>接下来看一下StaticSources$HiveCatalogMetrics的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">HiveCatalogMetrics</span> <span class="keyword">extends</span> <span class="title">Source</span> </span>&#123;</div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> sourceName: <span class="type">String</span> = <span class="string">"HiveExternalCatalog"</span></div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> metricRegistry: <span class="type">MetricRegistry</span> = <span class="keyword">new</span> <span class="type">MetricRegistry</span>()</div><div class="line"></div><div class="line">  <span class="keyword">val</span> <span class="type">METRIC_PARTITIONS_FETCHED</span> = metricRegistry.counter(<span class="type">MetricRegistry</span>.name(<span class="string">"partitionsFetched"</span>))</div><div class="line">  <span class="keyword">val</span> <span class="type">METRIC_FILES_DISCOVERED</span> = metricRegistry.counter(<span class="type">MetricRegistry</span>.name(<span class="string">"filesDiscovered"</span>))</div><div class="line">  ...</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="type">METRIC_PARTITIONS_FETCHED</span>.dec(<span class="type">METRIC_PARTITIONS_FETCHED</span>.getCount())</div><div class="line">    <span class="type">METRIC_FILES_DISCOVERED</span>.dec(<span class="type">METRIC_FILES_DISCOVERED</span>.getCount())</div><div class="line">    ...</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// clients can use these to avoid classloader issues with the codahale classes</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">incrementFetchedPartitions</span></span>(n: <span class="type">Int</span>): <span class="type">Unit</span> = <span class="type">METRIC_PARTITIONS_FETCHED</span>.inc(n)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">incrementFilesDiscovered</span></span>(n: <span class="type">Int</span>): <span class="type">Unit</span> = <span class="type">METRIC_FILES_DISCOVERED</span>.inc(n)</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个类中metric的类型为Counter，reset方法、incrementFetchedPartitions方法和incrementFilesDiscovered方法就是对这些Counter进行操作。</p>
<h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><p>Spark中已经内置了多种Sink，有ConsoleSink、CsvSink、JmxSink、MetricsServlet等，基本可以满足我们的需求了。接下来我们分析一两个常用Sink的实现。</p>
<h3 id="JmxSink"><a href="#JmxSink" class="headerlink" title="JmxSink"></a>JmxSink</h3><p>JmxSink的定义如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">JmxSink</span>(<span class="params">val property: <span class="type">Properties</span>, val registry: <span class="type">MetricRegistry</span>,</span></span></div><div class="line">    securityMgr: <span class="type">SecurityManager</span>) <span class="keyword">extends</span> <span class="title">Sink</span> &#123;</div><div class="line">  <span class="keyword">val</span> reporter: <span class="type">JmxReporter</span> = <span class="type">JmxReporter</span>.forRegistry(registry).build()</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</div><div class="line">    reporter.start()</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">stop</span></span>() &#123;</div><div class="line">    reporter.stop()</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">report</span></span>() &#123; &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>JmxSink继承Sink特征，因此它需要实现start()、stop()和report()方法。另外在JmxSink定义中创建了一个JmxReporter对象，创建reporter对象时需要MetricRegistry对象，这就将Source和Sink中的Report联系了起来（metric注册到Source的MetricRegistry，source注册到MetricsSystem的MetricRegistry，在生成Sink中Reporter的时候会使用MetrcsSystem中的MetricRegistry）。那么Sink是如何报告自己收集的metrics呢？我理解的是，内部的Reporter会自己报告，也可以调用Sink的report方法，report方法再调用reporter的report方法。（—-TODO，Reporter的汇报，会稍后补充）</p>
<h3 id="ConsoleSink"><a href="#ConsoleSink" class="headerlink" title="ConsoleSink"></a>ConsoleSink</h3><p>ConsoleSink的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">ConsoleSink</span>(<span class="params">val property: <span class="type">Properties</span>, val registry: <span class="type">MetricRegistry</span>,</span></span></div><div class="line">    securityMgr: <span class="type">SecurityManager</span>) <span class="keyword">extends</span> <span class="title">Sink</span> &#123;</div><div class="line">  <span class="keyword">val</span> <span class="type">CONSOLE_DEFAULT_PERIOD</span> = <span class="number">10</span></div><div class="line">  <span class="keyword">val</span> <span class="type">CONSOLE_DEFAULT_UNIT</span> = <span class="string">"SECONDS"</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> <span class="type">CONSOLE_KEY_PERIOD</span> = <span class="string">"period"</span></div><div class="line">  <span class="keyword">val</span> <span class="type">CONSOLE_KEY_UNIT</span> = <span class="string">"unit"</span></div><div class="line"></div><div class="line">  <span class="keyword">val</span> pollPeriod = <span class="type">Option</span>(property.getProperty(<span class="type">CONSOLE_KEY_PERIOD</span>)) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(s) =&gt; s.toInt</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="type">CONSOLE_DEFAULT_PERIOD</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">val</span> pollUnit: <span class="type">TimeUnit</span> = <span class="type">Option</span>(property.getProperty(<span class="type">CONSOLE_KEY_UNIT</span>)) <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(s) =&gt; <span class="type">TimeUnit</span>.valueOf(s.toUpperCase(<span class="type">Locale</span>.<span class="type">ROOT</span>))</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="type">TimeUnit</span>.valueOf(<span class="type">CONSOLE_DEFAULT_UNIT</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="type">MetricsSystem</span>.checkMinimalPollingPeriod(pollUnit, pollPeriod)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> reporter: <span class="type">ConsoleReporter</span> = <span class="type">ConsoleReporter</span>.forRegistry(registry)</div><div class="line">      .convertDurationsTo(<span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</div><div class="line">      .convertRatesTo(<span class="type">TimeUnit</span>.<span class="type">SECONDS</span>)</div><div class="line">      .build()</div><div class="line"></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</div><div class="line">    reporter.start(pollPeriod, pollUnit)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">stop</span></span>() &#123;</div><div class="line">    reporter.stop()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">report</span></span>() &#123;</div><div class="line">    reporter.report()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>ConsoleSink中也实现了三个必须的方法，除此之外还定义了一个ConsoleReporter。而且它实现的三个方法其实也是对ConsoleReporter进行操作的。查看其他的Sink，也能够发现，每个Sink都有一个Reporter（除了MetricsServlet外，它的逻辑与普通Sink不同）。</p>
<h2 id="Source和Sink的操作"><a href="#Source和Sink的操作" class="headerlink" title="Source和Sink的操作"></a>Source和Sink的操作</h2><h3 id="Source的操作"><a href="#Source的操作" class="headerlink" title="Source的操作"></a>Source的操作</h3><p>对于Source的操作，我们就参考StaticSources$HiveCatalogMetrics中相关metric的操作吧。<br>如下是HiveClientImpl的一个方法，他就在操作Source的METRIC_PARTITIONS_FETCHED。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>(</div><div class="line">      table: <span class="type">CatalogTable</span>,</div><div class="line">      spec: <span class="type">Option</span>[<span class="type">TablePartitionSpec</span>]): <span class="type">Seq</span>[<span class="type">CatalogTablePartition</span>] = withHiveState &#123;</div><div class="line">    <span class="keyword">val</span> hiveTable = toHiveTable(table, <span class="type">Some</span>(userName))</div><div class="line">    <span class="keyword">val</span> parts = spec <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; shim.getAllPartitions(client, hiveTable).map(fromHivePartition)</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(s) =&gt;</div><div class="line">        assert(s.values.forall(_.nonEmpty), <span class="string">s"partition spec '<span class="subst">$s</span>' is invalid"</span>)</div><div class="line">        client.getPartitions(hiveTable, s.asJava).asScala.map(fromHivePartition)</div><div class="line">    &#125;</div><div class="line">    <span class="type">HiveCatalogMetrics</span>.incrementFetchedPartitions(parts.length)</div><div class="line">    parts</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h3 id="Sink的操作"><a href="#Sink的操作" class="headerlink" title="Sink的操作"></a>Sink的操作</h3><p>对于Sink的调用，是在MetricsSystem的report方法中触发的：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span></span>() &#123;</div><div class="line">  sinks.foreach(_.report())</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>对于MetricsSystem中report方法的调用，会在各个组建停止的时候调用，进行强制汇报。</p>
<h2 id="Source、Sink、MetricsSystem以及MetricsConfig之间的关系"><a href="#Source、Sink、MetricsSystem以及MetricsConfig之间的关系" class="headerlink" title="Source、Sink、MetricsSystem以及MetricsConfig之间的关系"></a>Source、Sink、MetricsSystem以及MetricsConfig之间的关系</h2><p><img src="/attach/5c52afb97da92.png" alt="image.png"></p>
<h2 id="自定义Source"><a href="#自定义Source" class="headerlink" title="自定义Source"></a>自定义Source</h2><p>要定义自己的Source对象，需要实现org.apache.spark.metrics.source.Source特征，并实现sourceName(String类型)和metricRegistry(MetricRegistry类型)方法。之后定义自己的metric类型即可，可用的metric类型已经在上面的第一部分进行介绍。如下是DAGScheduulerSource的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerSource</span>(<span class="params">val dagScheduler: <span class="type">DAGScheduler</span></span>)</span></div><div class="line">    <span class="keyword">extends</span> <span class="type">Source</span> &#123;</div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> metricRegistry = <span class="keyword">new</span> <span class="type">MetricRegistry</span>()</div><div class="line">  <span class="keyword">override</span> <span class="keyword">val</span> sourceName = <span class="string">"DAGScheduler"</span></div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"stage"</span>, <span class="string">"failedStages"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = dagScheduler.failedStages.size</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"stage"</span>, <span class="string">"runningStages"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = dagScheduler.runningStages.size</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"stage"</span>, <span class="string">"waitingStages"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = dagScheduler.waitingStages.size</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"job"</span>, <span class="string">"allJobs"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = dagScheduler.numTotalJobs</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  metricRegistry.register(<span class="type">MetricRegistry</span>.name(<span class="string">"job"</span>, <span class="string">"activeJobs"</span>), <span class="keyword">new</span> <span class="type">Gauge</span>[<span class="type">Int</span>] &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValue</span></span>: <span class="type">Int</span> = dagScheduler.activeJobs.size</div><div class="line">  &#125;)</div><div class="line"></div><div class="line">  <span class="comment">/** Timer that tracks the time to process messages in the DAGScheduler's event loop */</span></div><div class="line">  <span class="keyword">val</span> messageProcessingTimer: <span class="type">Timer</span> =</div><div class="line">    metricRegistry.timer(<span class="type">MetricRegistry</span>.name(<span class="string">"messageProcessingTime"</span>))</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在这个类的定义中，实现了Source特征，并重写了metricRegistry和sourceName方法。接下来注册了自己要统计的metric，默认是以servlet中展示这些信息，我们可以通过www.xxxxx:8088/proxy/application_id/metrics/json来查看对应的输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">&quot;application_1530945921317_6019078.driver.DAGScheduler.job.activeJobs&quot;:&#123;&quot;value&quot;:2&#125;,&quot;application_1530945921317_6019078.driver.DAGScheduler.job.allJobs&quot;:&#123;&quot;value&quot;:77&#125;,&quot;application_1530945921317_6019078.driver.DAGScheduler.stage.failedStages&quot;:&#123;&quot;value&quot;:0&#125;,&quot;application_1530945921317_6019078.driver.DAGScheduler.stage.runningStages&quot;:&#123;&quot;value&quot;:2&#125;,&quot;application_1530945921317_6019078.driver.DAGScheduler.stage.waitingStages&quot;:&#123;&quot;value&quot;:0&#125;,</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>自定义的类截图<br><img src="/attach/5c613f9fdbb6f.png" alt="image.png"><br>该类会在DAGScheduler中进行实例化：<br><img src="/attach/5c613fccd71c9.png" alt="image.png"><br>然后在SparkContext中进行注册：<br><img src="/attach/5c613fea40b45.png" alt="image.png"><br>以下是自定义的source注册后，在servlet中的显示<br><img src="/attach/5c613f66f016d.png" alt="image.png"></p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如果在配置文件中配置自己的source呢？关键是如何定义。。。需要看一下</p>
<p>对于配置文件中metrics的配置格式如下：</p>
<blockquote>
<p>[instance].[sink|source].[name].[options] = xxxx<br>[instance]可以是master、worker、executor、driver或application，也就是明确了实例的类型。如果让所有实例都可以使用，可以使用“*”代替。<br>[sink|source]指定配置项是sink的信息还是source的信息，只能二选一。<br>[name]指定sink或source的名字。<br>[options]指定sink或source的相关属性，如class。</p>
</blockquote>
<p>注意点：如果是需要进行配置的自定义source，有两点需要注意。</p>
<blockquote>
<p>配置中必须通过class属性指定类名，程序会根据类名进行反射。<br>配置的自定义Source必须有不含构造参数的构造方法，否则无法实例化。</p>
</blockquote>
<h2 id="配置自定义Source"><a href="#配置自定义Source" class="headerlink" title="配置自定义Source"></a>配置自定义Source</h2><p>编辑 metrics.properties配置文件<br>增加如下配置即可<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">driver.source.rwmTest.class=org.apache.spark.metrics.source.RWMTestSource</div></pre></td></tr></table></figure></p>
<p>UI中的显示信息<br><img src="/attach/5c626eb6d83e9.png" alt="image.png"></p>
<h2 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h2><h3 id="Spark-config"><a href="#Spark-config" class="headerlink" title="Spark config"></a>Spark config</h3><table>
<thead>
<tr>
<th style="text-align:left">配置项</th>
<th style="text-align:left">默认值</th>
<th style="text-align:left">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">spark.metrics.conf</td>
<td style="text-align:left">metrics.properties</td>
<td style="text-align:left">Metrics系统的配置文件</td>
</tr>
<tr>
<td style="text-align:left">spark.metrics.conf.xxx</td>
<td style="text-align:left">无</td>
<td style="text-align:left">将xxx作为属性，添加到属性中，可以将其理解为 metrics.properties中配置的一种转移，会和metrics.properties中的配置项放在一起，而且此配置优先级较高</td>
</tr>
<tr>
<td style="text-align:left">spark.metrics.namespace</td>
<td style="text-align:left">无</td>
<td style="text-align:left">metrics的命名空间，参与构建Metrics source注册名的生成</td>
</tr>
<tr>
<td style="text-align:left">spark.app.id</td>
<td style="text-align:left">无</td>
<td style="text-align:left">如果spark.metrics.namespace没有指定值，则使用该值作为namespace，参与构建Metrics source注册名的生成</td>
</tr>
<tr>
<td style="text-align:left">spark.executor.id</td>
<td style="text-align:left">无</td>
<td style="text-align:left">executor的id，参数构建Metrics source注册名的生成</td>
</tr>
</tbody>
</table>
<h3 id="Metrics-config"><a href="#Metrics-config" class="headerlink" title="Metrics config"></a>Metrics config</h3><table>
<thead>
<tr>
<th style="text-align:left">配置项</th>
<th style="text-align:left">默认值</th>
<th style="text-align:left">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">source.(.+).(.+)</td>
<td style="text-align:left">无</td>
<td style="text-align:left">source的配置信息，就是以source.xxx.xxx形式的，只能有两个dot(.)</td>
</tr>
<tr>
<td style="text-align:left">sink.(.+).(.+)</td>
<td style="text-align:left">无</td>
<td style="text-align:left">sink的配置信息，就是以sink.xxx.xxx形式的，只能有两个dot(.)</td>
</tr>
</tbody>
</table>
<p>对于source和sink的配置，参考：$SPARK_HOME/conf/metrics.properties.template</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/01/23/yarn-restApi/" itemprop="url">
                  Yarn RestApi
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-01-23T15:04:35+08:00" content="2019-01-23">
              2019-01-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/yarn/" itemprop="url" rel="index">
                    <span itemprop="name">yarn</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文记录自己在工作学习期间使用Yarn rest api的一些记录</p>
<h1 id="Yarn-rest-api-介绍"><a href="#Yarn-rest-api-介绍" class="headerlink" title="Yarn rest api 介绍"></a>Yarn rest api 介绍</h1><h2 id="获取所有的application-id"><a href="#获取所有的application-id" class="headerlink" title="获取所有的application id"></a>获取所有的application id</h2><h3 id="Url的地址"><a href="#Url的地址" class="headerlink" title="Url的地址"></a>Url的地址</h3><p>http://<rm http="" address:port="">/ws/v1/cluster/apps<br>参考地址：<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Applications_API" target="_blank" rel="external">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Applications_API</a></rm></p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>可以提供的参数</p>
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">参数意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">states</td>
<td style="text-align:left">限制application的状态</td>
</tr>
<tr>
<td style="text-align:left">finalStatus</td>
<td style="text-align:left">限制最终状态，如：UNDEFINED</td>
</tr>
<tr>
<td style="text-align:left">user</td>
<td style="text-align:left">用户名</td>
</tr>
<tr>
<td style="text-align:left">queue</td>
<td style="text-align:left">所使用的队列</td>
</tr>
<tr>
<td style="text-align:left">limit</td>
<td style="text-align:left">限制返回的数量</td>
</tr>
<tr>
<td style="text-align:left">startedTimeBegin</td>
<td style="text-align:left">与startedTimeEnd配合限制application的start的时间</td>
</tr>
<tr>
<td style="text-align:left">startedTimeEnd</td>
<td style="text-align:left">与startedTimeBegin配合限制application的start的时间</td>
</tr>
<tr>
<td style="text-align:left">finishedTimeBegin</td>
<td style="text-align:left">与finishedTimeEnd配合限制application的完成时间</td>
</tr>
<tr>
<td style="text-align:left">finishedTimeEnd</td>
<td style="text-align:left">与finishedTimeBegin配合限制application的完成时间</td>
</tr>
<tr>
<td style="text-align:left">applicationTypes</td>
<td style="text-align:left">限制application的类型，如SPARK</td>
</tr>
<tr>
<td style="text-align:left">applicationTags</td>
<td style="text-align:left">不知道</td>
</tr>
<tr>
<td style="text-align:left">deSelects</td>
<td style="text-align:left">不知道</td>
</tr>
</tbody>
</table>
<h3 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h3><p>需要导入requests</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">queryApplications</span><span class="params">(host, port, p)</span>:</span></div><div class="line">    url = <span class="string">'http://%s:%s/ws/v1/cluster/apps'</span> % (host, port)</div><div class="line">    reponse = requests.get(url, params=p)</div><div class="line">    <span class="comment">#print reponse.url</span></div><div class="line">    apps = json.loads(reponse.text)</div><div class="line">    <span class="keyword">if</span> apps:</div><div class="line">        <span class="keyword">return</span> apps.get(<span class="string">"apps"</span>, &#123;&#125;)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line"><span class="keyword">if</span> <span class="string">"__main__"</span> == __name__:</div><div class="line">    host = <span class="string">'yarn.host.com'</span></div><div class="line">    port = <span class="number">8088</span></div><div class="line">    params = &#123;&#125;</div><div class="line">    params[<span class="string">'startedTimeBegin'</span>] = changeTimeToNumber(changeStrToTime(getHourBegin()))</div><div class="line">    params[<span class="string">'startedTimeEnd'</span>] = changeTimeToNumber(changeStrToTime(getHourEnd())) * <span class="number">1000</span></div><div class="line">    params[<span class="string">'applicationTypes'</span>] = [<span class="string">'SPARK'</span>]</div><div class="line">    apps = queryApplications(host, port, params)</div></pre></td></tr></table></figure>
<h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>返回在此Yarn调度过的applicaiton列表</p>
<h2 id="获取单个Application的信息"><a href="#获取单个Application的信息" class="headerlink" title="获取单个Application的信息"></a>获取单个Application的信息</h2><h3 id="Url的地址-1"><a href="#Url的地址-1" class="headerlink" title="Url的地址"></a>Url的地址</h3><p>http://<rm http="" address:port="">/ws/v1/cluster/apps/{appid}<br>参考地址：<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Application_API" target="_blank" rel="external">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html#Cluster_Application_API</a></rm></p>
<h3 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h3><p>没有参数</p>
<h3 id="Python实现-1"><a href="#Python实现-1" class="headerlink" title="Python实现"></a>Python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">queryApplication</span><span class="params">(appid, host, port)</span>:</span></div><div class="line">    url = <span class="string">'http://%s:%s/ws/v1/cluster/apps/%s'</span> % (host, port, appid)</div><div class="line">    reponse = requests.get(url)</div><div class="line">    <span class="comment">#print reponse.url</span></div><div class="line">    res = json.loads(reponse.text)</div><div class="line">    <span class="keyword">return</span> res</div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="string">"__main__"</span> == __name__:</div><div class="line">    host = <span class="string">'yarn.host.com'</span></div><div class="line">    port = <span class="number">8088</span></div><div class="line">    app = queryApplication(<span class="string">'application_1476912658570_0002'</span>, host, port)</div></pre></td></tr></table></figure>
<h3 id="返回值-1"><a href="#返回值-1" class="headerlink" title="返回值"></a>返回值</h3><p>返回application的详细信息，可以参考URL处提供的地址</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/01/18/spark-2-11-thriftServer/" itemprop="url">
                  spark-2.11-thriftServer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-01-18T15:29:58+08:00" content="2019-01-18">
              2019-01-18
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文记录Thrift server的学习，先从一个服务异常为切入点：</p>
<h1 id="Thrift-Server的本地启动"><a href="#Thrift-Server的本地启动" class="headerlink" title="Thrift Server的本地启动"></a>Thrift Server的本地启动</h1><p>– 感谢韦大侠帮助<br>直接运行 HiveThriftServer2是无法正常启动的，首先需要配置启动参数：<br><img src="/attach/pimg_5c1771760f7a5.png" alt="pimg_5c1771760f7a5.png"><br>在 Program arguments 中添加：-hiveconf spark.master=local[2] -hiveconf spark.driver.bindAddress=127.0.0.1<br>在Working directory中添加：/Users/renweiming/spark/spark-2.x<br>这样启动的话还是会抛出异常信息：<br><img src="/attach/pimg_5c1771cf3f9a6.png" alt="pimg_5c1771cf3f9a6.png"><br>解决缺少类的方法是 File -&gt; Project Structure…<br><img src="/attach/pimg_5c177201e0a2a.png" alt="pimg_5c177201e0a2a.png"><br>打开项目结构对话框<br><img src="/attach/pimg_5c177250538bb.png" alt="pimg_5c177250538bb.png"><br>点击左下角的“➕”来增加Jar。一个小建议，如果你的Spark项目已经构建过了，那么其实Spark所需的jar都已经存在于本地的maven仓库里了，直接去仓库中，将对应的jar添加即可，就不再去下载jar包了。<br>常见的一些所需jar包：<br>| 异常 | 所需jar | 说明 |<br>| ———— | ————- | —————- |<br>| java.lang.ClassNotFoundException: com.google.common.cache.CacheLoader | com.google.guava | 该问题，一般是因为Scope设置的是Provided，修改为Compile即可，见表格下的截图 |<br>| 我擦，一下子启动起来了，以前配置过，以后遇到再补充吧，不给表现机会。。| …| …|<br><img src="/attach/pimg_5c1774288b08d.png" alt="pimg_5c1774288b08d.png"></p>
<h1 id="带着问题学习"><a href="#带着问题学习" class="headerlink" title="带着问题学习"></a>带着问题学习</h1><p>在Thrift server中，出现了如下异常：<br>18/12/17 15:01:00 INFO AbstractService: Service:HiveServer2 is stopped.<br>通过向上追日志，发现还有如下信息：<br>18/12/17 15:00:59 INFO HiveServer2: Shutting down HiveServer2<br>继续向上追：<br>18/12/17 15:00:59 ERROR SparkExecuteStatementOperation: Error running hive query as user : livepm<br>继续向上追：</p>
<p>从代码结构来看：<br>HiveServer2继承CompositeService，继承AbstractService。上面的异常就是从 AbstractService的stop()方法中报出来的。而这个方法调用是从如下的流程中调用的：HiveServer2.stop() -&gt; CompositeService.stop() -&gt; AbstractService.stop()。<br>所以，从代码上来分析，肯定是什么地方调用了stop方法。<br>在HiveServer的init方法中，添加了程序关闭的钩子函数：<br><img src="/attach/pimg_5c1778027340a.png" alt="pimg_5c1778027340a.png"><br>所以肯定是主动调用了stop方法，或者是异常导致HiveServer关闭了。</p>
<p>开始看到什么记什么，稍后在整理<br>Thrift server的UI其实是在Spark的UI上增加了一个tab页，默认端口为4040，可以通过 spark.ui.port 进行自定义。Thrift Server的展示效果，是通过类 ThriftServerPage 和 ThriftServerSessionPage 来定义的。</p>
<p>在初始化HiveThriftServer的时候，会根据Hive的配置项hive.server2.transport.mode的值（可选的有http和binary）来决定生成哪种 ThriftCLIService。如果是http则生成 ThriftHttpCLIService，否则生成 ThriftBinaryCLIService。</p>
<h1 id="启动流程"><a href="#启动流程" class="headerlink" title="启动流程"></a>启动流程</h1><p>入口必然是HiveThriftServer2，HiveThriftServer2的main方法，在方法的开头就生成了一个HiveServer2对象，并调用它的parse方法得到一个ServerOptionsProcessorResponse对象，该对象中包含的ServerOptionsExecutor是 StartOptionExecutor对象。 – 但是这个服务好像就没有被调用，也就是说 HiveServer2并没有被调用。</p>
<p>接下来<br>创建了一个HiveThriftServer2对象，并调用了这个服务的init和start。<br><img src="/attach/pimg_5c18ae94ed28f.png" alt="pimg_5c18ae94ed28f.png"><br>然而start方法只是调用了父类的start，并将自身的启动标示started设置为true。父类（HiveServer2）的start方法，同样又调用了父类（CompositeService）的start方法。在这个类的方法中，它将serviceList中的service（通过addService添加的）分别调用start方法，然后又调用了父类（AbstractService）的start方法。在这个顶级抽象方法中，设置了服务的开始时间、检查了当前状态为INITED，并将服务的状态设置为 STARTED。<br>所以我们的关注点就落在了 serviceList中service是如何添加进去的。我们返回看一下HiveThriftServer2的init方法，就是上图中我们调用的init方法。<br><img src="/attach/pimg_5c18aee6c6ac3.png" alt="pimg_5c18aee6c6ac3.png"><br>这样就添加了两个service，分别是 SparkSQLCLIService 和 ThriftCLIService。针对THriftCLIService，会根据 hive.server2.transport.mode 的配置项（binary 或 http）（我们公司使用的是默认值“binary”，也就是用的 ThriftBinaryCLIService ）具体生成ThriftHttpCLIService或ThriftBinaryCLIService。<br>继续将此方法看完，在init的最后执行的是 initCompositeService(hiveConf)，此方法是ReflectedCompositeService定义的一个方法，具体如下：<br><img src="/attach/pimg_5c18b128e9a91.png" alt="pimg_5c18b128e9a91.png"><br>这个方法，要把它作为HiveThriftServer2的一部分来读，那么它的功能就是初始化父类ServiceList中的service：</p>
<blockquote>
<p>得到父类（CompositeService）的serviceList，并对里面的service进行初始化（执行init方法）<br>设置hiveConf信息，通过反射设置。<br>检查服务的当前状态（确定必须是NOTINITED状态）并设置新的状态（INITED状态）。 –  为啥不直接调用AbstractService的init方法呢？</p>
</blockquote>
<p>继续按着顺序来吧，看一看前面通过addService添加到serviceList中的每个service吧。</p>
<h2 id="首先看看-SparkSQLCLIService-的init"><a href="#首先看看-SparkSQLCLIService-的init" class="headerlink" title="首先看看 SparkSQLCLIService 的init"></a>首先看看 SparkSQLCLIService 的init</h2><p>为父类设置HiveConf<br>生成SparkSQLSessionManager，并将SparkSQLSessionManager通过addService添加到CompositeService的serviceList中。注意这里的CompositeService是SparkSQLCLIService自己的CompositeService。之后又调用了 initCompositeService。相当于将添加进去的service进行初始化。</p>
<h3 id="SparkSQLSessionManager的初始化"><a href="#SparkSQLSessionManager的初始化" class="headerlink" title="SparkSQLSessionManager的初始化"></a>SparkSQLSessionManager的初始化</h3><p>首先，将hiveConf设置给父类（SparkSQLSessionManager的父类 SessionManager ）。<br>然后，判断是否开启了 hive.server2.logging.operation.enabled 配置（默认为true），如果开启了，则执行initOperationLogRootDir来初始化操作日志目录。<br>然后，根据配置项 hive.server2.async.exec.threads 的值，生成一个固定线程数的线程池，并将线程池设置给父类的 backgroundOperationPool。<br>最后，生成一个 SparkSQLOperationManager 对象，并将此对象 设置给父类（SessionManager）的 operationManager。然后对 operationManager 进行初始化。</p>
<h3 id="SparkSQLOperationManager的初始化"><a href="#SparkSQLOperationManager的初始化" class="headerlink" title="SparkSQLOperationManager的初始化"></a>SparkSQLOperationManager的初始化</h3><p>根据配置 hive.server2.logging.operation.enabled 的值（默认为true），来确定是否要启动一个 hive.server2.logging.operation.level 配置级别的Appender。</p>
<h2 id="再看看-ThriftBinaryCLIService"><a href="#再看看-ThriftBinaryCLIService" class="headerlink" title="再看看 ThriftBinaryCLIService"></a>再看看 ThriftBinaryCLIService</h2><p>首先，根据系统环境或配置项 hive.server2.thrift.bind.host 中得到需要绑定的host，如果没有则绑定本地地址。<br>然后，根据配置项 hive.server2.thrift.worker.keepalive.time 获取worker保持活跃的时长（默认为60秒）。<br>继续然后，从系统变量 HIVE_SERVER2_THRIFT_PORT 或配置项 hive.server2.thrift.port 中获取服务绑定的端口号，默认为10000。<br>最后，从配置项 hive.server2.thrift.min.worker.threads 和 hive.server2.thrift.max.worker.threads 中分别读取worker的最小线程数和最大线程数。<br>调用父类（AbastractService）的init方法。<br>worker活跃时长、最大线程数和最小线程数，用来初始化Service内部的线程池。</p>
<p>综上来看，其实就是一层一层的进行初始化，但是为啥不直接调用初始化方法呢？个人推测是覆盖性操作。</p>
<p>继续回到 HiveThriftServer2 初始化的位置，接下来就是启动 HiveThriftServer2，调用start方法，调用链如下：<br>HiveThriftServer.start() -&gt; HiveServer2.start() -&gt; CompositeService.start()(–此方法中会将serviceList中的所有service进行启动)<br>所以，接下来我们对 SparkSQLCLIService 和 ThriftBinaryCLIService 的start方法进行分析。</p>
<h2 id="SparkSQLCLIService的启动"><a href="#SparkSQLCLIService的启动" class="headerlink" title="SparkSQLCLIService的启动"></a>SparkSQLCLIService的启动</h2><p>SparkSQLCLIService类中并没有定义start方法，但是它的父类CLIService中定义了。父类的启动很简单，首先调用父类（CompositeService）的start方法，相当于对serviceList中的各个service进行启动。然后自己内部生成一个 HiveMetaStoreClient，并链接获取默认的数据库（只是为了测试链接）。 至于serviceList中service的启动，需要结合上面的初始化来看看需要具体启动那些service。稍后上图。</p>
<h2 id="ThriftBinaryCLIService的启动"><a href="#ThriftBinaryCLIService的启动" class="headerlink" title="ThriftBinaryCLIService的启动"></a>ThriftBinaryCLIService的启动</h2><p>ThriftBinaryCLIService自身也没有定义start方法，其父类（ThriftCLISService）定义了start方法。具体逻辑如下：调用父类（AbstractService）的start方法。然后，将自己作为参数生成一个Thread，并进行启动（因为ThriftCLIService实现了Runnable接口）。然而，ThriftCLIService自身只是定义了抽象方法run，具体实现由 ThriftBinaryCLIService 或 ThrfitHttpCLIService 来实现。因为我们使用的是 ThriftBinaryCLIService ，因此我们只对此类进行分析。<br>对于ThriftBinaryCLIService的启动，我们进行分析：<br>创建线程池、创建TTransportFactory、创建TProcessorFactory、创建serverSocket，这些是用来创建TThreadPoolServer.Args，然后使用它来创建 TThreadPoolServer，然后调用service的serve方法来启动服务。这里就会输出 Starting … on port … with … … worker threads的日志。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2019/01/17/spark-2-11-shuffleDataReadAndWrite/" itemprop="url">
                  Spark 2.11 shuffle data read and write
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-01-17T19:09:23+08:00" content="2019-01-17">
              2019-01-17
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文记录对Spark Shuffle过程中对数据读写的梳理。本文将先从数据的读入作为切入点，也就是从ShuffleReader的源码作为切入，然后在逐步的展开。因此本文将从读取和写入两个角度来进行分析，最后在用流程图的方式将读取和写入整合起来。</p>
<h1 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h1><h2 id="ShuffleReader的实现类"><a href="#ShuffleReader的实现类" class="headerlink" title="ShuffleReader的实现类"></a>ShuffleReader的实现类</h2><p>ShuffleRead是定义在org.apache.spark.shuffle包中的一个接口（理解为接口吧，其实是trait），它只定义了一个方法read()，并且这个方法返回一个Iterator（迭代器）。对于ShuffleReader的实现类，只有一个类 BlockStoreShuffleReader，与ShuffleReader定义在同一个包中。</p>
<h3 id="ShuffleReader的read-方法的实现"><a href="#ShuffleReader的read-方法的实现" class="headerlink" title="ShuffleReader的read()方法的实现"></a>ShuffleReader的read()方法的实现</h3><p>read()基本的流程图参考如下如下<br><img src="" alt="image.png"></p>
<p>在read()方法中，首先生成一个ShuffleBlockFetcherIterator对象。该对象的详细介绍会在后面进行。<br>生成的ShuffleBlockFetcherIterator本身就是一个Iterator，但是需要注意这个Iterator中包含的数据都是进行了加密和压缩的，我们在之后分析ShuffleBlockFetcherIterator的时候会了解到。<br>接着，我们会得到序列化器的实例，将ShuffleBlockFectherIterator中的数据进行解析。<br>如果Shuffle的依赖中定义了聚合器，则需要进行一次聚合操作（将上面的迭代器中的数据再次处理）：如果是map端聚合，则使用聚合器的 combineCombinersByKey来处理，否则使用combineValuesByKey来处理。<br>最后，创建一个ExternalSorter并将上一步的数据全部插入到这个sorter中，并使用这个ExternalSorter创建一个CompletionIterator返回。<br>大家在这里会看到聚合器和ExternalSorter，这就实现了Shuffle的基本操作。</p>
<h2 id="ShuffleBlockFetcherIterator的实现与流程"><a href="#ShuffleBlockFetcherIterator的实现与流程" class="headerlink" title="ShuffleBlockFetcherIterator的实现与流程"></a>ShuffleBlockFetcherIterator的实现与流程</h2><p>生成这个对象需要一系列参数：</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>参数类型</th>
<th>参数的意义和作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>context</td>
<td>TaskContext</td>
<td>Task的上下文</td>
</tr>
<tr>
<td>shuffleClient</td>
<td>ShuffleClient</td>
<td>读取Shuffle数据的Client</td>
</tr>
<tr>
<td>blockManager</td>
<td>BlockManager</td>
<td>Block的管理器，可以获取Block的相关信息</td>
</tr>
<tr>
<td>blocksByAddress</td>
<td>Seq</td>
<td>根据BlockManagerId聚合的Block列表</td>
</tr>
<tr>
<td>streamWrapper</td>
<td>函数</td>
<td>用于将BlockId和对应的InputStream进行包装的方法</td>
</tr>
<tr>
<td>maxBytesInFlight</td>
<td>Long</td>
<td>——</td>
</tr>
<tr>
<td>maxReqsInFlight</td>
<td>Int</td>
<td>同时进行请求发送的最大数</td>
</tr>
<tr>
<td>maxBlocksInFlightPerAddress</td>
<td>Int</td>
<td>同时拉取某个远程地址的block的请求数</td>
</tr>
<tr>
<td>maxReqSizeShuffleToMem</td>
<td>Long</td>
<td>单个请求拉取数据的可用缓存，如果超出这个缓存则使用临时文件来拉取数据</td>
</tr>
<tr>
<td>detectCorrupt</td>
<td>Boolean</td>
<td>—</td>
</tr>
</tbody>
</table>
<p>通过以上参数，生成了我们的ShuffleBlockFetcherIterator。ShuffleBlockFetcherIterator实现了Iterator（迭代器）接口，同时也实现了TempShuffleFileManager（临时Shuffle文件管理器）。实现Iterator就意味着它有迭代器的相关方法（next、hasNext）；实现TempShuffleFileManager，就意味这它能够创建临时Shuffle文件（createTempShuffleFile）、能够注册临时文件的清理（registerTempShuffleFileToClean）。接下来我们分别按照接口的实现来分析，首先看看比较简单的TempShuffleFileManager：</p>
<h3 id="TempShuffleFileManager的实现"><a href="#TempShuffleFileManager的实现" class="headerlink" title="TempShuffleFileManager的实现"></a>TempShuffleFileManager的实现</h3><p>实现这个接口，我们需要实现两个方法 createTempShuffleFile 和 registerTempShuffleFileToClean。</p>
<h4 id="createTempShuffleFile"><a href="#createTempShuffleFile" class="headerlink" title="createTempShuffleFile"></a>createTempShuffleFile</h4><p>这个方法的实现很简单，就是调用BlockManager的DiskBlockManager的createTempLocalBlock来创建一个临时本地Block并返回。</p>
<h4 id="registerTempShuffleFileToCliean"><a href="#registerTempShuffleFileToCliean" class="headerlink" title="registerTempShuffleFileToCliean"></a>registerTempShuffleFileToCliean</h4><p>这个方法的实现也很简单，就是将文件添加到一个名为 shuffleFileSet 的集合中，等到ShuffleBlockFetcherIterator中cleanup方法被执行的时候，就会将 shuffleFileSet 集合中的文件统一删除。</p>
<h3 id="Iterator的实现"><a href="#Iterator的实现" class="headerlink" title="Iterator的实现"></a>Iterator的实现</h3><p>我们知道，ShuffleBlockFetcherIterator 最重要的功能是获取数据，这个过程会涉及到从远程拉取数据。</p>
<h4 id="hasNext"><a href="#hasNext" class="headerlink" title="hasNext"></a>hasNext</h4><p>方法实现很简单，就是判断已经处理的block数量是否达到需要拉取的block的数量（numBlocksProcessed &lt; numBlocksToFetch）。</p>
<h4 id="next"><a href="#next" class="headerlink" title="next"></a>next</h4><p>next方法的实现就复杂了，而且涉及到很多方法之间的调用，我们首先看看流程图，总体说明一下流程，然后在具体分析细节。<br><img src="/attach/5c3f1cf6f0fa4.png" alt="image.png"><br>这个流程图说明了 ShuffleBlockFetcherIterator 内部获取数据时几个方法之间的调用关系，next是对用户的接口，用户通过这个方法获取数据。但是我们都应该想到，shuffle数据是很庞大的，所以肯定不可能一次性都将数据拉取过来缓存，只能根据blockId逐步拉取，fetchUpToMaxBytes就是实现逐步拉取数据的逻辑，内部实现了对数据拉取的控制。当需要拉取数据的时候fetchUpToMaxBytes就会调用send方法，send方法是对sendRequest的一层封装，除了调用sendRequest之外，就是要记录每个远程地址当前正在传输Block的数量。sendRequest就是使用ShuffleClient从远程地址拉取数据的具体实现了。<br>为了便于理解，我们根据上面流程图的倒序进行分析。</p>
<h4 id="sendRequest"><a href="#sendRequest" class="headerlink" title="sendRequest"></a>sendRequest</h4><p>sendRequest是远程拉取数据的实现。从代码上来看，代码主要分成三个部分：记录状态信息（为fetchUpToMaxByte提供逻辑处理的数据）、生成BlockFetchingListender（调用fetchBlocks的时候需要这个监听器作为回调）以及使用shuffleClient拉取数据。<br>基本的流程图如下：<br><img src="/attach/5c3db21e60597.png" alt="image.png"><br>对于ShuffleClient的fetchBlocks方法的实现我们稍后会深入分析，但是这里需要意识到的是这个方法拉取的是多个block。</p>
<h4 id="send"><a href="#send" class="headerlink" title="send"></a>send</h4><p>send方法就是对sendRequest的包装，除了调用sendRequest方法之外，会记录当前远程地址正在传输Block的个数，也画一个图吧：<br><img src="/attach/5c3db673d673f.png" alt="image.png"><br>就是调用sendRequest，然后设置缓存的值。</p>
<h4 id="fetchUpToMaxBytes"><a href="#fetchUpToMaxBytes" class="headerlink" title="fetchUpToMaxBytes"></a>fetchUpToMaxBytes</h4><p>上面我们也简单的提了一下，这个方法就是读取最大限度的数据（但是要整读，不会读取半个block的数据，要么不读，要读取完成的block）。<br>这个方法的实现其实也比较简单，基本的思路就是在准备发送请求之前，先验证一下是否可以发送，如果可以则调用send方法，如果不可以，则将请求加入到延迟队列中。所以从上面的话中，大家可以了解到，这个数据会操作两个队列 fetchRequests 和 deferredFetchRequests，从代码来看，程序会先从deferredFetchRequest队列中拿请求处理，如果这个队列中没有请求或请求都不符合发送才会去fetchRequest队列中拿请求，实际处理刚开始的时候deferredFetchRequest必然是空的，只有当处理fetchRequest中的请求不符合发送条件的时候才会加入到deferredFetchRequest中，但是这两个队列的数据结构还是不一样的，fetchRequest存放的是FetchRequest(BlockManagerId, Seq[(BlockId, Long)])对象，也就是存储的是BlockManagerId-&gt;Block列表的映射关系，BlockManagerId可以简单的理解为存储Block的远程地址；而deferredFetchRequest，存放的是BlockManagerId -&gt; Queue[FetchRequest]的映射，也就是说在添加到deferredFetchRequest的时候根据BlockManagerId进行整合汇总了。<br>此方法的流程图如下：<br><img src="/attach/5c3e9749e5126.png" alt="image.png"><br>从图中，我们也看到了在这个方法对每个地址正在拉取block的数量(numBlocksInFlightPerAddress)、正在拉取数据的数据量(bytesInFlight)和正在拉取数据的请求个数(reqsInFlight)的使用。<br>在进入fetchUpToMaxBytes方法后，首先会遍历deferredFetchRequests集合中的数据，这里需要注意的是，这个数据根据BlockManagerId进行了汇总，key是BlockManagerId，value是一个FetchRequest的Queue。首先调用isRemoteBlockFetchable方法验证队列是否是可拉取的（主要判断当前最大同时数据拉取量和最大同时请求数）。然后使用isRemoteAddressMaxedOut方法验证要发送的请求是否达到了远程地址最大同时拉取数量。如果验证都符合条件，则将FetchRequest交给send方法来进行请求的发送。</p>
<h4 id="next-1"><a href="#next-1" class="headerlink" title="next"></a>next</h4><p>next方法是Iterator接口的方法，也是用户用来获取数据的方法。<br>因为我们已经知道了sendRequest方法的BlockFetchingListener对象在收到数据拉取成功或失败后会向results（LinkedBlockingQueue）中写入一个SuccessFetchResult或FailedFetchResult，如果是SuccessFetchResult，则会在其中包含一个ManagerBuffer，也就是我们想要的数据。所以next方法获取数据就是从results中拉取数据，又因为results是阻塞队列，所以当results中没有数据的时候，就会被take方法所阻塞，直到拿到数据进行处理。<br>如果从results拿到的数据为FailedFetchResult，则会抛出异常信息，导致拉取失败。<br>如果从results拿到的数据为SuccessFetchResult，那么我们就可以进行处理了，首先，因为这个block已经拉取完毕了，所以相关计数器（如正在拉取数据的数据量bytesInFlight）的计数需要进行更新。<br>对相关计数器操作完成，就会从ManagerBuffer中获取输入流，然后调用serializerManager.wrapStream方法进行数据流的加密和压缩。接着会根据配置（数据流确实被加密或压缩了 、数据量较小）来决定是否要将输入流转换为ChunkedByteBufferInputStream。<br>最后，返回blockId以及使用BufferReleasingInputStream包装的输入流（包装后可以带调用ShuffleBlockFetcherIterator中的清理方法来进行清理工作）。<br><img src="/attach/5c3eb7bc0bfcf.png" alt="image.png"></p>
<h4 id="initialize"><a href="#initialize" class="headerlink" title="initialize"></a>initialize</h4><p>上面的介绍的这些方法都是在从远程节点拉取数据。其实ShuffleBlockFetcherIterator也会读取本地的数据，但是在生成ShuffleBlockFetcherIterator的时候会对Block进行拆分。而这一切是从initialize方法开始的。<br><img src="/attach/5c3ee2f7ef0af.png" alt="image.png"><br>方法的逻辑很简单，显示注册一个Task完成事件，用来调用cleanup方法进行清理工作。然后调用splitLocalRemoteBlocks()方法，将远程Block和本地Block进行拆分，并将拆分后的远程Block打散放入fetchRequest队列中（供fetchUpToMaxBytes()使用）。接着分别调用fetchUpToMaxBytes()和fetchLocalBlocks()方法。</p>
<h4 id="splitLocalRemoteBlocks"><a href="#splitLocalRemoteBlocks" class="headerlink" title="splitLocalRemoteBlocks"></a>splitLocalRemoteBlocks</h4><p>方法的逻辑也相对简单，遍历blocksByAddress（类型为Seq[(BlockManagerId, Seq[(BlockId, Long)]]，BlockManagerId代表了一个远程地址，这个地址上存折多个Block，这里以(BlockId，Block的size)来表示）（这里的blocksByAddress是通过mapOutputTracker（通过SparkEnv.get.mapOutputTracker得到）的getMapSizesByExecutorId方法得到的）中的数据。<br>遍历数据时，会拿到BlockManagerId和这个BlockManager上的Block列表。通过BlockManagerId，能够得到executorId，对这个executorId与本地SparkEnv中的BlockManager中的executor进行比较，就可以判断这个BlockManagerId是否是本地的了（BlockManager中的executorId就相当于BlockManager的唯一ID了）。如果是本地的，将Block列表加入到localBlocks集合中（对于size为0的Block直接丢掉，无需拉取），后面fetchLocalBlocks方法会对这个集合进行处理。对于远程，需要对远程BlockManager中的每个Block进行遍历，这样做的目的是为了拆分FetchRequest（可能会将一个BlockManager中的多个Block分不同的请求来拉取）。</p>
<p><img src="/attach/5c3f1bed65ff7.png" alt="image.png"></p>
<p>从代码中对于FetchRequest的拆分，我们可以了解到在配置spark.reducer.maxSizeInFlight参数的时候，这个参数的最小值应该为一个Block的大小，否则后面没法发送请求，因为任何一个数据的大小都会超过限制，而FetchRequest的拆分是以Block为单位的，一个FetchRequest最少含有一个Block。</p>
<h4 id="fetchLocalBlocks"><a href="#fetchLocalBlocks" class="headerlink" title="fetchLocalBlocks"></a>fetchLocalBlocks</h4><p>fetchLocalBlocks的逻辑很简单，基本流程如下：<br><img src="/attach/5c3f1e5e644c7.png" alt="image.png"><br>此方法就是遍历localBlocks中的数据，并调用本地的BlockManger获取数据，然后将包装为一个FetchResult放到results中，供next方法使用。<br>如果在获取本地Block时发生异常，则推送results时推送的是FailureFetchResult，否则推送的是SuccessFetchResult。</p>
<p>至此，ShuffleBlockFetcherIterator的处理逻辑就介绍完了。</p>
<h3 id="shuffleWriter到shuffleReader的调用链"><a href="#shuffleWriter到shuffleReader的调用链" class="headerlink" title="shuffleWriter到shuffleReader的调用链"></a>shuffleWriter到shuffleReader的调用链</h3><p>我们已经知道了BlockStoreShuffleReader作为ShuffleReader进行数据读取，read方法返回Iterator对象。那么调用这个read方法的流程是什么样的呢？简单的流程图如下：<br><img src="/attach/5c3ff1431fbb5.png" alt="image.png"><br>基本流程就是在执行task的时候，会使用ShuffleWriter来写数据，写数据的时候就会调用RDD的iterator来读取数据。在使用iterator读取数据的时候会根据存储级别来确定调用getOrCompute()方法还是computeOrReadCheckpoint()方法，当RDD的存储级别不为NONE的时候就会调用getOrCompute()方法。但是这两个方法都会调用到computeOrReadCheckpoint()方法，然后调用ShuffleRDD的compute()方法，最终调用到了ShuffleReader的read()方法。所以接下来我们要看看ShuffleWriter的流程。</p>
<h3 id="ShuffleWriter"><a href="#ShuffleWriter" class="headerlink" title="ShuffleWriter"></a>ShuffleWriter</h3><p>ShuffleWriter的获取，ShuffleWriter是调用ShuffleManager(SparkEnv.get.shuffleManager)的getWriter方法得到的。调用getWriter方法的时候会传递dep.shuffleHandle作为参数，因为方法中会根据shuffleHandle的类型，生成不同类型的ShuffleWriter。<br><img src="/attach/5c3ff9cfa7f77.png" alt="image.png"><br>接下来，我们具体分析一下ShuffleWriter的write方法（以简单的SortShuffleWriter为例）。</p>
<h4 id="SortShuffleWriter-write"><a href="#SortShuffleWriter-write" class="headerlink" title="SortShuffleWriter.write"></a>SortShuffleWriter.write</h4><p>此方法的逻辑也比较简单。首先生成ExternalSorter，根据dependency.mapSideCombine来确定生成的ExternalSorter是否含有聚合器（如果为true则含有）。<br>然后调用sorter.insertAll将read返回的Iterator插入到上面生成的ExternalSorter中。<br>接着，使用IndexShuffleBlockResolver（其中包含BlockManager，因此可以管理Block），根据shuffleId和partitionId创建shuffle的数据文件，同时创建这个数据文件的临时文件（在数据文件后面加一个随机的后缀）。<br>然后调用sorter.writePartitionedFile方法，将sorter中的数据写到上面的临时文件中。接着根据临时文件写索引文件，并将临时文件调整为正式文件，通过调用shuffleBlockResolver.writeIndexFileAndCommit方法来实现（此方法中会对数据文件和索引文件进行验证）。<br>write方法比较简单，对于分类器ExternalSorter，我们在ShuffleReader和ShuffleWriter中都看到了，shuffle过程数据的混洗也是这样完成的吧。<br>write方法中使用shuffleBlockResolver做了两件事：获取数据文件（getDataFile）和写索引文件（writeIndexFileAndCommit）。接下来我们对这两个方法也一并分析一下。</p>
<h4 id="IndexShuffleBlockResolver-getDataFile"><a href="#IndexShuffleBlockResolver-getDataFile" class="headerlink" title="IndexShuffleBlockResolver.getDataFile"></a>IndexShuffleBlockResolver.getDataFile</h4><p><img src="/attach/5c40545e9e2c3.png" alt="image.png"><br>方法的实现很简单吧。就是调用BlockManager中的DiskBlockManager去获取文件，如果没有，则生成一个文件并返回（关于DiskBlockManager操作文件的逻辑可以参考内存分析章节）。</p>
<h4 id="shuffleBlockResolver-writeIndexFileAndCommit"><a href="#shuffleBlockResolver-writeIndexFileAndCommit" class="headerlink" title="shuffleBlockResolver.writeIndexFileAndCommit"></a>shuffleBlockResolver.writeIndexFileAndCommit</h4><p>这个方法逻辑稍微复杂一些，先是根据shuffleId和partitionId创建索引文件和索引临时文件。然后根据sorter.insertAll方法返回的文件每个分区的长度，写到索引临时文件中。索引文件指定了数据文件中每个partition的起止offset（sorter.insertAll方法，我们有机会在深入分析）。到这里需要注意，刚刚写的数据文件和索引文件，都是写入到临时文件中的，因为数据文件和索引文件可能已经存在了（因为一个task可能有多个尝试在同时执行），所以接下来就会对索引文件和数据文件（注意这里不是临时文件）进行验证（调用checkIndexAndDataFile方法）。验证成功，则表示有task的其他尝试已经完成了文件的写入，直接将索引临时文件和数据临时文件删除即可；如果验证失败，则将已有的数据文件和索引文件删除，将我们上面生成的索引临时文件和数据临时文件重命名为正式的索引文件和数据文件。<br>缺少一个流程图。。。。。。TODO</p>
<p>至此，数据的写入逻辑也就介绍完了，另外两种Writer的write实现，有机会再补充。</p>
<h3 id="ShuffleClient"><a href="#ShuffleClient" class="headerlink" title="ShuffleClient"></a>ShuffleClient</h3><p>在sendRequest方法中，我们调用了ShuffleClient对象来拉取Blocks。有个细节肯定没有忘记，就是会根据此次请求要拉取数据的大小来决定是否会传递TempShuffleFileManager，这个TempShuffleFileManager有什么用，我们会在分析的时候看到它的作用。另外，还有一个问题：ShuffleClient是如何得到的，具体的实现类是哪个？<br>从生成ShuffleBlockFetcherIterator是，我们知道ShuffleClient是调用BlockManager的shuffleClient方法得到的。<br><img src="/attach/5c3f269fe5441.png" alt="image.png"><br>代码逻辑很简单，根据配置“spark.shuffle.service.enabled”来确定使用ExternalShuffleClient作为ShuffleClient，还是使用BlockTransferService。因为我们开启了此参数，所以我们会针对ExternalShuffleClient进行分析。生成ExternalShuffleClient的时候会需要一个SparkTransportConf</p>
<h3 id="整个过程中所使用的配置"><a href="#整个过程中所使用的配置" class="headerlink" title="整个过程中所使用的配置"></a>整个过程中所使用的配置</h3><table>
<thead>
<tr>
<th>配置参数</th>
<th>默认值</th>
<th>参数作用</th>
<th>使用位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark.reducer.maxSizeInFlight</td>
<td>48M</td>
<td>控制该节点可以同时拉取多大量的数据（所有请求同时拉取数据的字节数）</td>
<td>1、isRemoteBlockFetchable方法中验证正在拉取的数据的数据量。2、在splitLocalRemoteBlocks方法中，用于拆分FetchRequest（当一个地址上的多个Block的总大小超过该值的五分之一的时候，就把这些Block拆到多个FetchRequest中）。</td>
</tr>
<tr>
<td>spark.reducer.maxReqsInFlight</td>
<td>Int.MaxValue</td>
<td>控制节点同时可以发送的请求数，超过这个数的请求，将被放到deferredFetchRequests中</td>
<td>isRemoteBlockFetchable方法中验证当前正在拉取数据的请求数</td>
</tr>
<tr>
<td>spark.reducer.maxBlocksInFlightPerAddress</td>
<td>Int.MaxValue</td>
<td>一个远程节点，可以同时拉取Block的个数</td>
<td>1、isRemoteAddressMaxedOut方法中检查某个远程地址上正在拉取的block的数量是否超出最大值。2、在splitLocalRemoteBlocks方法中，当一个地址（BlockManagerId）上拥有的Block个数超过该值时，为了可以提交send方法，需要将这些Block拆分到多个FetchRequest中</td>
</tr>
<tr>
<td>spark.shuffle.detectCorrupt</td>
<td>true</td>
<td>如果此参数为true，会将ManagerBuffer得到的输入流转换为ChunkedByteBufferInputStream类型</td>
<td>在shuffleBlockFetcherIterator的next方法中</td>
</tr>
<tr>
<td>spark.shuffle.compress</td>
<td>true</td>
<td>shuffle数据是否进行压缩</td>
<td>在next方法调用serializerManager.wrapStream方法时会验证</td>
</tr>
<tr>
<td>spark.shuffle.service.enabled</td>
<td>false</td>
<td>是否启用shuffleService</td>
<td>如果启用了，则生成ExternalShuffleClient对象作为ShuffleClient，否则使用BlockTransferService.我们开启了此参数</td>
</tr>
</tbody>
</table>
<h1 id="一些有趣的东西"><a href="#一些有趣的东西" class="headerlink" title="一些有趣的东西"></a>一些有趣的东西</h1><h2 id="去哪里可以得到shuffle数据的分布？"><a href="#去哪里可以得到shuffle数据的分布？" class="headerlink" title="去哪里可以得到shuffle数据的分布？"></a>去哪里可以得到shuffle数据的分布？</h2><p>答案是MapOutputTracker，通过SparkEnv.get.mapOutputTracker就可以得到MapOutputTracker对象。<br>比如：mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition) 就可以得到shuffleId阶段，根据ExecutorId聚合后的Block信息。</p>
<h1 id="读写流程的整合"><a href="#读写流程的整合" class="headerlink" title="读写流程的整合"></a>读写流程的整合</h1><p><img src="/attach/5c3d87a7dd187.png" alt="image.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/12/07/spark-2-11-storage/" itemprop="url">
                  spark-2.11-storage
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-12-07T11:59:01+08:00" content="2018-12-07">
              2018-12-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Spark存储管理在Spark执行application时担负这数据的传递、存储的重要职责。因此了解Spark的存储机制对于理解Spark的数据操作和性能的优化有着很重要的作用，本文以粗粒度方式来探究一下Spark的存储（最主要是内存）。由于在Spark中任务的执行、数据的传输均是发生在Executor端，因此本文只关注Executor端的存储操作。</p>
<h1 id="1、内存模式-On-heap与Off-heap"><a href="#1、内存模式-On-heap与Off-heap" class="headerlink" title="1、内存模式 On-heap与Off-heap"></a>1、内存模式 On-heap与Off-heap</h1><p>因为Executor是运行在JVM上的，所以Executor最直接的就是操作On-heap内存，但是除此之外，Spark还引入了Off-heap内存的使用，使Spark可以直接操作JVM之外的系统内存，并对此操作进行了优化。<br><img src="/attach/pimg_5c079127d675e.png"><br>该图中关于task共享Executor内存的较少我们将在后续介绍，这里只需要关注On-heap和Off-heap的区别即可。</p>
<h2 id="1-1、堆内内存-On-heap"><a href="#1-1、堆内内存-On-heap" class="headerlink" title="1.1、堆内内存 On-heap"></a>1.1、堆内内存 On-heap</h2><p>堆内内存的大小通过参数 –executor-memory 或 配置spark.executor.memory来控制。Spark对堆内内存的管理是一种计数上的管理，因为对对象的创建和销毁实际是由JVM来具体操作的，Spark无法准确的控制这些，因此它只是从计数（空间使用量）的角度来管理堆内内存。</p>
<h2 id="1-2、堆外内存-Off-heap"><a href="#1-2、堆外内存-Off-heap" class="headerlink" title="1.2、堆外内存 Off-heap"></a>1.2、堆外内存 Off-heap</h2><p>为了进一步优化内存的使用进而提高Shuffle的执行效率，Spark引入了堆外内存（Off-heap），使得Spark可以使用Executor上的系统内存。默认堆外内存是不可用的，可以通过 spark.memory.offHeap.enabled来进行开启。通过JDK Unsafe API，Spark能够直接操作系统内存，因此可以精确的控制堆外内存的申请和销毁。</p>
<h2 id="1-3、内存的统一管理"><a href="#1-3、内存的统一管理" class="headerlink" title="1.3、内存的统一管理"></a>1.3、内存的统一管理</h2><p>Spark对于内存的管理使用统一的抽象接口MemoryManager。它负责Spark的内存申请、释放以及不同用途内存之间的转换。对于内存管理的实现，Spark主要基于两种内存管理：静态内存管理模式（StaticMemoryManager）和统一内存管理模式（unifledMemoryManager）。从Spark 2.0开始，默认使用的内存管理模式为 统一内存管理模式（unifledMemoryManager）。如果想要使用静态内存管理模式，可以将 spark.memory.useLegacyMode 配置设置为true。</p>
<h1 id="2、内存的用途分类"><a href="#2、内存的用途分类" class="headerlink" title="2、内存的用途分类"></a>2、内存的用途分类</h1><p>从内存的使用来看，Spark对内存的使用主要在两个方面：数据执行和数据存储，所以我们堆内存的划分也就分为执行内存和存储内存。执行内存主要用于shuffle、join、sorts和aggregation的消耗，而存储内存主要用于数据的缓存和集群内数据的传输。在Spark内存管理中，执行内存和存储内存的大小是通过参数 spark.memory.storageFraction 来指定的，执行内存和存储内存之和就是Executor的可用内存（对于On-heap内存，含有other部分）。</p>
<h2 id="2-1、堆内内存中执行内存与存储内存的计算"><a href="#2-1、堆内内存中执行内存与存储内存的计算" class="headerlink" title="2.1、堆内内存中执行内存与存储内存的计算"></a>2.1、堆内内存中执行内存与存储内存的计算</h2><p>对于堆内内存，我们首先要介绍几个概念：</p>
<table>
<thead>
<tr>
<th>概念</th>
<th>解释／取值</th>
</tr>
</thead>
<tbody>
<tr>
<td>系统内存</td>
<td>可以理解为JVM的内存，如果设置了spark.testing.memory，则使用，否则Runtime.getRuntime.maxMemory</td>
</tr>
<tr>
<td>系统预留内存</td>
<td>系统预留的内存，依次spark.testing.reservedMemory &gt; spark.testing则为0 取值，默认为300（300 <em> 1024 </em> 1024）</td>
</tr>
<tr>
<td>最小系统内存</td>
<td>系统预留内存的1.5左右</td>
</tr>
<tr>
<td>可用内存</td>
<td>系统内存 - 预留系统内存</td>
</tr>
<tr>
<td>最大内存</td>
<td>可以被Spark使用的内存（执行内存和存储内存之和）。可用内存 * spark.memory.fraction（默认为0.6，我们集群的配置为0.7）</td>
</tr>
</tbody>
</table>
<p>最大内存又分成了存储内存和执行内存。存储内存在最大内存中的占比通过spark.memory.storageFraction（默认为0.5）配置来指定，其余的为执行内存。这里额外介绍一个细节，如果 spark.executor.memory配置的值小于 最小系统内存，executor是无法启动的。<br><img src="/attach/pimg_5c07a49aee1d7.png"></p>
<h2 id="2-2、堆外内存中执行内存和存储内存的计算"><a href="#2-2、堆外内存中执行内存和存储内存的计算" class="headerlink" title="2.2、堆外内存中执行内存和存储内存的计算"></a>2.2、堆外内存中执行内存和存储内存的计算</h2><p>堆外内存的大小是通过spark.memory.offHeap.size配置指定的。堆外内存比较简单，它不存在其他部分的内存分配，内部直接分为存储内存和执行内存。堆外存储内存所占比例同样通过配置spark.memory.storageFraction（默认0.5）来指定。<br><img src="/attach/pimg_5c07a4b15897b.png"><br>对于堆内存储内存和堆外存储内存，彼此之间是相互独立的，执行内存也是如此。</p>
<h2 id="2-3、存储级别"><a href="#2-3、存储级别" class="headerlink" title="2.3、存储级别"></a>2.3、存储级别</h2><p>我们已经知道了内存模式分为Off-heap和On-heap，而根据内存的用途有分为存储内存和执行内存。因此对于数据的存储，Spark从一下几个因素定义了存储级别（StorageLevel）：</p>
<blockquote>
<ol>
<li>磁盘/内存</li>
<li>堆内/堆外</li>
<li>序列化/不序列化</li>
<li>有副本/没有副本</li>
</ol>
</blockquote>
<p>有了存储级别，就能够明确的说明数据存储的位置、数据存储的方式以及数据存储的个数。</p>
<h1 id="3、静态内存管理与统一内存管理"><a href="#3、静态内存管理与统一内存管理" class="headerlink" title="3、静态内存管理与统一内存管理"></a>3、静态内存管理与统一内存管理</h1><p>最初Spark的采用的是静态内存管理，在2.0的版本中，Spark开始默认使用统一内存管理来进行内存管理。静态内存管理和统一内存管理的区别，可以简单的从执行内存和存储内存能否相互借用来区别。因为我们系统也是使用默认的统一内存管理来对内存进行管理，顾暂时不对静态内存管理进行理解。</p>
<h2 id="3-1、统一内存管理"><a href="#3-1、统一内存管理" class="headerlink" title="3.1、统一内存管理"></a>3.1、统一内存管理</h2><p>相对于静态内存，统一内存增加了动态占用机制的优化，其规则如下：</p>
<blockquote>
<p>1、通过配置项spark.memory.storageFraction，对存储内存和执行内存进行基本值的划分。<br>2、当存储内存不够、执行内存充足时，可以增加存储内存的容量，减少执行内存的容量。反之亦然。<br>3、当存储不够且执行也不充足时，存储数据落盘。执行不够且存储也不够时，执行阻塞或失败。<br>4、当存储占用执行时，执行可要求存储归还，存储不够的可以落盘；当执行占用存储时，存储无法要求执行归还，只能删除数据或落盘。</p>
</blockquote>
<p><img src="/attach/pimg_5c07afb32d3a0.png"></p>
<h2 id="3-2-动态占用机制的实现"><a href="#3-2-动态占用机制的实现" class="headerlink" title="3.2 动态占用机制的实现"></a>3.2 动态占用机制的实现</h2><p>上面我们提到了统一内存管理的动态占用机制，它可以更加充分的使用内存，那么这种机制是如何实现的呢？上面我们也说过，Spark其实是无法精确操作内存的，而是使用了类似计数管理的方式来实现的。<br>因此，在Spark的底层实现中，它为每种内存都创建了与之对应的内存池（执行内存池和存储内存池，但是存储模式又分为堆内和堆外，所以共有四种内存池），内存池记录了对应内存的使用量和容量。</p>
<h3 id="3-2-1-MemoryManager"><a href="#3-2-1-MemoryManager" class="headerlink" title="3.2.1 MemoryManager"></a>3.2.1 MemoryManager</h3><p>对于内存池的封装，是由 MemoryManager来实现，在其内部维持着四种内存池的引用。<br><img src="/attach/pimg_5c07bd672b531.png"><br>其中只有相同内存模式的不同内存之间可以动态占用，如：OnHeapStorageMemoryPool只可以和 OnHeapExecutionMemoryPool 相互占用。另外需要注意的是，内存的总大小（执行内存和存储内存之和）一旦确定是无法修改的，虽然可以调整某个内存的大小，但是总的大小是不变的。<br>MemoryManager（UnifiedMemoryManager）主要的职责就是根据需要调整各自内存池的容量、计算各自内存池的当前使用量以及分配使用量。</p>
<h1 id="4、存储内存的管理"><a href="#4、存储内存的管理" class="headerlink" title="4、存储内存的管理"></a>4、存储内存的管理</h1><p>存储内存最主要的使用就是数据缓存（RDD进行持久化保存）和集群内的数据传输（数据的广播）。而且我们前面也介绍了存储级别，还需要介绍一个其他的概念：Block。对于Block的理解，可以先简单的将数据的parition理解为一个Block，但是在存储过程中Block是由类型的（通过BlockId进行验证）：<br><img src="/attach/pimg_5c07c4739522a.png" alt="pimg_5c07c4739522a.png"><br>从上图可以看出，BlockId由众多的子类，而属于哪种类别的BlockId，就是通过字符串模式匹配来决定的。<br>这里我们为什么要介绍Block呢？因为数据缓存就是以Block方式存储的。<br>在Spark中Storage模块负责Spark在计算过程中产生的数据，对数据的读写进行了统一的封装（包括从内存、磁盘、本地、远程）。在代码架构上，BlockManager分为Master和Salve。Dirver上运行的是Master，Executor上运行的是Slave，两者之间相同通信对数据块（Block）进行管理。</p>
<h2 id="4-1、-具体的实现"><a href="#4-1、-具体的实现" class="headerlink" title="4.1、 具体的实现"></a>4.1、 具体的实现</h2><p>在MemoryStore中，保持一个entries对象，它是一个LinkedHashMap[BlockId, MemoryEntry[_]]对象。MemoryEntry是一个接口，它有两个实现：DeserializedMemoryEntry 和 SerializedMemoryEntry，分别处理非序列化数据和序列化数据的保存。当由此，也就明白了存储级别（StorageLevel）中序列化和非序列化的意义了。当数据向内存中缓存数据时，其实就是将数据保存到enties中，但是与普通生成兑现不太一样，他会以连续的内存来保存，也就是说一个Block内的数据，从内存上来看是连续存储的（序列化的数据很好理解，序列化之后，对象就是一串字节数，但是对于非序列化的对象，其内部会有一个转换操作）。</p>
<h1 id="5、执行内存的管理"><a href="#5、执行内存的管理" class="headerlink" title="5、执行内存的管理"></a>5、执行内存的管理</h1><p>执行内存最主要的使用就是shuffle、sorts、aggregate等操作的时候被使用。而排序和聚合其实都是以shuffle的结果来进行操作然后写出数据，所以我们先从Shuffle的存储进行分析。</p>
<h2 id="5-1、-Shuffle执行内存的使用"><a href="#5-1、-Shuffle执行内存的使用" class="headerlink" title="5.1、 Shuffle执行内存的使用"></a>5.1、 Shuffle执行内存的使用</h2><p>shuffle操作是RDD之间的一种数据转换，从上一个RDD中读取，写入到下一个RDD中，因此我们将从读写两个方面来分析一下：</p>
<h2 id="5-1-1、-shufflerReader"><a href="#5-1-1、-shufflerReader" class="headerlink" title="5.1.1、 shufflerReader"></a>5.1.1、 shufflerReader</h2><p>Spark的shuffle操作是由ShuffleManager（由子类SortShuffleManager进行实现）进行操作的。ShuffleManager要读取数据就需要获取Reader，从而得到BlockStoreShuffleReader，BlockStoreShuffleReader调用read()方法进行数据读取。ShuffleManager可以通过配置项spark.shuffle.manager进行设置（默认为sort，可选的值有sort和tungsten-sort）：</p>
<table>
<thead>
<tr>
<th>spark.shuffle.manager的取值</th>
<th>所代表的类</th>
</tr>
</thead>
<tbody>
<tr>
<td>sort</td>
<td>org.apache.spark.shuffle.sort.SortShuffleManager</td>
</tr>
<tr>
<td>tungsten-sort</td>
<td>org.apache.spark.shuffle.sort.SortShuffleManager</td>
</tr>
</tbody>
</table>
<p>这里需要引入以概念：ShuffleClient，它是实际拉取数据的客户端。在Spark内部存在两种ShuffleClient：BlockTransferService和ExternalShuffleClient。如果配置项 spark.shuffle.service.enabled 为true（默认为false），则启用ExternalShuffleClient（比如我们的集群，就启用了这个配置）。<br>在生成ExternalShuffleClient的需要SparkTransportConf，该配置有两个比较重要的配置：</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>意义</th>
<th>取值</th>
</tr>
</thead>
<tbody>
<tr>
<td>spark.shuffle.io.serverThreads</td>
<td>stage之间TransServer的线程数</td>
<td>用户设定，默认与可用的core的数量相同</td>
</tr>
<tr>
<td>spark.shuffle.io.clientThreads</td>
<td></td>
<td>用户设定，默认与可用的core的数量相同</td>
</tr>
</tbody>
</table>
<p>可用core的数量为：用户指定core数、运行时可用core数 以及 数字8 中最小的那个值（如果用户指定的数不是0，则使用用户指定的数和8中最小的值，否则就是可用core数和8中最小的那个）。我们集群没有对此进行配置，因此会使用JVM可用的core数进行设置，但是不会超过8个。<br>ExternalShuffleClient中重要的方法就是fetchBlock方法。在fetchBlock方法，会创建连接到目标host和port的TransportClient，然后利用这个client生成OneForOneBlockFetcher来拉取指定executor上（通过参数execId）指定的block（通过blockIds指定）。&gt;_&lt; 到这里都没有看到内存的使用。。。醉了<br>突然一个不小心，原来OneForOneBlockFetcher中使用了一个参数 TempShuffleFileManager，它是一个接口，实现类为 ShuffleBlockFetcherIterator。这个类中有一个方法 createTempShuffleFile()。那么我们就看看，OneForOneBlockFetcher 是否将数据写到了临时文件吧（山路十八弯呀）。通过跟踪代码，果然是将远程的数据写入到个临时文件中。但是当数据写完之后，这个文件会被用来生成一个ManagedBuffer（具体类为FileSegmentManagerBuffer），对于这个ManagedBuffer的操作会交给listener进行处理，这个linstener就又指向了ShuffleBlockFetcherIterator中的 BlockFetchingListener，调用它的onBlockFetchSuccess方法。在新的方法中，ManagerBuffer作为一个SuccessFetchResult对象被推送到results中（一个LinkedBlockingQueue队列）。我们已经知道这个方法是在 ShuffleBlockFetcherIteraotr中，而这个类本身就是Iterator，所以对上面的队列的读取，就发生在Iterator的next()方法中。继续回到生成ShuffleBlockFetcherIteraotr的地方BlockStoreShuffleReader.read()中。在read方法中，又继续对数据进行了处理，怎么处理的呢，当然从字节流被转换为对象（进行解序列化操作），但是read返回的依旧是一个迭代器（Iterator）。因为shuffle操作肯定对需要一种聚合手段，这里采用了ExternalAppendOnlyMap进行聚合操作。如果还需要排序，则使用进一步使用ExternalSorter对象进行操作。这两个类好复杂，慢慢在看（也就是这两对象的操作会占用内存）。</p>
<h3 id="5-1-2、ShuffleWriter"><a href="#5-1-2、ShuffleWriter" class="headerlink" title="5.1.2、ShuffleWriter"></a>5.1.2、ShuffleWriter</h3><p>shuffleWriter的调用是在ShuffleMapTask的runTask中触发的（这也很好理解，只要在执行task结束的时候才需要写数据呀），而且我们也知道，对于Task只分为两种类型ShuffleMapTask和ResultTask，因为是了解shuffle部分，所以我们只关注ShuffleMapTask，至于ResultTask以后再继续。<br>至于获取ShuffleWriter，是根据ShuffleDependency中shuffleHandle的类型所有决定的，不同的handler会生成不同的Writer：</p>
<table>
<thead>
<tr>
<th>handler类型</th>
<th>与之对应的writer</th>
</tr>
</thead>
<tbody>
<tr>
<td>unsafeShuffleHandle</td>
<td>UnsafeShuffleWriter</td>
</tr>
<tr>
<td>bypassMergeSortHandle</td>
<td>BypassMergeSortShuffleWriter</td>
</tr>
<tr>
<td>其他</td>
<td>SortShuffleWriter</td>
</tr>
</tbody>
</table>
<p>我们选择一个较为简单的Writer吧，就看SortShuffleWriter。对于Writer来说，最重要的方法必然是write。于是我们就在方法中看到了获取数据文件、生成BlockId、写文件的操作。<br><img src="/attach/pimg_5c09e4c7151a3.png" alt="pimg_5c09e4c7151a3.png"><br>从目前来看，shuffle的写操作，写的是文件，而非内存，但是从文档或其他人的文章都提到有写内存的，应该是我还没有看到，会后续补充。</p>
<h1 id="5-2、task执行内存的分配"><a href="#5-2、task执行内存的分配" class="headerlink" title="5.2、task执行内存的分配"></a>5.2、task执行内存的分配</h1><p>Executor内部是以多线程的方式执行task，要启动一个task其实就是将TaskRunner放到Executor内部的线程池中执行。既然，task是在Executor中运行，多task在运行期间，执行内存是如何分配的呢？Spark在执行内存池中维持了一个HashMap用来记录每个task所占用的内存。每个task允许使用的内存范围为 maxPoolSize/2N ~ maxPoolSize/N（N为当前活跃的Task数， maxPoolSize是执行内存池的最大空间），注意该限制只是在申请资源的时候验证，当申请资源的时候，如果可以分配给task的内存小于最小值，则会使申请资源的操作进入等待状态，等到有其他任务释放内存的时候，会被再次唤醒。<br><img src="/attach/pimg_5c08aca616f57.png" alt="pimg_5c08aca616f57.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/10/19/spark-2-11-ExecutorRunnable/" itemprop="url">
                  spark-2.11-ExecutorRunnable
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-10-19T11:45:12+08:00" content="2018-10-19">
              2018-10-19
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是对 org.apache.spark.deploy.yarn.ExecutorRunnable 源码进行学习的分析，spark版本为2.11。</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>这个方法就是用来启动container的。准备环境、生成命令，发送给NMClient。</p>
<h1 id="NMClient"><a href="#NMClient" class="headerlink" title="NMClient"></a>NMClient</h1><p>NMClient是Node Manager的客户端。一下是一些常用的方法。</p>
<table>
<thead>
<tr>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">public static NMClient createNMClient()</td>
<td style="text-align:left">创建一个 NMClient实例</td>
</tr>
<tr>
<td style="text-align:left">public void init(Configuration conf)</td>
<td style="text-align:left">初始化 NMClient</td>
</tr>
<tr>
<td style="text-align:left">public void start()</td>
<td style="text-align:left">启动服务</td>
</tr>
<tr>
<td style="text-align:left">public Map<string, bytebuffer=""> startContainer(Container container, ContainerLaunchContext containerLaunchContext) throws YarnException, IOException</string,></td>
<td style="text-align:left">启动一个分配的 contianer</td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/10/17/spark-2-11-ApplicationMaster/" itemprop="url">
                  spark 2.11 ApplicationMaster
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-10-17T19:51:13+08:00" content="2018-10-17">
              2018-10-17
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是对 org.apache.spark.deploy.yarn.ApplicationMaster 源码进行学习的分析，spark的版本为2.11。</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>ApplicationMaster 可以说是运行用户程序的入口类。该类的一些行为有解析用户参数、启动dirver、建立与driver的通信、启动reporter线程、启动用户类等。</p>
<h1 id="主要方法分析"><a href="#主要方法分析" class="headerlink" title="主要方法分析"></a>主要方法分析</h1><h2 id="ApplicationMaster伴生类的main方法"><a href="#ApplicationMaster伴生类的main方法" class="headerlink" title="ApplicationMaster伴生类的main方法"></a>ApplicationMaster伴生类的main方法</h2><p>该方法是ApplicationMaster的启动入口方法，方法定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="comment">// 注册日志</span></div><div class="line">  <span class="type">SignalUtils</span>.registerLogger(log)</div><div class="line"></div><div class="line">  <span class="comment">// 实例化 ApplicationMasterArguments对应，用来解析传入的参数</span></div><div class="line">  <span class="keyword">val</span> amArgs = <span class="keyword">new</span> <span class="type">ApplicationMasterArguments</span>(args)</div><div class="line"></div><div class="line">  <span class="comment">// 是否设置了 --properties-file 参数，如果设置，则将properties文件中的配置加载到系统参数中</span></div><div class="line">  <span class="keyword">if</span> (amArgs.propertiesFile != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="type">Utils</span>.getPropertiesFromFile(amArgs.propertiesFile).foreach &#123; <span class="keyword">case</span> (k, v) =&gt;</div><div class="line">      sys.props(k) = v</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 以指定的用户运行 ApplicationMaster</span></div><div class="line">  <span class="type">SparkHadoopUtil</span>.get.runAsSparkUser &#123; () =&gt;</div><div class="line">    master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, <span class="keyword">new</span> <span class="type">YarnRMClient</span>)</div><div class="line">    <span class="comment">// 运行 application master</span></div><div class="line">    <span class="type">System</span>.exit(master.run())</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从代码可以看出，该方法就是类的启动方法，注册日志、解析传入参数（如果参数传递了properties文件，则将properties中的配置加载到系统中），最后以特殊的用户身份启动ApplicationMaster（调用run方法）。</p>
<h2 id="run"><a href="#run" class="headerlink" title="run"></a>run</h2><p>该方法用来启动applicationMaster，方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Int</span> = &#123;</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// 获取application的id</span></div><div class="line">    <span class="keyword">val</span> appAttemptId = client.getAttemptId()</div><div class="line"></div><div class="line">    <span class="keyword">var</span> attemptID: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></div><div class="line"></div><div class="line">    <span class="comment">// 是否是集群模式，则设置集群模式需要的一些属性</span></div><div class="line">    <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">      <span class="comment">// Set the web ui port to be ephemeral for yarn so we don't conflict with</span></div><div class="line">      <span class="comment">// other spark processes running on the same box</span></div><div class="line">      <span class="type">System</span>.setProperty(<span class="string">"spark.ui.port"</span>, <span class="string">"0"</span>)</div><div class="line"></div><div class="line">      <span class="comment">// Set the master and deploy mode property to match the requested mode.</span></div><div class="line">      <span class="type">System</span>.setProperty(<span class="string">"spark.master"</span>, <span class="string">"yarn"</span>)</div><div class="line">      <span class="type">System</span>.setProperty(<span class="string">"spark.submit.deployMode"</span>, <span class="string">"cluster"</span>)</div><div class="line"></div><div class="line">      <span class="comment">// Set this internal configuration if it is running on cluster mode, this</span></div><div class="line">      <span class="comment">// configuration will be checked in SparkContext to avoid misuse of yarn cluster mode.</span></div><div class="line">      <span class="type">System</span>.setProperty(<span class="string">"spark.yarn.app.id"</span>, appAttemptId.getApplicationId().toString())</div><div class="line"></div><div class="line">      attemptID = <span class="type">Option</span>(appAttemptId.getAttemptId.toString)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// &lt;1&gt;</span></div><div class="line"></div><div class="line">    <span class="comment">// 设置调用上下文，从spark.log.callerContext配置中读取</span></div><div class="line">    <span class="keyword">new</span> <span class="type">CallerContext</span>(</div><div class="line">      <span class="string">"APPMASTER"</span>, sparkConf.get(<span class="type">APP_CALLER_CONTEXT</span>),</div><div class="line">      <span class="type">Option</span>(appAttemptId.getApplicationId.toString), attemptID).setCurrentContext()</div><div class="line"></div><div class="line">    logInfo(<span class="string">"ApplicationAttemptId: "</span> + appAttemptId)</div><div class="line"></div><div class="line">    <span class="comment">// This shutdown hook should run *after* the SparkContext is shut down.</span></div><div class="line">    <span class="comment">// 设置钩子函数，以便在 SparkContext 之后调用，进行操作</span></div><div class="line">    <span class="keyword">val</span> priority = <span class="type">ShutdownHookManager</span>.<span class="type">SPARK_CONTEXT_SHUTDOWN_PRIORITY</span> - <span class="number">1</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="type">ShutdownHookManager</span>.addShutdownHook(priority) &#123; () =&gt;</div><div class="line">      <span class="keyword">val</span> maxAppAttempts = client.getMaxRegAttempts(sparkConf, yarnConf)</div><div class="line">      <span class="keyword">val</span> isLastAttempt = client.getAttemptId().getAttemptId() &gt;= maxAppAttempts</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!finished) &#123;</div><div class="line">        <span class="comment">// The default state of ApplicationMaster is failed if it is invoked by shut down hook.</span></div><div class="line">        <span class="comment">// This behavior is different compared to 1.x version.</span></div><div class="line">        <span class="comment">// If user application is exited ahead of time by calling System.exit(N), here mark</span></div><div class="line">        <span class="comment">// this application as failed with EXIT_EARLY. For a good shutdown, user shouldn't call</span></div><div class="line">        <span class="comment">// System.exit(0) to terminate the application.</span></div><div class="line">        finish(finalStatus,</div><div class="line">          <span class="type">ApplicationMaster</span>.<span class="type">EXIT_EARLY</span>,</div><div class="line">          <span class="string">"Shutdown hook called before final status was reported."</span>)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!unregistered) &#123;</div><div class="line">        <span class="comment">// we only want to unregister if we don't want the RM to retry</span></div><div class="line">        <span class="keyword">if</span> (finalStatus == <span class="type">FinalApplicationStatus</span>.<span class="type">SUCCEEDED</span> || isLastAttempt) &#123;</div><div class="line">          unregister(finalStatus, finalMsg)</div><div class="line">          cleanupStagingDir()</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// &lt;2&gt;</span></div><div class="line"></div><div class="line">    <span class="comment">// Call this to force generation of secret so it gets populated into the</span></div><div class="line">    <span class="comment">// Hadoop UGI. This has to happen before the startUserApplication which does a</span></div><div class="line">    <span class="comment">// doAs in order for the credentials to be passed on to the executor containers.</span></div><div class="line">    <span class="comment">// 根据spark配置生成安全管理器</span></div><div class="line">    <span class="keyword">val</span> securityMgr = <span class="keyword">new</span> <span class="type">SecurityManager</span>(sparkConf)</div><div class="line"></div><div class="line">    <span class="comment">// If the credentials file config is present, we must periodically renew tokens. So create</span></div><div class="line">    <span class="comment">// a new AMDelegationTokenRenewer</span></div><div class="line">    <span class="comment">// spark.yarn.credentials.file</span></div><div class="line">    <span class="keyword">if</span> (sparkConf.contains(<span class="type">CREDENTIALS_FILE_PATH</span>.key)) &#123;</div><div class="line">      <span class="comment">// If a principal and keytab have been set, use that to create new credentials for executors</span></div><div class="line">      <span class="comment">// periodically</span></div><div class="line">      credentialRenewer =</div><div class="line">        <span class="keyword">new</span> <span class="type">ConfigurableCredentialManager</span>(sparkConf, yarnConf).credentialRenewer()</div><div class="line">      credentialRenewer.scheduleLoginFromKeytab()</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// &lt;3&gt;</span></div><div class="line"></div><div class="line">    <span class="comment">// 根据不同的集群模式，调用不同的方法</span></div><div class="line">    <span class="keyword">if</span> (isClusterMode) &#123;</div><div class="line">      runDriver(securityMgr)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      runExecutorLauncher(securityMgr)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// &lt;4&gt;</span></div><div class="line"></div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">      <span class="comment">// catch everything else if not specifically handled</span></div><div class="line">      logError(<span class="string">"Uncaught exception: "</span>, e)</div><div class="line">      finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">        <span class="type">ApplicationMaster</span>.<span class="type">EXIT_UNCAUGHT_EXCEPTION</span>,</div><div class="line">        <span class="string">"Uncaught exception: "</span> + e)</div><div class="line">  &#125;</div><div class="line">  exitCode</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><1> 这部分用来设置一些系统属性，以便后面使用。</1></p>
<p><2> 设置CurrentContext以及钩子方法，以便在sparkContext销毁之后进行清理操作。钩子函数实际上是交给了 SparkShutdownHookManager 对象进行处理。</2></p>
<p><3> 进行安全方面的一些设置，需要后续仔细看。</3></p>
<p><4> 进行服务的启动，这里区分是集群模式（cluster）还是客户端模式（client）。其内部执行的总体步骤是一样的，只是每个步骤的做的方式不同。<br>接下来，先从集群模式来看，然后再看客户端模式。</4></p>
<h2 id="runDriver"><a href="#runDriver" class="headerlink" title="runDriver"></a>runDriver</h2><p>运行deiver，只有集群模式，才会执行这个方法，方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runDriver</span></span>(securityMgr: <span class="type">SecurityManager</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="comment">// 添加IP过滤器</span></div><div class="line">  addAmIpFilter()</div><div class="line">  <span class="comment">// 启动用户Application，就是利用反射机制，运行用户指定的class中的main方法</span></div><div class="line">  userClassThread = startUserApplication()</div><div class="line"></div><div class="line">  <span class="comment">// This a bit hacky, but we need to wait until the spark.driver.port property has</span></div><div class="line">  <span class="comment">// been set by the Thread executing the user class.</span></div><div class="line">  logInfo(<span class="string">"Waiting for spark context initialization..."</span>)</div><div class="line">  <span class="comment">// spark.yarn.am.waitTime</span></div><div class="line">  <span class="keyword">val</span> totalWaitTime = sparkConf.get(<span class="type">AM_MAX_WAIT_TIME</span>)</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// 等待 SparkContext的生成，最多等待 totalWaitTime 毫秒</span></div><div class="line">    <span class="keyword">val</span> sc = <span class="type">ThreadUtils</span>.awaitResult(sparkContextPromise.future,</div><div class="line">      <span class="type">Duration</span>(totalWaitTime, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>))</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (sc != <span class="literal">null</span>) &#123;</div><div class="line">      rpcEnv = sc.env.rpcEnv</div><div class="line">      <span class="comment">// 启动 driver RPC</span></div><div class="line">      <span class="keyword">val</span> driverRef = runAMEndpoint(</div><div class="line">        sc.getConf.get(<span class="string">"spark.driver.host"</span>),</div><div class="line">        sc.getConf.get(<span class="string">"spark.driver.port"</span>),</div><div class="line">        isClusterMode = <span class="literal">true</span>)</div><div class="line"></div><div class="line">      <span class="comment">// 注册Application master</span></div><div class="line">      registerAM(sc.getConf, rpcEnv, driverRef, sc.ui.map(_.webUrl), securityMgr)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// Sanity check; should never happen in normal operation, since sc should only be null</span></div><div class="line">      <span class="comment">// if the user app did not create a SparkContext.</span></div><div class="line">      <span class="keyword">if</span> (!finished) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"SparkContext is null but app is still running!"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 等待 用户线程 的完成</span></div><div class="line">    userClassThread.join()</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">SparkException</span> <span class="keyword">if</span> e.getCause().isInstanceOf[<span class="type">TimeoutException</span>] =&gt;</div><div class="line">      logError(</div><div class="line">        <span class="string">s"SparkContext did not initialize after waiting for <span class="subst">$totalWaitTime</span> ms. "</span> +</div><div class="line">         <span class="string">"Please check earlier log output for errors. Failing the application."</span>)</div><div class="line">      finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">        <span class="type">ApplicationMaster</span>.<span class="type">EXIT_SC_NOT_INITED</span>,</div><div class="line">        <span class="string">"Timed out waiting for SparkContext."</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个方法比较重要，因此需要详细看看。addAmIpFilter方法，从代码来看是给Spark UI增加IP 过滤器的功能，方法中也会对不同的部署模式有不同的区分，对于集群模式，将过滤器信息（过滤器类和参数）设置到系统参数，而对于client模式，则通过RPC服务发送给了driver。由此可见对于集群模式，driver是运行在本地的，而客户端模式，driver是运行在别处的。运行在哪里呢？另外，addAmIpFilter实际上添加的是 org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter 这个Filter。<br>接下来，方法是在独立的线程中启动了用户类（通过–class参数传入的类），启动用户类，其大概的操作就是获取类加载器，利用反射，加载类并最终调用用户类的main方法。<br>接着，获取SparkContext，并通过runAMEndpoint方法得到 driverEndpint，driverEndpoint作为一个参数来向ResourceManager 注册 ApplicationMaster。<br>然后就是向 ResourceManager 注册 ApplcationMaster。<br>最后等待用户类的执行完成。</p>
<h2 id="runExecutorLauncher"><a href="#runExecutorLauncher" class="headerlink" title="runExecutorLauncher"></a>runExecutorLauncher</h2><p>runExecutorLauncher方法与上面的rundirver的地位相同，只是针对client模式的启动方式。方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runExecutorLauncher</span></span>(securityMgr: <span class="type">SecurityManager</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> port = sparkConf.get(<span class="type">AM_PORT</span>)</div><div class="line">  rpcEnv = <span class="type">RpcEnv</span>.create(<span class="string">"sparkYarnAM"</span>, <span class="type">Utils</span>.localHostName, port, sparkConf, securityMgr,</div><div class="line">    clientMode = <span class="literal">true</span>)</div><div class="line">  <span class="keyword">val</span> driverRef = waitForSparkDriver()</div><div class="line">  addAmIpFilter()</div><div class="line">  registerAM(sparkConf, rpcEnv, driverRef, sparkConf.getOption(<span class="string">"spark.driver.appUIAddress"</span>),</div><div class="line">    securityMgr)</div><div class="line"></div><div class="line">  <span class="comment">// In client mode the actor will stop the reporter thread.</span></div><div class="line">  reporterThread.join()</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>此方法相对 rundriver来说就简单多了，首先创建了一个用于连接本机的RpcEnv，然后是等待SparkDriver的启动完成，添加IP Filter（通过amEndpoint发送给driver）。最后向ResourceManager 注册 ApplicationMaster。</p>
<h2 id="registerAM"><a href="#registerAM" class="headerlink" title="registerAM"></a>registerAM</h2><p>此方法用来处理向 ResourceManager 注册 ApplicationMaster。通过这个方法，就将ApplicationMaster与YarnRMClient和YarnAllocator联系起来了。方法定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerAM</span></span>(</div><div class="line">    _sparkConf: <span class="type">SparkConf</span>,</div><div class="line">    _rpcEnv: <span class="type">RpcEnv</span>,</div><div class="line">    driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">    uiAddress: <span class="type">Option</span>[<span class="type">String</span>],</div><div class="line">    securityMgr: <span class="type">SecurityManager</span>) = &#123;</div><div class="line">  <span class="keyword">val</span> appId = client.getAttemptId().getApplicationId().toString()</div><div class="line">  <span class="keyword">val</span> attemptId = client.getAttemptId().getAttemptId().toString()</div><div class="line">  <span class="keyword">val</span> historyAddress =</div><div class="line">    _sparkConf.get(<span class="type">HISTORY_SERVER_ADDRESS</span>)</div><div class="line">      .map &#123; text =&gt; <span class="type">SparkHadoopUtil</span>.get.substituteHadoopVariables(text, yarnConf) &#125;</div><div class="line">      .map &#123; address =&gt; <span class="string">s"<span class="subst">$&#123;address&#125;</span><span class="subst">$&#123;HistoryServer.UI_PATH_PREFIX&#125;</span>/<span class="subst">$&#123;appId&#125;</span>/<span class="subst">$&#123;attemptId&#125;</span>"</span> &#125;</div><div class="line">      .getOrElse(<span class="string">""</span>)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> driverUrl = <span class="type">RpcEndpointAddress</span>(</div><div class="line">    _sparkConf.get(<span class="string">"spark.driver.host"</span>),</div><div class="line">    _sparkConf.get(<span class="string">"spark.driver.port"</span>).toInt,</div><div class="line">    <span class="type">CoarseGrainedSchedulerBackend</span>.<span class="type">ENDPOINT_NAME</span>).toString</div><div class="line"></div><div class="line">  <span class="comment">// Before we initialize the allocator, let's log the information about how executors will</span></div><div class="line">  <span class="comment">// be run up front, to avoid printing this out for every single executor being launched.</span></div><div class="line">  <span class="comment">// Use placeholders for information that changes such as executor IDs.</span></div><div class="line">  logInfo &#123;</div><div class="line">    <span class="keyword">val</span> executorMemory = sparkConf.get(<span class="type">EXECUTOR_MEMORY</span>).toInt</div><div class="line">    <span class="keyword">val</span> executorCores = sparkConf.get(<span class="type">EXECUTOR_CORES</span>)</div><div class="line">    <span class="keyword">val</span> dummyRunner = <span class="keyword">new</span> <span class="type">ExecutorRunnable</span>(<span class="type">None</span>, yarnConf, sparkConf, driverUrl, <span class="string">"&lt;executorId&gt;"</span>,</div><div class="line">      <span class="string">"&lt;hostname&gt;"</span>, executorMemory, executorCores, appId, securityMgr, localResources)</div><div class="line">    dummyRunner.launchContextDebugInfo()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  allocator = client.register(driverUrl,</div><div class="line">    driverRef,</div><div class="line">    yarnConf,</div><div class="line">    _sparkConf,</div><div class="line">    uiAddress,</div><div class="line">    historyAddress,</div><div class="line">    securityMgr,</div><div class="line">    localResources)</div><div class="line"></div><div class="line">  allocator.allocateResources()</div><div class="line">  <span class="comment">// 在 客户端 模式中 的 runExecutorLauncher 方法中join</span></div><div class="line">  reporterThread = launchReporterThread()</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该方法主要就是获取各种参数，然后调用client（YarnRMClient）的register方法进行注册（说是向ResourceManager注册的application，但以我来看，是注册的driver），还有就是启动reporter线程。</p>
<h2 id="launchReporterThread"><a href="#launchReporterThread" class="headerlink" title="launchReporterThread"></a>launchReporterThread</h2><p>用于生成并启动 reporter线程。方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchReporterThread</span></span>(): <span class="type">Thread</span> = &#123;</div><div class="line">  <span class="comment">// The number of failures in a row until Reporter thread give up</span></div><div class="line">  <span class="comment">// 获取配置的 reporter 线程最大失败次数</span></div><div class="line">  <span class="keyword">val</span> reporterMaxFailures = sparkConf.get(<span class="type">MAX_REPORTER_THREAD_FAILURES</span>)</div><div class="line"></div><div class="line">  <span class="keyword">val</span> t = <span class="keyword">new</span> <span class="type">Thread</span> &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">      <span class="keyword">var</span> failureCount = <span class="number">0</span></div><div class="line">      <span class="keyword">while</span> (!finished) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="comment">// 如果 allocator 失败的 executor 个数已经超出了设置的最大值，则 终止 application 的运行（终止用户类的运行）</span></div><div class="line">          <span class="keyword">if</span> (allocator.getNumExecutorsFailed &gt;= maxNumExecutorFailures) &#123;</div><div class="line">            finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">              <span class="type">ApplicationMaster</span>.<span class="type">EXIT_MAX_EXECUTOR_FAILURES</span>,</div><div class="line">              <span class="string">s"Max number of executor failures (<span class="subst">$maxNumExecutorFailures</span>) reached"</span>)</div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="comment">// 向YarnAllocator 申请资源</span></div><div class="line">            logDebug(<span class="string">"Sending progress"</span>)</div><div class="line">            allocator.allocateResources()</div><div class="line">          &#125;</div><div class="line">          failureCount = <span class="number">0</span></div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="comment">// 不同的异常不同的处理，中断异常，有可能是 finish 方法抛出来的</span></div><div class="line">          <span class="keyword">case</span> i: <span class="type">InterruptedException</span> =&gt; <span class="comment">// do nothing</span></div><div class="line">          <span class="keyword">case</span> e: <span class="type">ApplicationAttemptNotFoundException</span> =&gt;</div><div class="line">            failureCount += <span class="number">1</span></div><div class="line">            logError(<span class="string">"Exception from Reporter thread."</span>, e)</div><div class="line">            finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>, <span class="type">ApplicationMaster</span>.<span class="type">EXIT_REPORTER_FAILURE</span>,</div><div class="line">              e.getMessage)</div><div class="line">          <span class="comment">// 如果 reporter 线程的尝试次数超过配置的最大值，则终止 用户类的运行</span></div><div class="line">          <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">            failureCount += <span class="number">1</span></div><div class="line">            <span class="keyword">if</span> (!<span class="type">NonFatal</span>(e) || failureCount &gt;= reporterMaxFailures) &#123;</div><div class="line">              finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">                <span class="type">ApplicationMaster</span>.<span class="type">EXIT_REPORTER_FAILURE</span>, <span class="string">"Exception was thrown "</span> +</div><div class="line">                  <span class="string">s"<span class="subst">$failureCount</span> time(s) from Reporter thread."</span>)</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              logWarning(<span class="string">s"Reporter thread fails <span class="subst">$failureCount</span> time(s) in a row."</span>, e)</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="keyword">val</span> numPendingAllocate = allocator.getPendingAllocate.size</div><div class="line">          <span class="keyword">var</span> sleepStart = <span class="number">0</span>L</div><div class="line">          <span class="keyword">var</span> sleepInterval = <span class="number">200</span>L <span class="comment">// ms</span></div><div class="line">          allocatorLock.synchronized &#123;</div><div class="line">            <span class="comment">// 计算 reporter 的休眠时长， 根据</span></div><div class="line">            sleepInterval =</div><div class="line">              <span class="keyword">if</span> (numPendingAllocate &gt; <span class="number">0</span> || allocator.getNumPendingLossReasonRequests &gt; <span class="number">0</span>) &#123;</div><div class="line">                <span class="comment">// 进入这里，表示有丢失的container， 也有正在添加的container</span></div><div class="line">                <span class="keyword">val</span> currentAllocationInterval =</div><div class="line">                  math.min(heartbeatInterval, nextAllocationInterval)</div><div class="line">                nextAllocationInterval = currentAllocationInterval * <span class="number">2</span> <span class="comment">// avoid overflow</span></div><div class="line">                currentAllocationInterval</div><div class="line">              &#125; <span class="keyword">else</span> &#123;</div><div class="line">                nextAllocationInterval = initialAllocationInterval</div><div class="line">                heartbeatInterval</div><div class="line">              &#125;</div><div class="line">            sleepStart = <span class="type">System</span>.currentTimeMillis()</div><div class="line">            allocatorLock.wait(sleepInterval)</div><div class="line">          &#125;</div><div class="line">          <span class="keyword">val</span> sleepDuration = <span class="type">System</span>.currentTimeMillis() - sleepStart</div><div class="line"></div><div class="line">          <span class="comment">// 如果符合这个条件，说明上面的 allocatorLock.wait所等待的时间不够，改用Thread.sleep来休眠</span></div><div class="line">          <span class="keyword">if</span> (sleepDuration &lt; sleepInterval) &#123;</div><div class="line">            <span class="comment">// log when sleep is interrupted</span></div><div class="line">            logDebug(<span class="string">s"Number of pending allocations is <span class="subst">$numPendingAllocate</span>. "</span> +</div><div class="line">                <span class="string">s"Slept for <span class="subst">$sleepDuration</span>/<span class="subst">$sleepInterval</span> ms."</span>)</div><div class="line">            <span class="comment">// if sleep was less than the minimum interval, sleep for the rest of it</span></div><div class="line">            <span class="keyword">val</span> toSleep = math.max(<span class="number">0</span>, initialAllocationInterval - sleepDuration)</div><div class="line">            <span class="keyword">if</span> (toSleep &gt; <span class="number">0</span>) &#123;</div><div class="line">              logDebug(<span class="string">s"Going back to sleep for <span class="subst">$toSleep</span> ms"</span>)</div><div class="line">              <span class="comment">// use Thread.sleep instead of allocatorLock.wait. there is no need to be woken up</span></div><div class="line">              <span class="comment">// by the methods that signal allocatorLock because this is just finishing the min</span></div><div class="line">              <span class="comment">// sleep interval, which should happen even if this is signalled again.</span></div><div class="line">              <span class="type">Thread</span>.sleep(toSleep)</div><div class="line">            &#125;</div><div class="line">          &#125; <span class="keyword">else</span> &#123;</div><div class="line">            logDebug(<span class="string">s"Number of pending allocations is <span class="subst">$numPendingAllocate</span>. "</span> +</div><div class="line">                <span class="string">s"Slept for <span class="subst">$sleepDuration</span>/<span class="subst">$sleepInterval</span>."</span>)</div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">InterruptedException</span> =&gt;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// setting to daemon status, though this is usually not a good idea.</span></div><div class="line">  t.setDaemon(<span class="literal">true</span>)</div><div class="line">  t.setName(<span class="string">"Reporter"</span>)</div><div class="line">  t.start()</div><div class="line">  logInfo(<span class="string">s"Started progress reporter thread with (heartbeat : <span class="subst">$heartbeatInterval</span>, "</span> +</div><div class="line">          <span class="string">s"initial allocation : <span class="subst">$initialAllocationInterval</span>) intervals"</span>)</div><div class="line">  t</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该方法看起来很复杂，其实它主要要做的事情就是 向YarnAllocator申请资源（调用allocateResources方法）。其他代码就是判断是否还要申请资源，以及什么时候进行下一次申请。</p>
<h2 id="startUserApplication"><a href="#startUserApplication" class="headerlink" title="startUserApplication"></a>startUserApplication</h2><p>启动用户应用程序，其实就是启动用户通过 –class参数传递过来的类。方法定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startUserApplication</span></span>(): <span class="type">Thread</span> = &#123;</div><div class="line">  logInfo(<span class="string">"Starting the user application in a separate Thread"</span>)</div><div class="line"></div><div class="line">  <span class="comment">// 获取用户的类路经</span></div><div class="line">  <span class="keyword">val</span> classpath = <span class="type">Client</span>.getUserClasspath(sparkConf)</div><div class="line">  <span class="keyword">val</span> urls = classpath.map &#123; entry =&gt;</div><div class="line">    <span class="keyword">new</span> <span class="type">URL</span>(<span class="string">"file:"</span> + <span class="keyword">new</span> <span class="type">File</span>(entry.getPath()).getAbsolutePath())</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">val</span> userClassLoader =</div><div class="line">    <span class="keyword">if</span> (<span class="type">Client</span>.isUserClassPathFirst(sparkConf, isDriver = <span class="literal">true</span>)) &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">ChildFirstURLClassLoader</span>(urls, <span class="type">Utils</span>.getContextOrSparkClassLoader)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">new</span> <span class="type">MutableURLClassLoader</span>(urls, <span class="type">Utils</span>.getContextOrSparkClassLoader)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">  <span class="keyword">var</span> userArgs = args.userArgs</div><div class="line">  <span class="keyword">if</span> (args.primaryPyFile != <span class="literal">null</span> &amp;&amp; args.primaryPyFile.endsWith(<span class="string">".py"</span>)) &#123;</div><div class="line">    <span class="comment">// When running pyspark, the app is run using PythonRunner. The second argument is the list</span></div><div class="line">    <span class="comment">// of files to add to PYTHONPATH, which Client.scala already handles, so it's empty.</span></div><div class="line">    userArgs = <span class="type">Seq</span>(args.primaryPyFile, <span class="string">""</span>) ++ userArgs</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span> &amp;&amp; args.primaryRFile.endsWith(<span class="string">".R"</span>)) &#123;</div><div class="line">    <span class="comment">// TODO(davies): add R dependencies here</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// 用户类的main方法</span></div><div class="line">  <span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)</div><div class="line">    .getMethod(<span class="string">"main"</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</div><div class="line"></div><div class="line">  <span class="keyword">val</span> userThread = <span class="keyword">new</span> <span class="type">Thread</span> &#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="comment">// 在新的线程中运行 用户类的 main方法</span></div><div class="line">        mainMethod.invoke(<span class="literal">null</span>, userArgs.toArray)</div><div class="line"></div><div class="line">        <span class="comment">// 设置完成状态（用户类执行完成）</span></div><div class="line">        finish(<span class="type">FinalApplicationStatus</span>.<span class="type">SUCCEEDED</span>, <span class="type">ApplicationMaster</span>.<span class="type">EXIT_SUCCESS</span>)</div><div class="line"></div><div class="line">        <span class="comment">// 记录日志</span></div><div class="line">        logDebug(<span class="string">"Done running users class"</span>)</div><div class="line">      &#125; <span class="keyword">catch</span> &#123;</div><div class="line">        <span class="comment">// 根据异常的原因，设置用户类执行的完成状态（失败状态）</span></div><div class="line">        <span class="comment">// 异常的原因分为</span></div><div class="line">        <span class="comment">// 中断异常</span></div><div class="line">        <span class="comment">// app异常</span></div><div class="line">        <span class="comment">// 代码异常</span></div><div class="line">        <span class="keyword">case</span> e: <span class="type">InvocationTargetException</span> =&gt;</div><div class="line">          e.getCause <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> _: <span class="type">InterruptedException</span> =&gt;</div><div class="line">              <span class="comment">// Reporter thread can interrupt to stop user class</span></div><div class="line">            <span class="keyword">case</span> <span class="type">SparkUserAppException</span>(exitCode) =&gt;</div><div class="line">              <span class="keyword">val</span> msg = <span class="string">s"User application exited with status <span class="subst">$exitCode</span>"</span></div><div class="line">              logError(msg)</div><div class="line">              finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>, exitCode, msg)</div><div class="line">            <span class="keyword">case</span> cause: <span class="type">Throwable</span> =&gt;</div><div class="line">              logError(<span class="string">"User class threw exception: "</span> + cause, cause)</div><div class="line">              finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</div><div class="line">                <span class="type">ApplicationMaster</span>.<span class="type">EXIT_EXCEPTION_USER_CLASS</span>,</div><div class="line">                <span class="string">"User class threw exception: "</span> + cause)</div><div class="line">          &#125;</div><div class="line">          sparkContextPromise.tryFailure(e.getCause())</div><div class="line">      &#125; <span class="keyword">finally</span> &#123;</div><div class="line">        <span class="comment">// Notify the thread waiting for the SparkContext, in case the application did not</span></div><div class="line">        <span class="comment">// instantiate one. This will do nothing when the user code instantiates a SparkContext</span></div><div class="line">        <span class="comment">// (with the correct master), or when the user code throws an exception (due to the</span></div><div class="line">        <span class="comment">// tryFailure above).</span></div><div class="line">        sparkContextPromise.trySuccess(<span class="literal">null</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// 设置线程的 类加载器 、 线程名字， 启动线程</span></div><div class="line">  userThread.setContextClassLoader(userClassLoader)</div><div class="line">  userThread.setName(<span class="string">"Driver"</span>)</div><div class="line">  userThread.start()</div><div class="line">  userThread</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>首先，通过代码我们可以明确一个问题，那就是用户的程序，其实就是driver。对于这个方法实现的功能，简单来说，就是获取类路径、获取类加载器、实例话用户类、执行用户类的main方法。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/10/12/spark-2-11-ApplicationMasterarguments/" itemprop="url">
                  spark 2.11 ApplicationMasterarguments
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-10-12T12:52:13+08:00" content="2018-10-12">
              2018-10-12
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是对 org.apache.spark.deploy.yarn.ApplicationMasterArguments 源码学习的分析，spark的版本为2.11。</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>org.apache.spark.deploy.yarn.ApplicationMasterArguments类主要用来对ApplicationMaster参数进行解析。</p>
<h1 id="主要方法分析"><a href="#主要方法分析" class="headerlink" title="主要方法分析"></a>主要方法分析</h1><h2 id="parseArgs"><a href="#parseArgs" class="headerlink" title="parseArgs"></a>parseArgs</h2><p>该方法就是用来解析参数的。方法的定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">parseArgs</span></span>(inputArgs: <span class="type">List</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> userArgsBuffer = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]()</div><div class="line"></div><div class="line">  <span class="keyword">var</span> args = inputArgs</div><div class="line"></div><div class="line">  <span class="comment">// 从这个匹配可以看出，可以使用的参数列在下面，如果包含了其他参数，系统会异常退出</span></div><div class="line">  <span class="comment">// --jar jar包</span></div><div class="line">  <span class="comment">// --class 类</span></div><div class="line">  <span class="comment">// --primary-py-file  PYTHON语言编写的application</span></div><div class="line">  <span class="comment">// --primary-r-file   R语言编写的application</span></div><div class="line">  <span class="comment">// --arg  其他参数，多个参数需要使用多个 --arg 1 --arg "name"</span></div><div class="line">  <span class="comment">// --properties-file 配置文件</span></div><div class="line">  <span class="keyword">while</span> (!args.isEmpty) &#123;</div><div class="line">    <span class="comment">// --num-workers, --worker-memory, and --worker-cores are deprecated since 1.0,</span></div><div class="line">    <span class="comment">// the properties with executor in their names are preferred.</span></div><div class="line">    <span class="comment">// 开始解析 类参数  case ("--jar") :: value :: tail 就是提取参数和参数名 ，并把剩余的参数放到 tail中</span></div><div class="line">    args <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> (<span class="string">"--jar"</span>) :: value :: tail =&gt;</div><div class="line">        userJar = value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> (<span class="string">"--class"</span>) :: value :: tail =&gt;</div><div class="line">        userClass = value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> (<span class="string">"--primary-py-file"</span>) :: value :: tail =&gt;</div><div class="line">        primaryPyFile = value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> (<span class="string">"--primary-r-file"</span>) :: value :: tail =&gt;</div><div class="line">        primaryRFile = value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> (<span class="string">"--arg"</span>) :: value :: tail =&gt;</div><div class="line">        userArgsBuffer += value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> (<span class="string">"--properties-file"</span>) :: value :: tail =&gt;</div><div class="line">        propertiesFile = value</div><div class="line">        args = tail</div><div class="line"></div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">        printUsageAndExit(<span class="number">1</span>, args)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (primaryPyFile != <span class="literal">null</span> &amp;&amp; primaryRFile != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="comment">// scalastyle:off println</span></div><div class="line">    <span class="type">System</span>.err.println(<span class="string">"Cannot have primary-py-file and primary-r-file at the same time"</span>)</div><div class="line">    <span class="comment">// scalastyle:on println</span></div><div class="line">    <span class="type">System</span>.exit(<span class="number">-1</span>)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  userArgs = userArgsBuffer.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个方法对ApplicationMaster参数进行解析，通过方法中match…case判断代码，我们可以看出ApplicationMaster允许的参数只有 6 个，如果包含其他名称的参数则会异常退出，并且参数–primary-py-file 和 参数–primary-r-file 不允许同时出现。对于上面的match…case的分析，见章节结尾部分。</p>
<h2 id="printUsageAndExit"><a href="#printUsageAndExit" class="headerlink" title="printUsageAndExit"></a>printUsageAndExit</h2><p>该方法用来将ApplicationMaster的使用参数信息进行打印。方法定义<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">def printUsageAndExit(exitCode: Int, unknownParam: Any = null) &#123;</div><div class="line">  // scalastyle:off println</div><div class="line">  if (unknownParam != null) &#123;</div><div class="line">    System.err.println("Unknown/unsupported param " + unknownParam)</div><div class="line">  &#125;</div><div class="line">  System.err.println("""</div><div class="line">    |Usage: org.apache.spark.deploy.yarn.ApplicationMaster [options]</div><div class="line">    |Options:</div><div class="line">    |  --jar JAR_PATH       Path to your application's JAR file</div><div class="line">    |  --class CLASS_NAME   Name of your application's main class</div><div class="line">    |  --primary-py-file    A main Python file</div><div class="line">    |  --primary-r-file     A main R file</div><div class="line">    |  --arg ARG            Argument to be passed to your application's main class.</div><div class="line">    |                       Multiple invocations are possible, each will be passed in order.</div><div class="line">    |  --properties-file FILE Path to a custom Spark properties file.</div><div class="line">    """.stripMargin)</div><div class="line">  // scalastyle:on println</div><div class="line">  System.exit(exitCode)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><h2 id="参数判断的match-…-case"><a href="#参数判断的match-…-case" class="headerlink" title="参数判断的match … case"></a>参数判断的match … case</h2><p>首先看代码<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">args <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> (<span class="string">"--jar"</span>) :: value :: tail =&gt;</div><div class="line">      userJar = value</div><div class="line">      args = tail</div><div class="line"></div><div class="line">    <span class="keyword">case</span> (<span class="string">"--class"</span>) :: value :: tail =&gt;</div><div class="line">      userClass = value</div><div class="line">      args = tail</div></pre></td></tr></table></figure></p>
<p>case中的信息其实就是匹配模式，这里，如“(“–jar”) :: value :: tail”，其实就是在args开头匹配 “–jar” 参数，也就是如果args中的第一个值为”–jar“，那么将args的第二个值赋值给value，最后将剩余的值放到 tail中，但是需要注意的是，这个模式是从args的第一个元素开始的，如果第二元素是“–jar”，是不符合条件的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/10/11/spark-2-11-YarnRMClient/" itemprop="url">
                  spark 2.11 YarnRMClient
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-10-11T16:23:43+08:00" content="2018-10-11">
              2018-10-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是对 org.apache.spark.deploy.yarn.YarnRMClient 源码进行学习的分析，spark的版本为2.11。</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>YarnRMClient主要用来处理application master向Yarn resourceManager的注册和注销。</p>
<h1 id="主要方法分析"><a href="#主要方法分析" class="headerlink" title="主要方法分析"></a>主要方法分析</h1><h2 id="register"><a href="#register" class="headerlink" title="register"></a>register</h2><p>该方法很简单，就是向YARN ResourceManager注册application master，该方法会在 ApplicationMaster的registerAM方法中调用。具体方法实现<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">register</span></span>(</div><div class="line">      driverUrl: <span class="type">String</span>,</div><div class="line">      driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">      conf: <span class="type">YarnConfiguration</span>,</div><div class="line">      sparkConf: <span class="type">SparkConf</span>,</div><div class="line">      uiAddress: <span class="type">Option</span>[<span class="type">String</span>],</div><div class="line">      uiHistoryAddress: <span class="type">String</span>,</div><div class="line">      securityMgr: <span class="type">SecurityManager</span>,</div><div class="line">      localResources: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LocalResource</span>]</div><div class="line">    ): <span class="type">YarnAllocator</span> = &#123;</div><div class="line"></div><div class="line">    <span class="comment">// 调用AMRMClient自身的方法来生成AMRMClient，再使用 Yarn 配置进行初始化，启动AMRMClient</span></div><div class="line">    amClient = <span class="type">AMRMClient</span>.createAMRMClient()</div><div class="line">    amClient.init(conf)</div><div class="line">    amClient.start()</div><div class="line">    <span class="keyword">this</span>.uiHistoryAddress = uiHistoryAddress</div><div class="line"></div><div class="line">    <span class="keyword">val</span> trackingUrl = uiAddress.getOrElse &#123;</div><div class="line">      <span class="keyword">if</span> (sparkConf.get(<span class="type">ALLOW_HISTORY_SERVER_TRACKING_URL</span>)) uiHistoryAddress <span class="keyword">else</span> <span class="string">""</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    logInfo(<span class="string">"Registering the ApplicationMaster"</span>)</div><div class="line">    <span class="comment">// 向 ResourceManager 注册 application master，从代码看出 application master就是本机，TODO 这个本机是啥呢？？？</span></div><div class="line">    synchronized &#123;</div><div class="line">      amClient.registerApplicationMaster(<span class="type">Utils</span>.localHostName(), <span class="number">0</span>, trackingUrl)</div><div class="line">      registered = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 生成 YarnAllocator</span></div><div class="line">    <span class="comment">// driverUrl和driverRef需要说一下，</span></div><div class="line">    <span class="comment">// driverUrl，是driver运行的地址，会传递给Executor，应该是用于Execurot与driver进行交互</span></div><div class="line">    <span class="comment">// driverRef 在YarnAllocator中使用，用于同步executor的id，以及 发送删除executor的信息</span></div><div class="line">    <span class="keyword">new</span> <span class="type">YarnAllocator</span>(driverUrl, driverRef, conf, sparkConf, amClient, getAttemptId(), securityMgr,</div><div class="line">      localResources, <span class="keyword">new</span> <span class="type">SparkRackResolver</span>())</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>此方法逻辑很简单，一眼就看明白。生成AMRMClient（用于访问ResourceManager），向ResourceManager注册applicationMaster，生成YarnAllocator。但是需要注意生成YarnAllocator的参数。</p>
<h2 id="unregister"><a href="#unregister" class="headerlink" title="unregister"></a>unregister</h2><p>作用与register方法相反，从YARN ResourceManager中注销 application master。具体方法实现<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">unregister</span></span>(status: <span class="type">FinalApplicationStatus</span>, diagnostics: <span class="type">String</span> = <span class="string">""</span>): <span class="type">Unit</span> = synchronized &#123;</div><div class="line">	<span class="keyword">if</span> (registered) &#123;</div><div class="line">	  amClient.unregisterApplicationMaster(status, diagnostics, uiHistoryAddress)</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="getMaxRegAttempts"><a href="#getMaxRegAttempts" class="headerlink" title="getMaxRegAttempts"></a>getMaxRegAttempts</h2><p>此方法就是用来定义注册application master的最大尝试次数。具体方法定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** 获取注册AM的最大尝试次数 分别从spark配置和yarn配置中读取 如果spark配置中设置了，则使用spark和yarn配置中最小那个值 */</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getMaxRegAttempts</span></span>(sparkConf: <span class="type">SparkConf</span>, yarnConf: <span class="type">YarnConfiguration</span>): <span class="type">Int</span> = &#123;</div><div class="line">  <span class="keyword">val</span> sparkMaxAttempts = sparkConf.get(<span class="type">MAX_APP_ATTEMPTS</span>).map(_.toInt)</div><div class="line">  <span class="keyword">val</span> yarnMaxAttempts = yarnConf.getInt(</div><div class="line">    <span class="type">YarnConfiguration</span>.<span class="type">RM_AM_MAX_ATTEMPTS</span>, <span class="type">YarnConfiguration</span>.<span class="type">DEFAULT_RM_AM_MAX_ATTEMPTS</span>)</div><div class="line">  sparkMaxAttempts <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">Some</span>(x) =&gt; <span class="keyword">if</span> (x &lt;= yarnMaxAttempts) x <span class="keyword">else</span> yarnMaxAttempts</div><div class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; yarnMaxAttempts</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>此方法也很简单，分别从spark配置和yarn配置中读取 如果spark配置中设置了，则使用spark和yarn配置中最小那个值。没有在spark中配置，则使用yarn配置中的。</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="哪里生成YarnRMClient对象"><a href="#哪里生成YarnRMClient对象" class="headerlink" title="哪里生成YarnRMClient对象"></a>哪里生成YarnRMClient对象</h2><p>答案就是在ApplicationMaster的main方法中，代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">  </div><div class="line">  ...</div><div class="line">  </div><div class="line">  <span class="type">SparkHadoopUtil</span>.get.runAsSparkUser &#123; () =&gt;</div><div class="line">    master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, <span class="keyword">new</span> <span class="type">YarnRMClient</span>)</div><div class="line">    <span class="type">System</span>.exit(master.run())</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="哪里调用-YarnRMClient的register方法"><a href="#哪里调用-YarnRMClient的register方法" class="headerlink" title="哪里调用 YarnRMClient的register方法"></a>哪里调用 YarnRMClient的register方法</h2><p>在register方法中看到了YarnAllocator的生成，那么在哪里调用register方法呢？答案就是 org.apache.spark.deploy.yarn.ApplicationMaster中。而且ApplicationMaster含有main方法，是程序的入口。代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerAM</span></span>(</div><div class="line">      _sparkConf: <span class="type">SparkConf</span>,</div><div class="line">      _rpcEnv: <span class="type">RpcEnv</span>,</div><div class="line">      driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">      uiAddress: <span class="type">Option</span>[<span class="type">String</span>],</div><div class="line">      securityMgr: <span class="type">SecurityManager</span>) = &#123;</div><div class="line">    </div><div class="line">    ...</div><div class="line"></div><div class="line">    allocator = client.register(driverUrl,</div><div class="line">      driverRef,</div><div class="line">      yarnConf,</div><div class="line">      _sparkConf,</div><div class="line">      uiAddress,</div><div class="line">      historyAddress,</div><div class="line">      securityMgr,</div><div class="line">      localResources)</div><div class="line"></div><div class="line">    allocator.allocateResources()</div><div class="line">    reporterThread = launchReporterThread()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/10/10/spark-2-11-YarnAllocator/" itemprop="url">
                  spark 2.11 YarnAllocator
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-10-10T15:51:42+08:00" content="2018-10-10">
              2018-10-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/spark-2-11/" itemprop="url" rel="index">
                    <span itemprop="name">spark 2.11</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是对 org.apache.spark.deploy.yarn.YarnAllocator 类源码进行学习的分析，spark的版本为2.11。</p>
<h1 id="总体概述"><a href="#总体概述" class="headerlink" title="总体概述"></a>总体概述</h1><p>YarnAllocator可以理解成一个Container的筛选器。当调用了YarnAllocator.allocateResources()方法后，程序就会进行各种处理，最终调用ExecutorRunnable类来启动Executor。在YarnAllocator类中，最主要的方法有：allocateResources()、updateResourceRequests()、handleAllocatedContainers()、runAllocatedContainers()和processCompletedContainers()。而整个这些方法的调用，是通过allocateResources()来调用的。基本的流程如下图：</p>
<h1 id="主要方法的分析"><a href="#主要方法的分析" class="headerlink" title="主要方法的分析"></a>主要方法的分析</h1><h2 id="allocateResources"><a href="#allocateResources" class="headerlink" title="allocateResources"></a>allocateResources</h2><p>资源分配的入口，首先看方法的定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">allocateResources</span></span>(): <span class="type">Unit</span> = synchronized &#123;</div><div class="line">    updateResourceRequests()</div><div class="line"></div><div class="line">    <span class="comment">// 处理指示器</span></div><div class="line">    <span class="keyword">val</span> progressIndicator = <span class="number">0.1</span>f</div><div class="line">    <span class="comment">// Poll the ResourceManager. This doubles as a heartbeat if there are no pending container</span></div><div class="line">    <span class="comment">// requests.</span></div><div class="line">    <span class="comment">// 调用 AMRMClient 分配资源</span></div><div class="line">    <span class="keyword">val</span> allocateResponse = amClient.allocate(progressIndicator)</div><div class="line"></div><div class="line">    <span class="comment">// 得到已经分配的 container</span></div><div class="line">    <span class="keyword">val</span> allocatedContainers = allocateResponse.getAllocatedContainers()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (allocatedContainers.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// 输出日志信息，包括 分配的container数量，正在运行的以及启动的executor数量，以及可用的资源信息</span></div><div class="line">      logDebug((<span class="string">"Allocated containers: %d. Current executor count: %d. "</span> +</div><div class="line">        <span class="string">"Launching executor count: %d. Cluster resources: %s."</span>)</div><div class="line">        .format(</div><div class="line">          allocatedContainers.size,</div><div class="line">          numExecutorsRunning.get,</div><div class="line">          numExecutorsStarting.get,</div><div class="line">          allocateResponse.getAvailableResources))</div><div class="line"></div><div class="line">      <span class="comment">// 处理已经分配的container</span></div><div class="line">      handleAllocatedContainers(allocatedContainers.asScala)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 获取已经执行完成的 container</span></div><div class="line">    <span class="keyword">val</span> completedContainers = allocateResponse.getCompletedContainersStatuses()</div><div class="line">    <span class="keyword">if</span> (completedContainers.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      logDebug(<span class="string">"Completed %d containers"</span>.format(completedContainers.size))</div><div class="line">      <span class="comment">//处理已经完成的container</span></div><div class="line">      processCompletedContainers(completedContainers.asScala)</div><div class="line">      logDebug(<span class="string">"Finished processing %d completed containers. Current running executor count: %d."</span></div><div class="line">        .format(completedContainers.size, numExecutorsRunning.get))</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>这个方法首先就是要更新资源的申请（调用updateResourceRequests()方法，我们稍后再看），然后就是调用AMRMClient（amClient）来分配资源，分配资源的返回值（allocateResponse）会包含三部分信息：已经分配的Container（allocatedContainers）、可用的资源和完成的Container（completedContainers）。对于已经分配的和完成的Container，会有对应的方法去处理；对于可用的资源，只是输出到日志。</p>
<h2 id="updateResourceRequests"><a href="#updateResourceRequests" class="headerlink" title="updateResourceRequests"></a>updateResourceRequests</h2><p>更新资源的请求信息，首先看方法的定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateResourceRequests</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="comment">// 得到正在添加的container 并 得到正在添加 container的数量</span></div><div class="line">    <span class="keyword">val</span> pendingAllocate = getPendingAllocate</div><div class="line">    <span class="keyword">val</span> numPendingAllocate = pendingAllocate.size</div><div class="line"></div><div class="line">    <span class="comment">// 计划要启动的executor数量 - 正在请求启动的executor - 已经启动的executor - 已经运行任务的executor = 缺少多少executor</span></div><div class="line">    <span class="comment">// 所以这里是在计算 比预计要启动的executor，还缺少多少个</span></div><div class="line">    <span class="keyword">val</span> missing = targetNumExecutors - numPendingAllocate -</div><div class="line">      numExecutorsStarting.get - numExecutorsRunning.get</div><div class="line">    logDebug(<span class="string">s"Updating resource requests, target: <span class="subst">$targetNumExecutors</span>, "</span> +</div><div class="line">      <span class="string">s"pending: <span class="subst">$numPendingAllocate</span>, running: <span class="subst">$&#123;numExecutorsRunning.get&#125;</span>, "</span> +</div><div class="line">      <span class="string">s"executorsStarting: <span class="subst">$&#123;numExecutorsStarting.get&#125;</span>"</span>)</div><div class="line">    <span class="comment">// &lt;1&gt;</span></div><div class="line"></div><div class="line">    <span class="comment">// missing 可以为正数 也可能为负数，负数则说明 动态分配分配多了，但是没有超过最大个数，这个数是通过计划启动个数算出来的</span></div><div class="line">    <span class="keyword">if</span> (missing &gt; <span class="number">0</span>) &#123;</div><div class="line">      logInfo(<span class="string">s"Will request <span class="subst">$missing</span> executor container(s), each with "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;resource.getVirtualCores&#125;</span> core(s) and "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;resource.getMemory&#125;</span> MB memory (including <span class="subst">$memoryOverhead</span> MB of overhead)"</span>)</div><div class="line"></div><div class="line">      <span class="comment">// 将要添加的container请求拆分到三个组：位置匹配列表、位置不匹配列表 和 无位置列表。</span></div><div class="line">      <span class="comment">// 对于位置匹配的 container 请求，将他们放到可用的地方，等待分配</span></div><div class="line">      <span class="comment">// 对于位置不匹配的和无位置的container请求，取消这些container的请求，因为 位置优先权已经变了，</span></div><div class="line">      <span class="keyword">val</span> (localRequests, staleRequests, anyHostRequests) = splitPendingAllocationsByLocality(</div><div class="line">        hostToLocalTaskCounts, pendingAllocate)</div><div class="line">      <span class="comment">// &lt;2&gt;</span></div><div class="line"></div><div class="line">      <span class="comment">// cancel "stale" requests for locations that are no longer needed</span></div><div class="line">      <span class="comment">// 对于位置不匹配的container，进行移除操作，并记录日志， 移除了N个container</span></div><div class="line">      staleRequests.foreach &#123; stale =&gt;</div><div class="line">        amClient.removeContainerRequest(stale)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">val</span> cancelledContainers = staleRequests.size</div><div class="line">      <span class="keyword">if</span> (cancelledContainers &gt; <span class="number">0</span>) &#123;</div><div class="line">        logInfo(<span class="string">s"Canceled <span class="subst">$cancelledContainers</span> container request(s) (locality no longer needed)"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;3&gt;</span></div><div class="line"></div><div class="line">      <span class="comment">// 计算还可以分配的container的数量，就是 缺少的 + 取消的</span></div><div class="line">      <span class="comment">// 因为cancelledContainers的个数实际上就是从pendingAllocate 中取消的</span></div><div class="line">      <span class="keyword">val</span> availableContainers = missing + cancelledContainers</div><div class="line"></div><div class="line">      <span class="comment">// 计算潜在的container就是 可以分配的container + 上面那些 不限制位置的的contianer的数量</span></div><div class="line">      <span class="keyword">val</span> potentialContainers = availableContainers + anyHostRequests.size</div><div class="line"></div><div class="line">      <span class="comment">// TODO 这是在弄啥 ？？？ 应该是根据 潜在container的数量，生成对应个的contaner的位置引用</span></div><div class="line">      <span class="keyword">val</span> containerLocalityPreferences = <span class="keyword">if</span> (labelExpression.isEmpty) &#123;</div><div class="line">        containerPlacementStrategy.localityOfRequestedContainers(</div><div class="line">          potentialContainers, numLocalityAwareTasks, hostToLocalTaskCounts,</div><div class="line">          allocatedHostToContainersMap, localRequests)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="type">Array</span>.empty[<span class="type">ContainerLocalityPreferences</span>]</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 根据上面的containerLocalityPreferences 创建container添加请求（注意是请求）</span></div><div class="line">      <span class="comment">// newLocalityRequest 用来记录要添加的container的请求</span></div><div class="line">      <span class="keyword">val</span> newLocalityRequests = <span class="keyword">new</span> mutable.<span class="type">ArrayBuffer</span>[<span class="type">ContainerRequest</span>]</div><div class="line">      containerLocalityPreferences.foreach &#123;</div><div class="line">        <span class="comment">// createContainerRequest 用来生成container的创建请求</span></div><div class="line">        <span class="keyword">case</span> <span class="type">ContainerLocalityPreferences</span>(nodes, racks) <span class="keyword">if</span> nodes != <span class="literal">null</span> =&gt;</div><div class="line">          newLocalityRequests += createContainerRequest(resource, nodes, racks)</div><div class="line">        <span class="keyword">case</span> _ =&gt;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 需要再次判断 总的container的数量，如果availableContainers &gt; newLocalityRequests 表示，还不够</span></div><div class="line">      <span class="comment">// 为啥 availableContainers 会大于 newLocalityRequests ？ 因为 labelExpression.isEmpty 为空时，会生成一个空的Array</span></div><div class="line">      <span class="keyword">if</span> (availableContainers &gt;= newLocalityRequests.size) &#123;</div><div class="line">        <span class="comment">// more containers are available than needed for locality, fill in requests for any host</span></div><div class="line">        <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until (availableContainers - newLocalityRequests.size)) &#123;</div><div class="line">          <span class="comment">// createContainerRequest 用来生成container的创建请求</span></div><div class="line">          newLocalityRequests += createContainerRequest(resource, <span class="literal">null</span>, <span class="literal">null</span>)</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line"></div><div class="line">        <span class="comment">// 这里的 newLocalityRequests 实际上对应的个是 potentialContainers = availableContainers + anyHostRequests.size</span></div><div class="line">        <span class="comment">// 因此，如果 newLocalityRequests &gt; availableContainers 则表示生成多了，且 anyHostRequests 的多了</span></div><div class="line"></div><div class="line">        <span class="keyword">val</span> numToCancel = newLocalityRequests.size - availableContainers</div><div class="line">        <span class="comment">// 因此释放到一些多余的 anyHostRequests</span></div><div class="line">        <span class="comment">// cancel some requests without locality preferences to schedule more local containers</span></div><div class="line">        anyHostRequests.slice(<span class="number">0</span>, numToCancel).foreach &#123; nonLocal =&gt;</div><div class="line">          amClient.removeContainerRequest(nonLocal)</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (numToCancel &gt; <span class="number">0</span>) &#123;</div><div class="line">          logInfo(<span class="string">s"Canceled <span class="subst">$numToCancel</span> unlocalized container requests to resubmit with locality"</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;4&gt;</span></div><div class="line"></div><div class="line">      <span class="comment">// AMRMClient 请求添加container</span></div><div class="line">      newLocalityRequests.foreach &#123; request =&gt;</div><div class="line">        amClient.addContainerRequest(request)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;5&gt;</span></div><div class="line"></div><div class="line">      <span class="keyword">if</span> (log.isInfoEnabled()) &#123;</div><div class="line">        <span class="keyword">val</span> (localized, anyHost) = newLocalityRequests.partition(_.getNodes() != <span class="literal">null</span>)</div><div class="line">        <span class="keyword">if</span> (anyHost.nonEmpty) &#123;</div><div class="line">          logInfo(<span class="string">s"Submitted <span class="subst">$&#123;anyHost.size&#125;</span> unlocalized container requests."</span>)</div><div class="line">        &#125;</div><div class="line">        localized.foreach &#123; request =&gt;</div><div class="line">          logInfo(<span class="string">s"Submitted container request for host <span class="subst">$&#123;hostStr(request)&#125;</span>."</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;6&gt;</span></div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (numPendingAllocate &gt; <span class="number">0</span> &amp;&amp; missing &lt; <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// 如果不缺少executor，并且还有正在添加的executor</span></div><div class="line"></div><div class="line">      <span class="comment">// 计算要取消的contaner的数量，为什么是最小值，个人这样理解：-missing，其实是多出来的，但是在计算missing的时候，</span></div><div class="line">      <span class="comment">// 已经减去 numPendingAllocate 了，也就是说 numPendingAllocate 认为是已经使用的数量</span></div><div class="line">      <span class="comment">// 因此，如果取最大值，那么当 numPendingAllocate &gt; -missing 时，删除的container就太多了</span></div><div class="line">      <span class="keyword">val</span> numToCancel = math.min(numPendingAllocate, -missing)</div><div class="line">      logInfo(<span class="string">s"Canceling requests for <span class="subst">$numToCancel</span> executor container(s) to have a new desired "</span> +</div><div class="line">        <span class="string">s"total <span class="subst">$targetNumExecutors</span> executors."</span>)</div><div class="line"></div><div class="line">      <span class="comment">// 获取匹配的请求，并且有匹配的数据，则移除这些container（而且我猜测，这里的寻找匹配的请求，是在pending的队列中找的）</span></div><div class="line">      <span class="keyword">val</span> matchingRequests = amClient.getMatchingRequests(<span class="type">RM_REQUEST_PRIORITY</span>, <span class="type">ANY_HOST</span>, resource)</div><div class="line">      <span class="keyword">if</span> (!matchingRequests.isEmpty) &#123;</div><div class="line">        matchingRequests.iterator().next().asScala</div><div class="line">          .take(numToCancel).foreach(amClient.removeContainerRequest)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        logWarning(<span class="string">"Expected to find pending requests, but found none."</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;7&gt;</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p><1> 部分主要就是计算系统是否已经达到了目标个数的executor（container是executor的容器，目前一个container只包含了一个executor），并计算缺少的个数。计算的公式就是val missing = targetNumExecutors - numPendingAllocate - numExecutorsStarting.get - numExecutorsRunning.get。targetNumExecutors是配置中 spark.dynamicAllocation.minExecutors 、spark.dynamicAllocation.initialExecutors 以及 spark.executor.instances 三个配置中的最大值（开启了动态分配的话，如果没开启，则使用 spark.executor.instances 的值），并且要求 spark.dynamicAllocation.maxExecutors &gt;= spark.dynamicAllocation.initialExecutors &gt;= spark.dynamicAllocation.minExecutors（如果没有开启动态分配，则不存在这种要求）。这里涉及了4个配置项。numPendingAllocate的值调用AMRMClient的getMatchingRequests方法，获取location为*的所有请求。</1></p>
<p><2> 这一部分就是对添加中的请求（pendingAllocate）进行分类，分为位置自由的、位置匹配的和位置不匹配的。分类的依据是ContainerRequest.getNodes。如果nodes为空，则认为是位置自由的，如果nodes不空，则判断nodes是否hostToLocalTaskCounts的keyset有交集，如果有则认为是匹配的，否则不匹配。这里的匹配和不匹配，大概就是寻找本地的containerRequest（？？？？？？？？？？？？？？？？）。</2></p>
<p><3> 这一部分是对上面找出来的位置不匹配的请求，进行取消，并记录日志。筛选的规则是优先使用位置符合的，坚决不使用位置不符合的，数量不够的时候，使用位置自由的。</3></p>
<p><4> 这一部分是计算出需要创建的container个数。进行ContainerRequest的创建，首先创建位置符合的，然后创建位置自由的，并且将多余的位置自由的请求取消掉。</4></p>
<p><5> 在这里调用AMRMClient的addContainerRequest方法来增加ContainerRequest。</5></p>
<p><6> 记录日志</6></p>
<p><7> 将超出目标个数的container（位置自由的）取消。<br>所以从总体来看，这个方法其实就是把container的个数控制在目标个数范围内，如果缺少了，则增加，如果多了，则取消一些请求。</7></p>
<h2 id="handleAllocatedContainers"><a href="#handleAllocatedContainers" class="headerlink" title="handleAllocatedContainers"></a>handleAllocatedContainers</h2><p>此方法用来处理申请资源的container。方法的定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleAllocatedContainers</span></span>(allocatedContainers: <span class="type">Seq</span>[<span class="type">Container</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="comment">// 用来保存要使用的Containers</span></div><div class="line">    <span class="keyword">val</span> containersToUse = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>](allocatedContainers.size)</div><div class="line"></div><div class="line">    <span class="comment">// Match incoming requests by host 根据host进行匹配，匹配不成功的下面继续匹配</span></div><div class="line">    <span class="keyword">val</span> remainingAfterHostMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- allocatedContainers) &#123;</div><div class="line">      matchContainerToRequest(allocatedContainer, allocatedContainer.getNodeId.getHost,</div><div class="line">        containersToUse, remainingAfterHostMatches)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Match remaining by rack 对上面按照host匹配不成功的进行机架匹配</span></div><div class="line">    <span class="keyword">val</span> remainingAfterRackMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- remainingAfterHostMatches) &#123;</div><div class="line">      <span class="keyword">val</span> rack = resolver.resolve(conf, allocatedContainer.getNodeId.getHost)</div><div class="line">      matchContainerToRequest(allocatedContainer, rack, containersToUse,</div><div class="line">        remainingAfterRackMatches)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 通过上面的两次匹配可以看到，最优先使用的是 host -&gt; rack -&gt; *</span></div><div class="line"></div><div class="line">    <span class="comment">// Assign remaining that are neither node-local nor rack-local</span></div><div class="line">    <span class="keyword">val</span> remainingAfterOffRackMatches = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]</div><div class="line">    <span class="keyword">for</span> (allocatedContainer &lt;- remainingAfterRackMatches) &#123;</div><div class="line">      matchContainerToRequest(allocatedContainer, <span class="type">ANY_HOST</span>, containersToUse,</div><div class="line">        remainingAfterOffRackMatches)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 三次匹配都没有成功的，就释放掉了</span></div><div class="line">    <span class="keyword">if</span> (!remainingAfterOffRackMatches.isEmpty) &#123;</div><div class="line">      logDebug(<span class="string">s"Releasing <span class="subst">$&#123;remainingAfterOffRackMatches.size&#125;</span> unneeded containers that were "</span> +</div><div class="line">        <span class="string">s"allocated to us"</span>)</div><div class="line">      <span class="keyword">for</span> (container &lt;- remainingAfterOffRackMatches) &#123;</div><div class="line">        internalReleaseContainer(container)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 启动所有的container，这些container上经过上面过滤后的可以使用container</span></div><div class="line">    runAllocatedContainers(containersToUse)</div><div class="line"></div><div class="line">    logInfo(<span class="string">"Received %d containers from YARN, launching executors on %d of them."</span></div><div class="line">      .format(allocatedContainers.size, containersToUse.size))</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>从代码来看，这个方法其实就是对allocatedContainers再次进行过滤，根据主机、机架 和 通配主机（*）。最后将不匹配的释放掉（不同于取消请求）。并在方法的最后启动所有分配的container启动。</p>
<h2 id="runAllocatedContainers"><a href="#runAllocatedContainers" class="headerlink" title="runAllocatedContainers"></a>runAllocatedContainers</h2><p>运行 container，方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runAllocatedContainers</span></span>(containersToUse: <span class="type">ArrayBuffer</span>[<span class="type">Container</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">for</span> (container &lt;- containersToUse) &#123;</div><div class="line">      <span class="comment">// executorIdConter 应该是同步的，用来生成新的executor的id</span></div><div class="line">      executorIdCounter += <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> executorHostname = container.getNodeId.getHost</div><div class="line">      <span class="keyword">val</span> containerId = container.getId</div><div class="line">      <span class="keyword">val</span> executorId = executorIdCounter.toString</div><div class="line">      assert(container.getResource.getMemory &gt;= resource.getMemory)</div><div class="line">      logInfo(<span class="string">s"Launching container <span class="subst">$containerId</span> on host <span class="subst">$executorHostname</span> "</span> +</div><div class="line">        <span class="string">s"for executor with ID <span class="subst">$executorId</span>"</span>)</div><div class="line">      <span class="comment">//&lt;1&gt;</span></div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// 主要是为了更新各种计数</span></div><div class="line">      <span class="function"><span class="keyword">def</span> <span class="title">updateInternalState</span></span>(): <span class="type">Unit</span> = synchronized &#123;</div><div class="line">        <span class="comment">// 正在运行的executor加一</span></div><div class="line">        numExecutorsRunning.incrementAndGet()</div><div class="line">        <span class="comment">// 启动中的executor 减一，因为已经运行了，就不能处于启动中了</span></div><div class="line">        numExecutorsStarting.decrementAndGet()</div><div class="line"></div><div class="line">        <span class="comment">//保存 executor -&gt; container的关系 以及 container -&gt; executorId的关系</span></div><div class="line">        executorIdToContainer(executorId) = container</div><div class="line">        containerIdToExecutorId(container.getId) = executorId</div><div class="line"></div><div class="line">        <span class="comment">// 记录 某个主机上都有哪些 containers</span></div><div class="line">        <span class="keyword">val</span> containerSet = allocatedHostToContainersMap.getOrElseUpdate(executorHostname,</div><div class="line">          <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">ContainerId</span>])</div><div class="line">        containerSet += containerId</div><div class="line">        <span class="comment">// 记录contain运行在那个主机上</span></div><div class="line">        allocatedContainerToHostMap.put(containerId, executorHostname)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;2&gt;</span></div><div class="line"></div><div class="line">      <span class="comment">// 如果正在运行的executor的数量小于 想要启动的executor个数</span></div><div class="line">      <span class="keyword">if</span> (numExecutorsRunning.get &lt; targetNumExecutors) &#123;</div><div class="line"></div><div class="line">        <span class="comment">// 将启动的executor的计数加一</span></div><div class="line">        <span class="comment">// 这里为啥要加一呢？？？</span></div><div class="line">        <span class="comment">// 因为 接下来要启动 container了，没有启动起来之前则认为处于启动中，因此先加一，一旦启动完成，则调用上面的updateInternalState</span></div><div class="line">        <span class="comment">// 方法，在这个方法中会对运行中的executor加一，启动中的executor减一。</span></div><div class="line">        numExecutorsStarting.incrementAndGet()</div><div class="line"></div><div class="line">        <span class="comment">// spark.yarn.launchContainers 配置的值</span></div><div class="line">        <span class="keyword">if</span> (launchContainers) &#123;</div><div class="line">          launcherPool.execute(<span class="keyword">new</span> <span class="type">Runnable</span> &#123;</div><div class="line">            <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</div><div class="line">              <span class="keyword">try</span> &#123;</div><div class="line">                <span class="comment">// 调用 ExecutorRunnalbe方法来启动container</span></div><div class="line">                <span class="keyword">new</span> <span class="type">ExecutorRunnable</span>(</div><div class="line">                  <span class="type">Some</span>(container),</div><div class="line">                  conf,</div><div class="line">                  sparkConf,</div><div class="line">                  driverUrl,</div><div class="line">                  executorId,</div><div class="line">                  executorHostname,</div><div class="line">                  executorMemory,</div><div class="line">                  executorCores,</div><div class="line">                  appAttemptId.getApplicationId.toString,</div><div class="line">                  securityMgr,</div><div class="line">                  localResources</div><div class="line">                ).run()</div><div class="line"></div><div class="line">                <span class="comment">// 跟新各种计数</span></div><div class="line">                updateInternalState()</div><div class="line">              &#125; <span class="keyword">catch</span> &#123;</div><div class="line">                <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</div><div class="line">                  numExecutorsStarting.decrementAndGet()</div><div class="line">                  <span class="keyword">if</span> (<span class="type">NonFatal</span>(e)) &#123;</div><div class="line">                    logError(<span class="string">s"Failed to launch executor <span class="subst">$executorId</span> on container <span class="subst">$containerId</span>"</span>, e)</div><div class="line">                    <span class="comment">// Assigned container should be released immediately</span></div><div class="line">                    <span class="comment">// to avoid unnecessary resource occupation.</span></div><div class="line">                    <span class="comment">// 启动失败，则释放掉这个container</span></div><div class="line">                    amClient.releaseAssignedContainer(containerId)</div><div class="line">                  &#125; <span class="keyword">else</span> &#123;</div><div class="line">                    <span class="keyword">throw</span> e</div><div class="line">                  &#125;</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">          &#125;)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          <span class="comment">// For test only</span></div><div class="line">          updateInternalState()</div><div class="line">        &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        logInfo((<span class="string">"Skip launching executorRunnable as runnning Excecutors count: %d "</span> +</div><div class="line">          <span class="string">"reached target Executors count: %d."</span>).format(</div><div class="line">          numExecutorsRunning.get, targetNumExecutors))</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// &lt;3&gt;</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p><1> 获取container和executor的信息，方便下面使用。</1></p>
<p><2> 定义了一个方法，这个方法就是用来更新各种数据关系，有executor运行的数量、executor启动的数量、executorId到container的对应关系、containerId到executorId的对应关系、host上运行的contianer的对应关系、container在哪个host运行的关系。</2></p>
<p><3> 异步生成ExecutorRunnable，并启动。</3></p>
<h2 id="processCompletedContainers"><a href="#processCompletedContainers" class="headerlink" title="processCompletedContainers"></a>processCompletedContainers</h2><p>此方法也在allocateResources()方法中调用，用来处理完成的container，完成的container可能是被kill掉，也可能是正常完成的。方法定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[yarn] <span class="function"><span class="keyword">def</span> <span class="title">processCompletedContainers</span></span>(completedContainers: <span class="type">Seq</span>[<span class="type">ContainerStatus</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="comment">// 循环完成的container</span></div><div class="line">    <span class="keyword">for</span> (completedContainer &lt;- completedContainers) &#123;</div><div class="line"></div><div class="line">      <span class="comment">// 获取containerId, 判断container是否在releasedContainers 中，获取 container所在的host</span></div><div class="line">      <span class="keyword">val</span> containerId = completedContainer.getContainerId</div><div class="line">      <span class="keyword">val</span> alreadyReleased = releasedContainers.remove(containerId)</div><div class="line">      <span class="keyword">val</span> hostOpt = allocatedContainerToHostMap.get(containerId)</div><div class="line">      <span class="keyword">val</span> onHostStr = hostOpt.map(host =&gt; <span class="string">s" on host: <span class="subst">$host</span>"</span>).getOrElse(<span class="string">""</span>)</div><div class="line">      <span class="comment">// &lt;1&gt;</span></div><div class="line"></div><div class="line">      <span class="comment">// 如果alreadyReleased为false，则表示releasedContainers 中没有这个container，或者是有但是删除失败</span></div><div class="line">      <span class="keyword">val</span> exitReason = <span class="keyword">if</span> (!alreadyReleased) &#123;</div><div class="line">        <span class="comment">// Decrement the number of executors running. The next iteration of</span></div><div class="line">        <span class="comment">// the ApplicationMaster's reporting thread will take care of allocating.</span></div><div class="line">        numExecutorsRunning.decrementAndGet()</div><div class="line">        logInfo(<span class="string">"Completed container %s%s (state: %s, exit status: %s)"</span>.format(</div><div class="line">          containerId,</div><div class="line">          onHostStr,</div><div class="line">          completedContainer.getState,</div><div class="line">          completedContainer.getExitStatus))</div><div class="line">        <span class="comment">// 获取container的退出状态</span></div><div class="line">        <span class="keyword">val</span> exitStatus = completedContainer.getExitStatus</div><div class="line"></div><div class="line">        <span class="comment">// 根据退出状态来判断是否是由于Application的原因</span></div><div class="line">        <span class="comment">// 以及退出的原因</span></div><div class="line">        <span class="comment">// ContainerExitStatus.SUCCESS 表示是因为YARN事件，不是因为运行的job发生error而导致的</span></div><div class="line">        <span class="comment">// ContainerExitStatus.PREEMPTED 表示主机上的端口被占用了</span></div><div class="line">        <span class="comment">// VMEM_EXCEEDED_EXIT_CODE 表示 虚拟内存的问题</span></div><div class="line">        <span class="comment">// PMEM_EXCEEDED_EXIT_CODE 表示 物理内存的问题</span></div><div class="line">        <span class="comment">// 否则</span></div><div class="line">        <span class="comment">// 除了第一种和第二种，其他的认为都属于 Application的原因</span></div><div class="line">        <span class="keyword">val</span> (exitCausedByApp, containerExitReason) = exitStatus <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">ContainerExitStatus</span>.<span class="type">SUCCESS</span> =&gt;</div><div class="line">            (<span class="literal">false</span>, <span class="string">s"Executor for container <span class="subst">$containerId</span> exited because of a YARN event (e.g., "</span> +</div><div class="line">              <span class="string">"pre-emption) and not because of an error in the running job."</span>)</div><div class="line">          <span class="keyword">case</span> <span class="type">ContainerExitStatus</span>.<span class="type">PREEMPTED</span> =&gt;</div><div class="line">            <span class="comment">// Preemption is not the fault of the running tasks, since YARN preempts containers</span></div><div class="line">            <span class="comment">// merely to do resource sharing, and tasks that fail due to preempted executors could</span></div><div class="line">            <span class="comment">// just as easily finish on any other executor. See SPARK-8167.</span></div><div class="line">            (<span class="literal">false</span>, <span class="string">s"Container <span class="subst">$&#123;containerId&#125;</span><span class="subst">$&#123;onHostStr&#125;</span> was preempted."</span>)</div><div class="line">          <span class="comment">// Should probably still count memory exceeded exit codes towards task failures</span></div><div class="line">          <span class="keyword">case</span> <span class="type">VMEM_EXCEEDED_EXIT_CODE</span> =&gt;</div><div class="line">            (<span class="literal">true</span>, memLimitExceededLogMessage(</div><div class="line">              completedContainer.getDiagnostics,</div><div class="line">              <span class="type">VMEM_EXCEEDED_PATTERN</span>))</div><div class="line">          <span class="keyword">case</span> <span class="type">PMEM_EXCEEDED_EXIT_CODE</span> =&gt;</div><div class="line">            (<span class="literal">true</span>, memLimitExceededLogMessage(</div><div class="line">              completedContainer.getDiagnostics,</div><div class="line">              <span class="type">PMEM_EXCEEDED_PATTERN</span>))</div><div class="line">          <span class="keyword">case</span> _ =&gt;</div><div class="line">            <span class="comment">// Enqueue the timestamp of failed executor</span></div><div class="line">            failedExecutorsTimeStamps.enqueue(clock.getTimeMillis())</div><div class="line">            (<span class="literal">true</span>, <span class="string">"Container marked as failed: "</span> + containerId + onHostStr +</div><div class="line">              <span class="string">". Exit status: "</span> + completedContainer.getExitStatus +</div><div class="line">              <span class="string">". Diagnostics: "</span> + completedContainer.getDiagnostics)</div><div class="line"></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 如果是由于Application的原因退出的，则以警告记录日志，否则以info级别记录日志</span></div><div class="line">        <span class="keyword">if</span> (exitCausedByApp) &#123;</div><div class="line">          logWarning(containerExitReason)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          logInfo(containerExitReason)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 生成一个ExecutorExited 对象并返回给变量</span></div><div class="line">        <span class="type">ExecutorExited</span>(exitStatus, exitCausedByApp, containerExitReason)</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="comment">// 如果 alreadyReleased 为true，则表示 container已经被kill掉了，在 internalReleaseContainer 方法中会操作</span></div><div class="line">        <span class="type">ExecutorExited</span>(completedContainer.getExitStatus, exitCausedByApp = <span class="literal">false</span>,</div><div class="line">          <span class="string">s"Container <span class="subst">$containerId</span> exited from explicit termination request."</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// &lt;2&gt;</span></div><div class="line"></div><div class="line">      <span class="keyword">for</span> &#123;</div><div class="line">        host &lt;- hostOpt</div><div class="line">        <span class="comment">// 根据host获取上面所运行的container</span></div><div class="line">        containerSet &lt;- allocatedHostToContainersMap.get(host)</div><div class="line">      &#125; &#123;</div><div class="line">        <span class="comment">// 将container从host所包含的container集合中删除，这样host上的container集合就含有这个container了</span></div><div class="line">        containerSet.remove(containerId)</div><div class="line">        <span class="comment">// 删除完成后，如果 container 集合列表空了，则说明 host上只运行了这一个contianer，则删除host与container的对应关系，否则就更新一下</span></div><div class="line">        <span class="keyword">if</span> (containerSet.isEmpty) &#123;</div><div class="line">          allocatedHostToContainersMap.remove(host)</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          allocatedHostToContainersMap.update(host, containerSet)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 将container 到 host的映射关系也删除</span></div><div class="line">        allocatedContainerToHostMap.remove(containerId)</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 移除 container到executor的对应关系</span></div><div class="line">      containerIdToExecutorId.remove(containerId).foreach &#123; eid =&gt;</div><div class="line">        <span class="comment">// 将executor到container的对应关系也删除</span></div><div class="line">        executorIdToContainer.remove(eid)</div><div class="line"></div><div class="line">        <span class="comment">// 从 pendingLossReasonRequests 移除 executor</span></div><div class="line">        pendingLossReasonRequests.remove(eid) <span class="keyword">match</span> &#123;</div><div class="line">          <span class="keyword">case</span> <span class="type">Some</span>(pendingRequests) =&gt;</div><div class="line">            <span class="comment">// Notify application of executor loss reasons so it can decide whether it should abort</span></div><div class="line">            pendingRequests.foreach(_.reply(exitReason))</div><div class="line"></div><div class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">            releasedExecutorLossReasons.put(eid, exitReason)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// &lt;3&gt;</span></div><div class="line"></div><div class="line">        <span class="comment">// 如果没有被kill掉</span></div><div class="line">        <span class="keyword">if</span> (!alreadyReleased) &#123;</div><div class="line">          <span class="comment">// The executor could have gone away (like no route to host, node failure, etc)</span></div><div class="line">          <span class="comment">// Notify backend about the failure of the executor</span></div><div class="line">          <span class="comment">// container非异常释放的计数加一</span></div><div class="line">          numUnexpectedContainerRelease += <span class="number">1</span></div><div class="line">          <span class="comment">// 发送删除 execurot的请求</span></div><div class="line">          driverRef.send(<span class="type">RemoveExecutor</span>(eid, exitReason))</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// &lt;4&gt;</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p><1> 获取containerId, 判断container是否在releasedContainers 中，获取 container所在的host，以便后面使用。</1></p>
<p><2> 分析contianer退出的原因，退出的类型分为 App引发的和非App引发的。具体的判断，可以看代码和注释。</2></p>
<p><3> 主要为了清理container各种关系的保存信息。</3></p>
<p><4> 使用Netty RPC发送移除Executor的信息。</4></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从上面的代码的调用过程以及实现我们可以看出，YarnAllocator实际上类似一个过滤器，它会从Resource Manager那里申请资源（通过AMRMClient获取），对获取到资源按照host -&gt; stack -&gt; any的顺序筛选container，并将合适的container启动后，反馈给调用者。<br>这个类功能很简单，但是在整个集群中又比较不太好理解，首先需要确定的是，YarnAllocator自己不管理资源（不对资源进行操作），只是筛选，虽然也会有释放、取消操作，但是这些操作都是调用Resource Manager的api来完成的。<br>另外，YarnAllocator是运行在driver上的，由AM来调用（？？？？？需要再次确认），因此，如果每个application都会有自己的YarnAllocator，它只是为自己的job的运行筛选container，而不是全局为所有的application统一筛选。</p>
<h1 id="AMRMClient的一些方法"><a href="#AMRMClient的一些方法" class="headerlink" title="AMRMClient的一些方法"></a>AMRMClient的一些方法</h1><table>
<thead>
<tr>
<th style="text-align:left">方法名</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">AllocateResponse allocate(float progressIndicator)</td>
<td style="text-align:left">请求额外的container并接收新的container的分配。</td>
</tr>
<tr>
<td style="text-align:left">List&lt;? extends Collection<t>&gt; getMatchingRequests(Priority priority, String resourceName, Resource capability)</t></td>
<td style="text-align:left">获取与给定参数匹配的未完成的请求。</td>
</tr>
<tr>
<td style="text-align:left">void removeContainerRequest(T req)</td>
<td style="text-align:left">移除之前的container请求。</td>
</tr>
<tr>
<td style="text-align:left">void addContainerRequest(T req)</td>
<td style="text-align:left">在调用allocate之前为container申请资源。</td>
</tr>
<tr>
<td style="text-align:left">void releaseAssignedContainer(ContainerId containerId)</td>
<td style="text-align:left">释放由Resource Manager分配的container。</td>
</tr>
<tr>
<td style="text-align:left">RegisterApplicationMasterResponse registerApplicationMaster(String appHostName, int appHostPort, String appTrackingUrl)</td>
<td style="text-align:left">注册application Master</td>
</tr>
</tbody>
</table>
<h1 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h1><h2 id="YarnAllocator是什么时候生成的"><a href="#YarnAllocator是什么时候生成的" class="headerlink" title="YarnAllocator是什么时候生成的"></a>YarnAllocator是什么时候生成的</h2><p>是在YarnRMClient的register方法中，向AMRMClient注册ApplicationMaster（调用AMRMClient.registerApplicationMaster方法）完成之后生成的。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">register</span></span>(</div><div class="line">      driverUrl: <span class="type">String</span>,</div><div class="line">      driverRef: <span class="type">RpcEndpointRef</span>,</div><div class="line">      conf: <span class="type">YarnConfiguration</span>,</div><div class="line">      sparkConf: <span class="type">SparkConf</span>,</div><div class="line">      uiAddress: <span class="type">Option</span>[<span class="type">String</span>],</div><div class="line">      uiHistoryAddress: <span class="type">String</span>,</div><div class="line">      securityMgr: <span class="type">SecurityManager</span>,</div><div class="line">      localResources: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LocalResource</span>]</div><div class="line">    ): <span class="type">YarnAllocator</span> = &#123;</div><div class="line">    amClient = <span class="type">AMRMClient</span>.createAMRMClient()</div><div class="line">    amClient.init(conf)</div><div class="line">    amClient.start()</div><div class="line">    <span class="keyword">this</span>.uiHistoryAddress = uiHistoryAddress</div><div class="line"></div><div class="line">    <span class="keyword">val</span> trackingUrl = uiAddress.getOrElse &#123;</div><div class="line">      <span class="keyword">if</span> (sparkConf.get(<span class="type">ALLOW_HISTORY_SERVER_TRACKING_URL</span>)) uiHistoryAddress <span class="keyword">else</span> <span class="string">""</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    logInfo(<span class="string">"Registering the ApplicationMaster"</span>)</div><div class="line">    synchronized &#123;</div><div class="line">      amClient.registerApplicationMaster(<span class="type">Utils</span>.localHostName(), <span class="number">0</span>, trackingUrl)</div><div class="line">      registered = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">new</span> <span class="type">YarnAllocator</span>(driverUrl, driverRef, conf, sparkConf, amClient, getAttemptId(), securityMgr,</div><div class="line">      localResources, <span class="keyword">new</span> <span class="type">SparkRackResolver</span>())</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/09/17/spark-resource-study/" itemprop="url">
                  Spark Resource Study
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-09-17T14:36:19+08:00" content="2018-09-17">
              2018-09-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Core"><a href="#Core" class="headerlink" title="Core"></a>Core</h1><h2 id="Partition-分区"><a href="#Partition-分区" class="headerlink" title="Partition 分区"></a>Partition 分区</h2><p>在Partition特征中，只定义了index，用来表示分区在父级RDD中索引。</p>
<h2 id="Dependency-依赖"><a href="#Dependency-依赖" class="headerlink" title="Dependency 依赖"></a>Dependency 依赖</h2><p>依赖的定义在 org.apache.spark.Dependency类中，从代码中可以看出，Dependency有2个子类，分别代表了2中类型的依赖，分别为：NarrowDependency和ShuffleDependency。其中NarrowDependency有两个子类：OneToOneDependency和RangeDependency。</p>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>RDD是Resilient Distributed Dataset的简称，是Spark中的基本抽象。要实例化一个RDD，需要两个参数：SparkContext和Dependency列表。需要SparkContext是因为SparkContext提供了RDD的一些操作（如生成RDD的id，清理RDD的缓存、缓存RDD等），而Dependency则是因为它表示了RDD的继承关系。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RDD</span>[<span class="type">T</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></div><div class="line">    @transient private var _sc: <span class="type">SparkContext</span>,</div><div class="line">    @transient private var deps: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]]</div><div class="line">  ) <span class="keyword">extends</span> <span class="title">Serializable</span> <span class="keyword">with</span> <span class="title">Logging</span> &#123;</div></pre></td></tr></table></figure></p>
<p>此处可以看到RDD的基本构造方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(<span class="meta">@transient</span> oneParent: <span class="type">RDD</span>[_]) =</div><div class="line">    <span class="keyword">this</span>(oneParent.context, <span class="type">List</span>(<span class="keyword">new</span> <span class="type">OneToOneDependency</span>(oneParent)))</div></pre></td></tr></table></figure>
<p>使用已有的RDD构造新的RDD。</p>
<p>此外，RDD定义了一些抽象，需要子类进行实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>] -- 计算给定的分区，返回一个迭代器</div><div class="line"></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] -- 返回<span class="type">RDD</span>的所有分区</div><div class="line"></div><div class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getDependencies</span></span>: <span class="type">Seq</span>[<span class="type">Dependency</span>[_]] = deps -- 返回<span class="type">RDD</span>的到父类<span class="type">RDD</span>的所有依赖</div></pre></td></tr></table></figure></p>
<h2 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h2><h1 id="wordCount分析"><a href="#wordCount分析" class="headerlink" title="wordCount分析"></a>wordCount分析</h1><p>了解了一些代码之后，决定从wordCount的案例进行分析，以便了解Spark进行计算时的具体操作。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="string">"master"</span>, <span class="string">"testApplication"</span>);</div><div class="line">sc.hadoopFile(<span class="string">"path"</span>, <span class="number">5</span>).map(_ =&gt; <span class="number">1</span>).count()</div></pre></td></tr></table></figure></p>
<p>因为在Spark中，transform是延迟执行的，也就是说，action之前的transform只有在遇到后面的action之后，才开始执行。因此上面的代码就要从count()开始。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span></span>(): <span class="type">Long</span> = sc.runJob(<span class="keyword">this</span>, <span class="type">Utils</span>.getIteratorSize _).sum  </div><div class="line"><span class="comment">//Utils.getIteratorSize方法，在之后的代码块中展示，其实现就是根据参数的Iterator，计算一下这个迭代器中的数据个数（猜测迭代器最终是RDD分区的迭代器）</span></div><div class="line"><span class="comment">//这里的runJob的定义是</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">U</span>): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</div><div class="line">    runJob(rdd, func, <span class="number">0</span> until rdd.partitions.length)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//然后又指向</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">U</span>, partitions: <span class="type">Seq</span>[<span class="type">Int</span>]): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> cleanedFunc = clean(func)</div><div class="line">    runJob(rdd, (ctx: <span class="type">TaskContext</span>, it: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; cleanedFunc(it), partitions)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">//然后继续指向</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>, partitions: <span class="type">Seq</span>[<span class="type">Int</span>]): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> results = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">U</span>](partitions.size)</div><div class="line">    runJob[<span class="type">T</span>, <span class="type">U</span>](rdd, func, partitions, (index, res) =&gt; results(index) = res)</div><div class="line">    results</div><div class="line">  &#125;</div><div class="line"></div><div class="line"><span class="comment">//继续指向</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>, partitions: <span class="type">Seq</span>[<span class="type">Int</span>], resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    ...</div><div class="line">    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</div><div class="line">    progressBar.foreach(_.finishAll())</div><div class="line">    rdd.doCheckpoint()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>最终执行Job落到了 dagScheduler 对象身上<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>, partitions: <span class="type">Seq</span>[<span class="type">Int</span>], callSite: <span class="type">CallSite</span>, resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>, properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</div><div class="line">    <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</div><div class="line">    ...</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>dagScheduler 的runJob方法中调用submitJob来提交任务</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>, partitions: <span class="type">Seq</span>[<span class="type">Int</span>], callSite: <span class="type">CallSite</span>, resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>, properties: <span class="type">Properties</span>):<span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</div><div class="line">    ...</div><div class="line">    <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</div><div class="line">    eventProcessLoop.post(<span class="type">JobSubmitted</span>(jobId, rdd, func2, partitions.toArray, callSite, waiter, <span class="type">SerializationUtils</span>.clone(properties)))</div><div class="line">    waiter</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>最终，通过eventProcessLoop的post将任务提交到了任务执行队列。 这里需要注意的一个问题，加入任务队列的是一个 JobSubmitted对象。为什么要如此处理呢？需要从eventProcessLoop对象入手。<br>eventProcessLoop是DAGSchedulerEventProcessLoop的实例<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> eventProcessLoop = <span class="keyword">new</span> <span class="type">DAGSchedulerEventProcessLoop</span>(<span class="keyword">this</span>)</div></pre></td></tr></table></figure></p>
<p>查看 DAGSchedulerEventProcessLoop 的定义<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerEventProcessLoop</span>(<span class="params">dagScheduler: <span class="type">DAGScheduler</span></span>) <span class="keyword">extends</span> <span class="title">EventLoop</span>[<span class="type">DAGSchedulerEvent</span>](<span class="params">"dag-scheduler-event-loop"</span>) <span class="keyword">with</span> <span class="title">Logging</span></span></div></pre></td></tr></table></figure></p>
<p>DAGSchedulerEventProcessLoop继承于 EventLoop，EventLoop的内部有一个EventThread的线程，该线程从事件队列中循环获取数据<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (!stopped.get) &#123;</div><div class="line">  <span class="keyword">val</span> event = eventQueue.take()</div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    onReceive(event)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>DAGSchedulerEventProcessLoop的doOnReceive方法的定义如下<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</div><div class="line">      dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当从事件队列中获取到数据后，如果JobSubmitted对象，则调用dagScheduler的handleJobSubmitted方法。由此也知道了为什么eventProcessLoop.post()推的数据是 JobSubmitted 对象了。</p>
<p>再看handleJobSubmitted方法的定义：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</div><div class="line">  finalRDD: <span class="type">RDD</span>[_],</div><div class="line">  func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</div><div class="line">  partitions: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">  callSite: <span class="type">CallSite</span>,</div><div class="line">  listener: <span class="type">JobListener</span>,</div><div class="line">  properties: <span class="type">Properties</span>) &#123;</div><div class="line">	<span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></div><div class="line">	<span class="keyword">try</span> &#123;</div><div class="line">	  <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></div><div class="line">	  <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></div><div class="line">	  finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</div><div class="line">	&#125; <span class="keyword">catch</span> &#123;</div><div class="line">	  <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">	    logWarning(<span class="string">"Creating new stage failed due to exception - job: "</span> + jobId, e)</div><div class="line">	    listener.jobFailed(e)</div><div class="line">	    <span class="keyword">return</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</div><div class="line">	</div><div class="line">	jobIdToActiveJob(jobId) = job</div><div class="line">	activeJobs += job</div><div class="line">	finalStage.setActiveJob(job)</div><div class="line">	<span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</div><div class="line">	<span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</div><div class="line">	listenerBus.post(</div><div class="line">	  <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</div><div class="line">	submitStage(finalStage)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由此看到了创建步骤（createResultStage(finalRDD, func, partitions, jobId, callSite)）和提交步骤（submitStage(finalStage)）的代码。</p>
<p>？？？上面的代码分析过程中，我们知道整个transform的触发点是从action（count()）开始的，而count是最后一个RDD（map生成的那个RDD）的方法。map对应的RDD是MapPartitionsRDD。在MapPartitionsRDD的compute方法中，而compute方法中使用的迭代器是从最开始的那个RDD开始的（ firstParent[T].iterator(split, context) ）。</p>
<p>创建步骤 createResultStage(finalRDD, func, partitions, jobId, callSite)</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/09/07/scal-study/" itemprop="url">
                  Scala Study
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-09-07T14:29:54+08:00" content="2018-09-07">
              2018-09-07
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文只是用来记录scala的一些语法信息</p>
<h1 id="Scala-Option"><a href="#Scala-Option" class="headerlink" title="Scala Option"></a>Scala Option</h1><p>/System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/java_home</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/09/05/optparse-python/" itemprop="url">
                  Python学习之optparse
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-09-05T11:30:34+08:00" content="2018-09-05">
              2018-09-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="optparse"><a href="#optparse" class="headerlink" title="optparse"></a>optparse</h1><p>在使用python进行命令开发的过程中，经常需要使用的就是命令行参数了，本章节介绍一个功能强大，易于使用的内建命令行参数处理模块optparse。</p>
<h2 id="简单的使用"><a href="#简单的使用" class="headerlink" title="简单的使用"></a>简单的使用</h2><p>首先需要创建一个OptionParser对象，该类属于optparse模块，因此使用前需要导入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> optparse <span class="keyword">import</span> OptionParser</div><div class="line">parser = OptionParser(usage=<span class="string">"usage: %prog action [options]"</span>,)</div><div class="line"></div><div class="line">或</div><div class="line"></div><div class="line"><span class="keyword">import</span> optparse</div><div class="line">parser = optparse.OptionParser(usage=<span class="string">"usage: %prog action [options]"</span>,)</div></pre></td></tr></table></figure>
<p>可以不写参数，参数用来指定帮助的显示信息，如果没有指定，则默认显示“usage: %prog [options]”。</p>
<h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">def __init__(self,</div><div class="line">             usage=None,</div><div class="line">             option_list=None,</div><div class="line">             option_class=Option,</div><div class="line">             version=None,</div><div class="line">             conflict_handler=&quot;error&quot;,</div><div class="line">             description=None,</div><div class="line">             formatter=None,</div><div class="line">             add_help_option=True,</div><div class="line">             prog=None,</div><div class="line">             epilog=None):</div><div class="line"></div><div class="line">作者：fuyoufang</div><div class="line">链接：https://www.jianshu.com/p/bec089061742</div><div class="line">來源：简书</div><div class="line">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</div></pre></td></tr></table></figure>
<h3 id="add-option函数"><a href="#add-option函数" class="headerlink" title="add_option函数"></a>add_option函数</h3><p>创建OptionParser对象之后，就可以使用add_option来定义命令行参数了<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parsser.add_option(...)</div></pre></td></tr></table></figure></p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>add_option的前两参数分别为短参数名和长参数名。其中长参数名可以省略。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser.add_option(<span class="string">"-f"</span>, dest=<span class="string">"fileName"</span>)</div></pre></td></tr></table></figure></p>
<h4 id="dest"><a href="#dest" class="headerlink" title="dest"></a>dest</h4><p>定义程序内参数值的名字，之后通过这个名字来取参数的值。如果为空，则使用不加“-”的短参数名。</p>
<h4 id="action"><a href="#action" class="headerlink" title="action"></a>action</h4><p>action是add_option的一个参数，用来指定解析到参数后的操作。默认值为“store”，表示将参数值保存到options对象中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">parser.add_option(<span class="string">"-f"</span>, <span class="string">"--file"</span>, action=<span class="string">"store"</span>, dest=<span class="string">"filename"</span>)</div><div class="line">(options, args) = parser.parse_args([<span class="string">"-f"</span>, <span class="string">"myfile.log"</span>])</div><div class="line"><span class="keyword">print</span> options.filename</div></pre></td></tr></table></figure></p>
<p>其中action值的store还可以有其他两种类型：store_ture和store_false，用来处理不带参数值的参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">parser.add_option(<span class="string">"-g"</span>, action=<span class="string">"store_true"</span>, dest=<span class="string">"isGoodUser"</span>)</div><div class="line">parser.add_option(<span class="string">"-s"</span>, action=<span class="string">"store_false"</span>, dest=<span class="string">"isGoodUser"</span>)</div></pre></td></tr></table></figure></p>
<p>action可以使用的值出了store_true和store_false之外，还可以使用store、store_const、append、count、callback等。</p>
<h4 id="type"><a href="#type" class="headerlink" title="type"></a>type</h4><p>type是add_option方法的一个参数，用来指定参数值的类型，默认为String。还可以指定为“int”、“float”等<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser.add_option(<span class="string">"-n"</span>, type=<span class="string">"int"</span>, dest=<span class="string">"num"</span>)</div></pre></td></tr></table></figure></p>
<h4 id="default"><a href="#default" class="headerlink" title="default"></a>default</h4><p>通过add_option方法的default参数可以对命令行参数设置默认值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser.add_option(<span class="string">"-f"</span>, <span class="string">"--file"</span>, default=<span class="string">"test.log"</span>)</div></pre></td></tr></table></figure></p>
<h4 id="help"><a href="#help" class="headerlink" title="help"></a>help</h4><p>用于指定参数在帮助程序中显示的信息，详细请见下方的“生成帮助”章节。</p>
<h4 id="metavar"><a href="#metavar" class="headerlink" title="metavar"></a>metavar</h4><p>metavar配合help参数，用于帮助提醒用户该命令行所期待的参数，详细请见下方的“生成帮助”章节。</p>
<h4 id="choices"><a href="#choices" class="headerlink" title="choices"></a>choices</h4><p>当type为choices时，需要设置此值。</p>
<h4 id="const"><a href="#const" class="headerlink" title="const"></a>const</h4><p>指定一个常数，配合action为store_const和append_const时一起使用。</p>
<h3 id="parse-args函数"><a href="#parse-args函数" class="headerlink" title="parse_args函数"></a>parse_args函数</h3><p>一旦定义好了所有的命令行参数，就可以调用parse_args()来解析命令行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(options, args) = parser.parse_args()</div></pre></td></tr></table></figure></p>
<h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h4><p>你可以传递一个命令行参数列表给parse_args方法，否则默认使用sys.argv[:1]。<br>parse_args方法有两个返回值：</p>
<blockquote>
<p>options optpars.Values对象，保存了所有命令行的值。只要知道命令行参数名，就可以得到。<br>args 一个由 positional arguments组成的列表。</p>
</blockquote>
<h3 id="set-defaults函数"><a href="#set-defaults函数" class="headerlink" title="set_defaults函数"></a>set_defaults函数</h3><p>除了在add_option方法中使用default参数设置默认值，还可以使用set_default函数，来统一设置默认值。该方法应该在所有add_option函数之前调用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">parser.set_default(filename=<span class="string">"test.log"</span>, isGoodUser=<span class="keyword">False</span>)</div></pre></td></tr></table></figure></p>
<p>set_defaults函数，可以用来设置多个默认值。</p>
<h3 id="has-option方法"><a href="#has-option方法" class="headerlink" title="has_option方法"></a>has_option方法</h3><p>用来检查是否有相应的选项<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> parser.has_option(<span class="string">"fileName"</span>)</div></pre></td></tr></table></figure></p>
<h3 id="remove-option"><a href="#remove-option" class="headerlink" title="remove_option()"></a>remove_option()</h3><p>用来删除相应的选项。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> parser.remove_option(<span class="string">"fileName"</span>)</div></pre></td></tr></table></figure></p>
<h2 id="生成帮助"><a href="#生成帮助" class="headerlink" title="生成帮助"></a>生成帮助</h2><p>optparse的另一个方便的功能便是自动生成帮助，而你需要做的事情就是在调用add_option方法时指定help参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">parser = optparse.OptionParser(usage=<span class="string">"usage: %prog action [options]"</span>,)</div><div class="line">parser.add_option(<span class="string">"-v"</span>, action=<span class="string">"store_true"</span>, metavar=<span class="string">"参数的期望值"</span>, help=<span class="string">"这是-v的参数的意义"</span>)</div></pre></td></tr></table></figure></p>
<p>当optparse解析到-h或者–help时，就会调用parser.print_help()方法来打印帮助信息。</p>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>在出现用户输入无效的、不完整的命令行参数而发生异常时，optparse可以自动检测并处理，比如参数值类型错误等。<br>用户也可以使用parser.error函数来手动抛出异常。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">parser.parse_args()</div><div class="line"><span class="keyword">if</span> parser.isGooodUser:</div><div class="line">    parse.error(<span class="string">"this is an exception"</span>)</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/09/04/ambari-resource/" itemprop="url">
                  Ambari Resource 01
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-09-04T15:03:02+08:00" content="2018-09-04">
              2018-09-04
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在使用Ambari的过程中遇到了好多问题，比如删除一个cluster（使用ambari-server reset命令）后，重启Ambari Server之后一直报错，提示找不到集群。尝试各种方法之后，无法找到满意的解决之道的情况下，只好硬着头皮读读源码，了解一下Ambari的启动机制。在此记下源码阅读的笔记和心得。</p>
<p>首先分析一下Ambari Server的启动脚本(ambari-server.py)，以便了解Ambari Server是如何启动的。</p>
<p>首先看入口函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  <span class="keyword">try</span>:</div><div class="line">    mainBody()</div><div class="line">  <span class="keyword">except</span> (KeyboardInterrupt, EOFError):</div><div class="line">    print(<span class="string">"\nAborting ... Keyboard Interrupt."</span>)</div><div class="line">    sys.exit(<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>没什么可说的，就是调用文件中的 mainBody() 方法。</p>
<h3 id="mainBody方法"><a href="#mainBody方法" class="headerlink" title="mainBody方法"></a>mainBody方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">mainBody</span><span class="params">()</span>:</span></div><div class="line">  <span class="comment">#初始化命令行参数解析器</span></div><div class="line">  parser = optparse.OptionParser(usage=<span class="string">"usage: %prog action [options]"</span>,)</div><div class="line">  action = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">  <span class="comment">#init_action_parser方法，在脚本中会有两个方法，一个是针对windows的一个是针对linux的，所以看代码的时候需要注意（方法上使用@OsFamilyFuncImpl标示），我们这里看的是linux的</span></div><div class="line">  <span class="comment">#就是对命令行解析器进行初始化，并针对行为进行进一步的初始化</span></div><div class="line">  init_action_parser(action, parser)</div><div class="line"></div><div class="line">  <span class="comment">#使用命令行参数解析器，对命令行进行解析</span></div><div class="line">  (options, args) = parser.parse_args()</div><div class="line"></div><div class="line">  <span class="comment"># check if only silent key set</span></div><div class="line">  default_options = parser.get_default_values()</div><div class="line">  silent_options = default_options</div><div class="line">  silent_options.silent = <span class="keyword">True</span></div><div class="line"></div><div class="line">  <span class="keyword">if</span> options == silent_options:</div><div class="line">    options.only_silent = <span class="keyword">True</span></div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    options.only_silent = <span class="keyword">False</span></div><div class="line"></div><div class="line">  <span class="comment"># varbose是在init_action_parser方法中设置的，对应的-v参数。是否打印状态信息</span></div><div class="line">  <span class="comment"># set_varbose方法位于 ambari_commons.logging_utils中，其实就是设置全局变量_VERBOSE的值。</span></div><div class="line">  <span class="comment"># set verbose</span></div><div class="line">  set_verbose(options.verbose)</div><div class="line"></div><div class="line">  <span class="comment">#接下来就是调用main方法。这里目测是同一个main方法，最大的区别就是有异常处理，有待之后补充TODO--------------------？？？</span></div><div class="line">  <span class="keyword">if</span> options.verbose:</div><div class="line">    main(options, args, parser)</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">      main(options, args, parser)</div><div class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">      print_error_msg(<span class="string">"Unexpected &#123;0&#125;: &#123;1&#125;"</span>.format((e).__class__.__name__, str(e)) +\</div><div class="line">      <span class="string">"\nFor more info run ambari-server with -v or --verbose option"</span>)</div><div class="line">      sys.exit(<span class="number">1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_action_parser</span><span class="params">(action, parser)</span>:</span></div><div class="line">  <span class="comment">#定义了参数可用的行为，如ambari-server start，其中start就是行为。这里定义了行为以及对应行为处理操作。</span></div><div class="line">  <span class="comment">#这些行为的处理方法其实是进一步的初始化参数解析器，会根据对应的行为对参数解析器进行不同的初始化。</span></div><div class="line">  action_parser_map = &#123;</div><div class="line">    SETUP_ACTION: init_setup_parser_options,</div><div class="line">    SETUP_JCE_ACTION: init_empty_parser_options,</div><div class="line">    START_ACTION: init_start_parser_options,</div><div class="line">    STOP_ACTION: init_empty_parser_options,</div><div class="line">    RESTART_ACTION: init_start_parser_options,</div><div class="line">    RESET_ACTION: init_reset_parser_options,</div><div class="line">    STATUS_ACTION: init_empty_parser_options,</div><div class="line">    UPGRADE_ACTION: init_empty_parser_options,</div><div class="line">    LDAP_SETUP_ACTION: init_ldap_setup_parser_options,</div><div class="line">    LDAP_SYNC_ACTION: init_ldap_sync_parser_options,</div><div class="line">    SET_CURRENT_ACTION: init_set_current_parser_options,</div><div class="line">    SETUP_SECURITY_ACTION: init_setup_security_parser_options,</div><div class="line">    REFRESH_STACK_HASH_ACTION: init_empty_parser_options,</div><div class="line">    BACKUP_ACTION: init_empty_parser_options,</div><div class="line">    RESTORE_ACTION: init_empty_parser_options,</div><div class="line">    UPDATE_HOST_NAMES_ACTION: init_empty_parser_options,</div><div class="line">    CHECK_DATABASE_ACTION: init_empty_parser_options,</div><div class="line">    ENABLE_STACK_ACTION: init_enable_stack_parser_options,</div><div class="line">    SETUP_SSO_ACTION: init_setup_sso_options,</div><div class="line">    DB_PURGE_ACTION: init_db_purge_parser_options,</div><div class="line">    INSTALL_MPACK_ACTION: init_install_mpack_parser_options,</div><div class="line">    UNINSTALL_MPACK_ACTION: init_uninstall_mpack_parser_options,</div><div class="line">    UPGRADE_MPACK_ACTION: init_upgrade_mpack_parser_options,</div><div class="line">    PAM_SETUP_ACTION: init_pam_setup_parser_options,</div><div class="line">    KERBEROS_SETUP_ACTION: init_kerberos_setup_parser_options,</div><div class="line">  &#125;</div><div class="line">  parser.add_option(<span class="string">"-v"</span>, <span class="string">"--verbose"</span>,</div><div class="line">                    action=<span class="string">"store_true"</span>, dest=<span class="string">"verbose"</span>, default=<span class="keyword">False</span>,</div><div class="line">                    help=<span class="string">"Print verbose status messages"</span>)</div><div class="line">  parser.add_option(<span class="string">"-s"</span>, <span class="string">"--silent"</span>,</div><div class="line">                    action=<span class="string">"store_true"</span>, dest=<span class="string">"silent"</span>, default=<span class="keyword">False</span>,</div><div class="line">                    help=<span class="string">"Silently accepts default prompt values. For db-cleanup command, silent mode will stop ambari server."</span>)</div><div class="line">  <span class="keyword">try</span>:</div><div class="line">    <span class="comment">#根据行为，做进一步的解析器初始化，我们以setup行为为例，那么setup行为的参数解析器对应的是init_setup_parser_options函数。</span></div><div class="line">    action_parser_map[action](parser)</div><div class="line">  <span class="keyword">except</span> KeyError:</div><div class="line">    parser.error(<span class="string">"Invalid action: "</span> + action)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@OsFamilyFuncImpl(OsFamilyImpl.DEFAULT)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_setup_parser_options</span><span class="params">(parser)</span>:</span></div><div class="line">  database_group = optparse.OptionGroup(parser, <span class="string">'Database options (command need to include all options)'</span>)</div><div class="line">  database_group.add_option(<span class="string">'--database'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Database to use embedded|oracle|mysql|mssql|postgres|sqlanywhere"</span>, dest=<span class="string">"dbms"</span>)</div><div class="line">  database_group.add_option(<span class="string">'--databasehost'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Hostname of database server"</span>, dest=<span class="string">"database_host"</span>)</div><div class="line">  database_group.add_option(<span class="string">'--databaseport'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Database port"</span>, dest=<span class="string">"database_port"</span>)</div><div class="line">  database_group.add_option(<span class="string">'--databasename'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Database/Service name or ServiceID"</span>,</div><div class="line">                            dest=<span class="string">"database_name"</span>)</div><div class="line">  database_group.add_option(<span class="string">'--databaseusername'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Database user login"</span>, dest=<span class="string">"database_username"</span>)</div><div class="line">  database_group.add_option(<span class="string">'--databasepassword'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Database user password"</span>, dest=<span class="string">"database_password"</span>)</div><div class="line">  parser.add_option_group(database_group)</div><div class="line"></div><div class="line">  jdbc_group = optparse.OptionGroup(parser, <span class="string">'JDBC options (command need to include all options)'</span>)</div><div class="line">  jdbc_group.add_option(<span class="string">'--jdbc-driver'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Specifies the path to the JDBC driver JAR file or archive "</span> \</div><div class="line">                                                            <span class="string">"with all required files(jdbc jar, libraries and etc), for the "</span> \</div><div class="line">                                                            <span class="string">"database type specified with the --jdbc-db option. "</span> \</div><div class="line">                                                            <span class="string">"Used only with --jdbc-db option. Archive is supported only for"</span> \</div><div class="line">                                                            <span class="string">" sqlanywhere database."</span> ,</div><div class="line">                        dest=<span class="string">"jdbc_driver"</span>)</div><div class="line">  jdbc_group.add_option(<span class="string">'--jdbc-db'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Specifies the database type [postgres|mysql|mssql|oracle|hsqldb|sqlanywhere] for the "</span> \</div><div class="line">                                                        <span class="string">"JDBC driver specified with the --jdbc-driver option. Used only with --jdbc-driver option."</span>,</div><div class="line">                        dest=<span class="string">"jdbc_db"</span>)</div><div class="line">  parser.add_option_group(jdbc_group)</div><div class="line"></div><div class="line">  other_group = optparse.OptionGroup(parser, <span class="string">'Other options'</span>)</div><div class="line"></div><div class="line">  other_group.add_option(<span class="string">'-j'</span>, <span class="string">'--java-home'</span>, default=<span class="keyword">None</span>,</div><div class="line">                         help=<span class="string">"Use specified java_home.  Must be valid on all hosts"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--stack-java-home'</span>, dest=<span class="string">"stack_java_home"</span>, default=<span class="keyword">None</span>,</div><div class="line">                    help=<span class="string">"Use specified java_home for stack services.  Must be valid on all hosts"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--skip-view-extraction'</span>, action=<span class="string">"store_true"</span>, default=<span class="keyword">False</span>, help=<span class="string">"Skip extraction of system views"</span>, dest=<span class="string">"skip_view_extraction"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--postgresschema'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Postgres database schema name"</span>,</div><div class="line">                         dest=<span class="string">"postgres_schema"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--sqla-server-name'</span>, default=<span class="keyword">None</span>, help=<span class="string">"SQL Anywhere server name"</span>, dest=<span class="string">"sqla_server_name"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--sidorsname'</span>, default=<span class="string">"sname"</span>, help=<span class="string">"Oracle database identifier type, Service ID/Service "</span></div><div class="line">                                                               <span class="string">"Name sid|sname"</span>, dest=<span class="string">"sid_or_sname"</span>)</div><div class="line">  other_group.add_option(<span class="string">'--enable-lzo-under-gpl-license'</span>, action=<span class="string">"store_true"</span>, default=<span class="keyword">False</span>, help=<span class="string">"Automatically accepts GPL license"</span>, dest=<span class="string">"accept_gpl"</span>)</div><div class="line"></div><div class="line">  <span class="comment"># the --master-key option is needed in the event passwords in the ambari.properties file are encrypted</span></div><div class="line">  other_group.add_option(<span class="string">'--master-key'</span>, default=<span class="keyword">None</span>, help=<span class="string">"Master key for encrypting passwords"</span>, dest=<span class="string">"master_key"</span>)</div><div class="line"></div><div class="line">  parser.add_option_group(other_group)</div></pre></td></tr></table></figure>
<p>这个方法就是为setup的行为，做了进一步的解析器设置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">_VERBOSE = <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_verbose</span><span class="params">(newVal)</span>:</span></div><div class="line">  <span class="keyword">global</span> _VERBOSE</div><div class="line">  _VERBOSE = newVal</div></pre></td></tr></table></figure>
<p>该方法就是设置全局变量_VERBOSE的值。</p>
<h3 id="main"><a href="#main" class="headerlink" title="main"></a>main</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(options, args, parser)</span>:</span></div><div class="line">  init_logging()</div><div class="line"></div><div class="line">  <span class="comment"># set silent</span></div><div class="line">  set_silent(options.silent)</div><div class="line"></div><div class="line">  <span class="comment"># debug mode</span></div><div class="line">  set_debug_mode_from_options(options)</div><div class="line">  init_debug(options)</div><div class="line"></div><div class="line">  <span class="comment">#perform checks</span></div><div class="line"></div><div class="line">  options.warnings = []</div><div class="line"></div><div class="line">  <span class="keyword">if</span> len(args) == <span class="number">0</span>:</div><div class="line">    <span class="keyword">print</span> parser.print_help()</div><div class="line">    parser.error(<span class="string">"No action entered"</span>)</div><div class="line"></div><div class="line">  action_map = create_user_action_map(args, options)</div><div class="line"></div><div class="line">  action = args[<span class="number">0</span>]</div><div class="line"></div><div class="line">  <span class="keyword">try</span>:</div><div class="line">    action_obj = action_map[action]</div><div class="line">  <span class="keyword">except</span> KeyError:</div><div class="line">    parser.error(<span class="string">"Invalid action: "</span> + action)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> action == SETUP_ACTION:</div><div class="line">    <span class="keyword">if</span> are_cmd_line_db_args_blank(options):</div><div class="line">      options.must_set_database_options = <span class="keyword">True</span></div><div class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> are_cmd_line_db_args_valid(options):</div><div class="line">      parser.error(<span class="string">'All database options should be set. Please see help for the options.'</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      options.must_set_database_options = <span class="keyword">False</span></div><div class="line"></div><div class="line">    <span class="comment">#correct database</span></div><div class="line">    fix_database_options(options, parser)</div><div class="line"></div><div class="line">  matches = <span class="number">0</span></div><div class="line">  <span class="keyword">for</span> args_number_required <span class="keyword">in</span> action_obj.possible_args_numbers:</div><div class="line">    matches += int(len(args) == args_number_required)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> matches == <span class="number">0</span>:</div><div class="line">    <span class="keyword">print</span> parser.print_help()</div><div class="line">    possible_args = <span class="string">' or '</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> action_obj.possible_args_numbers)</div><div class="line">    parser.error(<span class="string">"Invalid number of arguments. Entered: "</span> + str(len(args)) + <span class="string">", required: "</span> + possible_args)</div><div class="line"></div><div class="line">  options.exit_message = <span class="string">"Ambari Server '%s' completed successfully."</span> % action</div><div class="line">  options.exit_code = <span class="keyword">None</span></div><div class="line"></div><div class="line">  <span class="keyword">try</span>:</div><div class="line">    <span class="keyword">if</span> action <span class="keyword">in</span> _action_option_dependence_map:</div><div class="line">      required, optional = _action_option_dependence_map[action]</div><div class="line">      <span class="keyword">for</span> opt_str, opt_dest <span class="keyword">in</span> required:</div><div class="line">        <span class="keyword">if</span> hasattr(options, opt_dest) <span class="keyword">and</span> getattr(options, opt_dest) <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">          <span class="keyword">print</span> <span class="string">"Missing option &#123;0&#125; for action &#123;1&#125;"</span>.format(opt_str, action)</div><div class="line">          print_action_arguments_help(action)</div><div class="line">          <span class="keyword">print</span> <span class="string">"Run ambari-server.py --help to see detailed description of each option"</span></div><div class="line">          <span class="keyword">raise</span> FatalException(<span class="number">1</span>, <span class="string">"Missing option"</span>)</div><div class="line">    action_obj.execute()</div><div class="line"></div><div class="line">    <span class="keyword">if</span> action_obj.need_restart:</div><div class="line">      pstatus, pid = is_server_runing()</div><div class="line">      <span class="keyword">if</span> pstatus:</div><div class="line">        <span class="keyword">print</span> <span class="string">'NOTE: Restart Ambari Server to apply changes'</span> + \</div><div class="line">              <span class="string">' ("ambari-server restart|stop+start")'</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> options.warnings:</div><div class="line">      <span class="keyword">for</span> warning <span class="keyword">in</span> options.warnings:</div><div class="line">        print_warning_msg(warning)</div><div class="line">        <span class="keyword">pass</span></div><div class="line">      options.exit_message = <span class="string">"Ambari Server '%s' completed with warnings."</span> % action</div><div class="line">      <span class="keyword">pass</span></div><div class="line">  <span class="keyword">except</span> FatalException <span class="keyword">as</span> e:</div><div class="line">    <span class="keyword">if</span> e.reason <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      print_error_msg(<span class="string">"Exiting with exit code &#123;0&#125;. \nREASON: &#123;1&#125;"</span>.format(e.code, e.reason))</div><div class="line">      logger.exception(str(e))</div><div class="line">    sys.exit(e.code)</div><div class="line">  <span class="keyword">except</span> NonFatalException <span class="keyword">as</span> e:</div><div class="line">    options.exit_message = <span class="string">"Ambari Server '%s' completed with warnings."</span> % action</div><div class="line">    <span class="keyword">if</span> e.reason <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      print_warning_msg(e.reason)</div><div class="line"></div><div class="line">  <span class="keyword">if</span> options.exit_message <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">    <span class="keyword">print</span> options.exit_message</div><div class="line"></div><div class="line">  <span class="keyword">if</span> options.exit_code <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:  <span class="comment"># not all actions may return a system exit code</span></div><div class="line">    sys.exit(options.exit_code)</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/08/20/ambari-doc/" itemprop="url">
                  ambari_doc
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-08-20T15:57:27+08:00" content="2018-08-20">
              2018-08-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/Ambari/" itemprop="url" rel="index">
                    <span itemprop="name">Ambari</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Stacks-and-Services"><a href="#Stacks-and-Services" class="headerlink" title="Stacks and Services"></a>Stacks and Services</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Ambari支持Stack的概念，并且将服务组合在一个Stack定义中。通过堆栈的作用，Ambari有统一定义的安装接口，管理并监控一组服务，并且引入了Stacks+Servides来提供延伸。<br>从Ambari2.3开始，还支持Extension的概念，并将自定义服务组合在一个Extension定义中。</p>
<h2 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h2><table>
<thead>
<tr>
<th style="text-align:left">Term</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Stack</td>
<td style="text-align:left">定义了一组服务，并且这些服务从这里获取软件包。一个Stack能够有一个或多个版本，并且每个版本可以是活跃/不活跃的。例如, Stack=”HDP-1.3.3”。</td>
</tr>
<tr>
<td style="text-align:left">Extension</td>
<td style="text-align:left">定义了一组自定义服务，这些自定义服务可以被添加到一个stack版本中。一个Extension能够有一个或多个版本。</td>
</tr>
<tr>
<td style="text-align:left">Service</td>
<td style="text-align:left">定义Components（MASTER、SLAVE、CLIENT）组成了Service。如，Service=”HDFS”。</td>
</tr>
<tr>
<td style="text-align:left">Component</td>
<td style="text-align:left">每个Component遵循确切的生命周期（start、stop、install等）。例如：Service=”HDFS”包含的组件有：”NameNode(MASTER)”、”Secondary NameNode(MASTER)”、”DataNode(SLAVE)”和”HDFS Client(CLIENT)”</td>
</tr>
</tbody>
</table>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Stack的定义可以在源码结构的/ambari-server/src/main/resources/stacks中找到。在你安装了Ambari服务之后，Stack的定义可以在/var/lib/ambari-server/resources/stacks中找到。</p>
<h2 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h2><p>Stack定义的结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">|_ stacks</div><div class="line">   |_ &lt;stack_name&gt;</div><div class="line">      |_ &lt;stack_version&gt;</div><div class="line">         metainfo.xml</div><div class="line">         |_ hooks</div><div class="line">         |_ repos</div><div class="line">            repoinfo.xml</div><div class="line">         |_ services</div><div class="line">            |_ &lt;service_name&gt;</div><div class="line">               metainfo.xml</div><div class="line">               metrics.json</div><div class="line">               |_ configuration</div><div class="line">                  &#123;configuration files&#125;</div><div class="line">               |_ package</div><div class="line">                  &#123;files, scripts, templates&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Defining-a-Service-and-Components"><a href="#Defining-a-Service-and-Components" class="headerlink" title="Defining a Service and Components"></a>Defining a Service and Components</h2><p>Service中的metainfo.xml描述了这个service、这个service的Components以及管理执行命令的脚本。服务的一个组件只能是MASTER、SLAVE或CLIENT三种类型中的一个。组件的类型用来告诉Ambari管理和监控这个组件的默认脚本。<br>对于每个Component，<commandscript>用来指从合适执行脚本。这个Component必须支持的一组默认命令。</commandscript></p>
<p>| Component Category | Default Lifecycle Commands |<br>| MASTER             | install, start, stop, configure, status |<br>| SLAVE              | install, start, stop, configure, status |<br>| CLIENT             | install, configure, status |</p>
<p>Ambari支持用PYTHON写的不同命令。类型用来知道如何执行命令脚本。如果你的Component需要支持多于默认生命周期的命令，你也能够创建自定义命令。<br>例如，下面的metainfo.xml在YARN服务描述了ResourceManager组件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;component&gt;</div><div class="line">  &lt;name&gt;RESOURCEMANAGER&lt;/name&gt;</div><div class="line">  &lt;category&gt;MASTER&lt;/category&gt;</div><div class="line">  &lt;commandScript&gt;</div><div class="line">    &lt;script&gt;scripts/resourcemanager.py&lt;/script&gt;</div><div class="line">    &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">    &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">  &lt;/commandScript&gt;</div><div class="line">  &lt;customCommands&gt;</div><div class="line">    &lt;customCommand&gt;</div><div class="line">      &lt;name&gt;DECOMMISSION&lt;/name&gt;</div><div class="line">      &lt;commandScript&gt;</div><div class="line">        &lt;script&gt;scripts/resourcemanager.py&lt;/script&gt;</div><div class="line">        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">      &lt;/commandScript&gt;</div><div class="line">    &lt;/customCommand&gt;</div><div class="line">  &lt;/customCommands&gt;</div><div class="line">&lt;/component&gt;</div></pre></td></tr></table></figure></p>
<p>ResourceManager是一个MASTER组件，这个命令脚本为scripts/resourcemanager.py，这个脚本可以在services/YARN/package目录中找到。这个脚本是使用PYTHON写的，并且这个以python方法的方式实现了默认的生命周期命令。下面是install方法，对应的是默认的INSTALL命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resourcemanager</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    self.install_packages(env)</div><div class="line">    self.configure(env)</div></pre></td></tr></table></figure></p>
<p>你还可以看到有一个自定义命令DECOMMISSION，这意味着在python命令脚本中还有一个decommission方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decommission</span><span class="params">(self, env)</span>:</span></div><div class="line">  <span class="keyword">import</span> params</div><div class="line"> </div><div class="line">  ...</div><div class="line"> </div><div class="line">  Execute(yarn_refresh_cmd,</div><div class="line">          user=yarn_user</div><div class="line">  )</div><div class="line">  <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<h2 id="Using-Stack-Inheritance"><a href="#Using-Stack-Inheritance" class="headerlink" title="Using Stack Inheritance"></a>Using Stack Inheritance</h2><p>Stacks能够从其他Stack进行继承，以便共享命令脚本和配置。通过如下方式降低了代码的重复：</p>
<blockquote>
<p>为子Stack定义了repositories。<br>在子Stack中添加新的Service（不是在父Stack中）。<br>重写父级Services的命令脚本。<br>重写父级Services的配置。</p>
</blockquote>
<p>例如：HDP 2.1 Stack继承了HDP 2.0.6 Stack，因此只需要在Stack定义中对HDP 2.1 Stack中适当的修改。这个extension在metainfo.xml中对HDP 2.1 Stack进行定义。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">metainfo</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">versions</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">active</span>&gt;</span>true<span class="tag">&lt;/<span class="name">active</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">versions</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">extends</span>&gt;</span>2.0.6<span class="tag">&lt;/<span class="name">extends</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metainfo</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h2 id="Example-Implementing-a-Custom-Service"><a href="#Example-Implementing-a-Custom-Service" class="headerlink" title="Example: Implementing a Custom Service"></a>Example: Implementing a Custom Service</h2><p>在这个例子中，我们将创建一个名为”SAMPLESRV”的自定义service，并将它添加到已有的Stack定义中。这个service含有 MASTER、SLAVE和CLIENT组件。</p>
<h3 id="Create-and-Add-the-Service"><a href="#Create-and-Add-the-Service" class="headerlink" title="Create and Add the Service"></a>Create and Add the Service</h3><p>1、在Ambari server上，跳转到/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services目录。在这个例子中，我们将浏览到HDP 2.0 stack定义。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services</div></pre></td></tr></table></figure></p>
<p>2、创建一个目录：/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV。它用来包含SAMPLESEV的service的定义。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV</div></pre></td></tr></table></figure></p>
<p>3、跳转到新创建的SAMPLESRV目录，创建metainfo.xml文件，这个文件用来描述新的service。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;metainfo&gt;</div><div class="line">    &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt;</div><div class="line">    &lt;services&gt;</div><div class="line">        &lt;service&gt;</div><div class="line">            &lt;name&gt;SAMPLESRV&lt;/name&gt;</div><div class="line">            &lt;displayName&gt;New Sample Service&lt;/displayName&gt;</div><div class="line">            &lt;comment&gt;A New Sample Service&lt;/comment&gt;</div><div class="line">            &lt;version&gt;1.0.0&lt;/version&gt;</div><div class="line">            &lt;components&gt;</div><div class="line">                &lt;component&gt;</div><div class="line">                    &lt;name&gt;SAMPLESRV_MASTER&lt;/name&gt;</div><div class="line">                    &lt;displayName&gt;Sample Srv Master&lt;/displayName&gt;</div><div class="line">                    &lt;category&gt;MASTER&lt;/category&gt;</div><div class="line">                    &lt;cardinality&gt;1&lt;/cardinality&gt;</div><div class="line">                    &lt;commandScript&gt;</div><div class="line">                        &lt;script&gt;scripts/master.py&lt;/script&gt;</div><div class="line">                        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                    &lt;/commandScript&gt;</div><div class="line">                &lt;/component&gt;</div><div class="line">                &lt;component&gt;</div><div class="line">                    &lt;name&gt;SAMPLESRV_SLAVE&lt;/name&gt;</div><div class="line">                    &lt;displayName&gt;Sample Srv Slave&lt;/displayName&gt;</div><div class="line">                    &lt;category&gt;SLAVE&lt;/category&gt;</div><div class="line">                    &lt;cardinality&gt;1+&lt;/cardinality&gt;</div><div class="line">                    &lt;commandScript&gt;</div><div class="line">                        &lt;script&gt;scripts/slave.py&lt;/script&gt;</div><div class="line">                        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                    &lt;/commandScript&gt;</div><div class="line">                &lt;/component&gt;</div><div class="line">                &lt;component&gt;</div><div class="line">                    &lt;name&gt;SAMPLESRV_CLIENT&lt;/name&gt;</div><div class="line">                    &lt;displayName&gt;Sample Srv Client&lt;/displayName&gt;</div><div class="line">                    &lt;category&gt;CLIENT&lt;/category&gt;</div><div class="line">                    &lt;cardinality&gt;1+&lt;/cardinality&gt;</div><div class="line">                    &lt;commandScript&gt;</div><div class="line">                        &lt;script&gt;scripts/sample_client.py&lt;/script&gt;</div><div class="line">                        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                    &lt;/commandScript&gt;</div><div class="line">                &lt;/component&gt;</div><div class="line">            &lt;/components&gt;</div><div class="line">            &lt;osSpecifics&gt;</div><div class="line">                &lt;osSpecific&gt;</div><div class="line">                    &lt;osFamily&gt;any&lt;/osFamily&gt;  &lt;!-- note: use osType rather than osFamily for Ambari 1.5.0 and 1.5.1 --&gt;</div><div class="line">                &lt;/osSpecific&gt;</div><div class="line">            &lt;/osSpecifics&gt;</div><div class="line">        &lt;/service&gt;</div><div class="line">    &lt;/services&gt;</div><div class="line">&lt;/metainfo&gt;</div></pre></td></tr></table></figure></p>
<p>4、在上面，我们的service名为“SAMPLESRV”，它包含：</p>
<blockquote>
<p>一个名为”SAMPLESRV_MASTER”的MASTER的组件。<br>一个名为“SLAVE”的SLAVE的组件。<br>一个名为“CLIENT”的CLIENT的组件。</p>
</blockquote>
<p>5、接下来，创建命令脚本。为脚本创建目录/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV/package/scripts，并在这个目录中定义service的metainfo。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV/package/scripts</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/SAMPLESRV/package/scripts</div></pre></td></tr></table></figure></p>
<p>跳转到script目录，并创建.py命令脚本文件。<br>master.py文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Master</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Stop the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Start the Sample Srv Master'</span>;</div><div class="line">     </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Status of the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Master'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  Master().execute()</div></pre></td></tr></table></figure></p>
<p>slave.py文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Slave</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Stop the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Start the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Status of the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Slave'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  Slave().execute()</div></pre></td></tr></table></figure></p>
<p>sample_client.py文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SampleClient</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Client'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Client'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  SampleClient().execute()</div></pre></td></tr></table></figure></p>
<p>7、现在重启Ambari Server以便新的service定义分发到集群的所有Agents。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ambari-server restart</div></pre></td></tr></table></figure></p>
<h3 id="Install-the-Service-Via-Ambari-WEb-“Add-Service”"><a href="#Install-the-Service-Via-Ambari-WEb-“Add-Service”" class="headerlink" title="Install the Service(Via Ambari WEb “Add Service”)"></a>Install the Service(Via Ambari WEb “Add Service”)</h3><p>从Ambari 1.7.0开始，可以通过Ambari Web来添加自定义服务。</p>
<blockquote>
<p>在Ambari web页面，跳转到services，并点击左边service导航部分的Action按钮。<br>点击“Add Services”。你将看到一个包含“My Sample Service”（在metainfo.xml文件中定义service的<displayname>）的选项。<br>选择“My Sample service”并点击下一步。<br>选择“Sample Srv Master”并点击下一步。<br>选择host来安装”Sample Srv Client”，并点击下一步。<br>一旦完成，”My Sample Service”将会在在service导航区可用。<br>如果你想要为所有host添加“Sample Srv Client”，你可以跳转到Host，并到航道指定的host并点击”+ Add”。</displayname></p>
</blockquote>
<h2 id="Example-Implementing-a-Custom-Client-only-Service"><a href="#Example-Implementing-a-Custom-Client-only-Service" class="headerlink" title="Example: Implementing a Custom Client-only Service"></a>Example: Implementing a Custom Client-only Service</h2><p>在这个例子中，我们将创建一个名为“TESTSRV”的自定义service，添加到已经存在的Stack定义上，并Ambari APIs来安装/配置这个service。这个service是一个CLIENT，因此它有两个命令：install和configure。</p>
<h3 id="Create-and-Add-the-Service-1"><a href="#Create-and-Add-the-Service-1" class="headerlink" title="Create and Add the Service"></a>Create and Add the Service</h3><p>1、在Ambari Service上，跳转到 /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services目录。在这个例子中，我们将跳转到HDP2.0 Stack 定义中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services</div></pre></td></tr></table></figure></p>
<p>2、创建一个名为/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV的目录，它用来包含TESTSRV的service定义。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV</div></pre></td></tr></table></figure></p>
<p>3、跳转到新创建的TESTSRV目录，创建一个名为metainfo.xml的文件用来描述新的service。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;metainfo&gt;</div><div class="line">    &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt;</div><div class="line">    &lt;services&gt;</div><div class="line">        &lt;service&gt;</div><div class="line">            &lt;name&gt;TESTSRV&lt;/name&gt;</div><div class="line">            &lt;displayName&gt;New Test Service&lt;/displayName&gt;</div><div class="line">            &lt;comment&gt;A New Test Service&lt;/comment&gt;</div><div class="line">            &lt;version&gt;0.1.0&lt;/version&gt;</div><div class="line">            &lt;components&gt;</div><div class="line">                &lt;component&gt;</div><div class="line">                    &lt;name&gt;TEST_CLIENT&lt;/name&gt;</div><div class="line">                    &lt;displayName&gt;New Test Client&lt;/displayName&gt;</div><div class="line">                    &lt;category&gt;CLIENT&lt;/category&gt;</div><div class="line">                    &lt;cardinality&gt;1+&lt;/cardinality&gt;</div><div class="line">                    &lt;commandScript&gt;</div><div class="line">                        &lt;script&gt;scripts/test_client.py&lt;/script&gt;</div><div class="line">                        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                    &lt;/commandScript&gt;</div><div class="line">                    &lt;customCommands&gt;</div><div class="line">                      &lt;customCommand&gt;</div><div class="line">                        &lt;name&gt;SOMETHINGCUSTOM&lt;/name&gt;</div><div class="line">                        &lt;commandScript&gt;</div><div class="line">                          &lt;script&gt;scripts/test_client.py&lt;/script&gt;</div><div class="line">                          &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                          &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                        &lt;/commandScript&gt;</div><div class="line">                      &lt;/customCommand&gt;</div><div class="line">                    &lt;/customCommands&gt;</div><div class="line">                &lt;/component&gt;</div><div class="line">            &lt;/components&gt;</div><div class="line">            &lt;osSpecifics&gt;</div><div class="line">                &lt;osSpecific&gt;</div><div class="line">                    &lt;osFamily&gt;any&lt;/osFamily&gt;  &lt;!-- note: use osType rather than osFamily for Ambari 1.5.0 and 1.5.1 --&gt;</div><div class="line">                &lt;/osSpecific&gt;</div><div class="line">            &lt;/osSpecifics&gt;</div><div class="line">        &lt;/service&gt;</div><div class="line">    &lt;/services&gt;</div><div class="line">&lt;/metainfo&gt;</div></pre></td></tr></table></figure></p>
<p>4、在上面，我们的service名为“TESTSRV”，并且它包含了一个名为“TEST_CLIENT”的组件，这个组件属于CLIENT类型。这个client通过命令脚本scripts/test_client.py来管理。接下来创建命令脚本。<br>5、为命令脚本创建目录/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV/package/scripts。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV/package/scripts</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTSRV/package/scripts</div></pre></td></tr></table></figure></p>
<p>6、跳转到scripts目录，并创建test_client.py文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"> </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestClient</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the client'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the client'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">somethingcustom</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Something custom'</span>;</div><div class="line"> </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  TestClient().execute()</div></pre></td></tr></table></figure></p>
<p>7、现在，重启Ambari Server，将新的service定义分发到集群的所有Agents。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ambari-server restart</div></pre></td></tr></table></figure></p>
<h3 id="Install-the-Service-Via-the-Ambari-REST-API"><a href="#Install-the-Service-Via-the-Ambari-REST-API" class="headerlink" title="Install the Service(Via the Ambari REST API)"></a>Install the Service(Via the Ambari REST API)</h3><p>1、将Service添加到Cluster。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">POST</div><div class="line">/api/v1/clusters/MyCluster/services</div><div class="line"> </div><div class="line">&#123;</div><div class="line">&quot;ServiceInfo&quot;: &#123;</div><div class="line">  &quot;service_name&quot;:&quot;TESTSRV&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>2、添加组件到Service。这个例子中，添加TEST_CLIENT到TESTSRV。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">POST</div><div class="line">/api/v1/clusters/MyCluster/services/TESTSRV/components/TEST_CLIENT</div></pre></td></tr></table></figure></p>
<p>3、将组件添加到所有host。例如，要安装到c6402.ambari.apache.org和c6403.ambari.apache.org上，首先使用POST在这些主机上创建host_component源<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">POST</div><div class="line">/api/v1/clusters/MyCluster/hosts/c6402.ambari.apache.org/host_components/TEST_CLIENT</div><div class="line"> </div><div class="line">POST</div><div class="line">/api/v1/clusters/MyCluster/hosts/c6403.ambari.apache.org/host_components/TEST_CLIENT</div></pre></td></tr></table></figure></p>
<p>4、现在，需要在所有主机上安装组件。在这个命令中，你指导Ambari来安装与这个service有关的所有组件。调用每个主机上命令脚本的install方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">PUT</div><div class="line">/api/v1/clusters/MyCluster/services/TESTSRV</div><div class="line"> </div><div class="line">&#123;</div><div class="line">  &quot;RequestInfo&quot;: &#123;</div><div class="line">    &quot;context&quot;: &quot;Install Test Srv Client&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;Body&quot;: &#123;</div><div class="line">    &quot;ServiceInfo&quot;: &#123;</div><div class="line">      &quot;state&quot;: &quot;INSTALLED&quot;</div><div class="line">    &#125;   </div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>除了同时安装所有的组件，你还可以只在某一台机器上装组件。在这个例子中，我们在c6402.ambari.apache.org上安装TEST_CLIENT：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">PUT</div><div class="line">/api/v1/clusters/MyCluster/hosts/c6402.ambari.apache.org/host_components/TEST_CLIENT</div><div class="line"> </div><div class="line">&#123;</div><div class="line">  &quot;RequestInfo&quot;: &#123;</div><div class="line">    &quot;context&quot;:&quot;Install Test Srv Client&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;Body&quot;: &#123;</div><div class="line">    &quot;HostRoles&quot;: &#123;</div><div class="line">      &quot;state&quot;:&quot;INSTALLED&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>6、使用如下信息配置主机上的client。这将最终调用命令脚本中的configure()方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">POST</div><div class="line">/api/v1/clusters/MyCluster/requests</div><div class="line">  </div><div class="line">&#123;</div><div class="line">  &quot;RequestInfo&quot; : &#123;</div><div class="line">    &quot;command&quot; : &quot;CONFIGURE&quot;,</div><div class="line">    &quot;context&quot; : &quot;Config Test Srv Client&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;Requests/resource_filters&quot;: [&#123;</div><div class="line">    &quot;service_name&quot; : &quot;TESTSRV&quot;,</div><div class="line">    &quot;component_name&quot; : &quot;TEST_CLIENT&quot;,</div><div class="line">    &quot;hosts&quot; : &quot;c6403.ambari.apache.org&quot;</div><div class="line">  &#125;]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>7、如果你想看哪些主机完成了安装。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">GET</div><div class="line">/api/v1/clusters/MyCluster/components/TEST_CLIENT</div></pre></td></tr></table></figure></p>
<h3 id="Install-the-Service-via-Ambari-Web-“Add-Services”"><a href="#Install-the-Service-via-Ambari-Web-“Add-Services”" class="headerlink" title="Install the Service(via Ambari Web “Add Services”)"></a>Install the Service(via Ambari Web “Add Services”)</h3><blockquote>
<p>1、在Ambari Web界面，跳转到Services并点击左侧Service导航区的Actions按钮。<br>2、点击“Add Services”。你将看到一个“My Test Service”的选项（在service的metainfo.xml文件中services的<displayname>中定义）。<br>3、选择“My Test Service”并点击下一步。<br>4、选择主机来安装“New Test Client”并点击下一步。<br>5、一旦完成，“My Test Service”将在Service导航区中可用。<br>6、如果你想要在其他主机上添加“New Test Client”，你可以跳转到Hosts，并指定主机后点击“+ Add”。</displayname></p>
</blockquote>
<h2 id="Example-Implementing-a-Custom-Client-only-Service-with-Configs"><a href="#Example-Implementing-a-Custom-Client-only-Service-with-Configs" class="headerlink" title="Example: Implementing a Custom Client-only Service (with Configs)"></a>Example: Implementing a Custom Client-only Service (with Configs)</h2><p>在这个例子中，我们将创建一个名为“TESTCONFIGSRV”的自定义service，并将其添加到已有的Stack定义上。这个service是一个CLIENT类型，因此它有两个命令：install和configure。service还包含”test-confg”配置类型。</p>
<h3 id="Create-and-Add-the-Service-to-Stack"><a href="#Create-and-Add-the-Service-to-Stack" class="headerlink" title="Create and Add the Service to Stack"></a>Create and Add the Service to Stack</h3><p>1、在Ambari Server上，跳转到/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services目录。在这个例子中，我们将跳转到HDP 2.0 Stack定义。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services</div></pre></td></tr></table></figure></p>
<p>2、创建名为/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV的目录，它包含了为TESTCONFIGSRV定义的service。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV</div></pre></td></tr></table></figure></p>
<p>3、跳转到刚刚创建的TESTCONFIGSRV目录，创建一个metainfo.xml文件，这个文件描述了这个新的service。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;metainfo&gt;</div><div class="line">    &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt;</div><div class="line">    &lt;services&gt;</div><div class="line">        &lt;service&gt;</div><div class="line">            &lt;name&gt;TESTCONFIGSRV&lt;/name&gt;</div><div class="line">            &lt;displayName&gt;New Test Config Service&lt;/displayName&gt;</div><div class="line">            &lt;comment&gt;A New Test Config Service&lt;/comment&gt;</div><div class="line">            &lt;version&gt;0.1.0&lt;/version&gt;</div><div class="line">            &lt;components&gt;</div><div class="line">                &lt;component&gt;</div><div class="line">                    &lt;name&gt;TESTCONFIG_CLIENT&lt;/name&gt;</div><div class="line">                    &lt;displayName&gt;New Test Config Client&lt;/displayName&gt;</div><div class="line">                    &lt;category&gt;CLIENT&lt;/category&gt;</div><div class="line">                    &lt;cardinality&gt;1+&lt;/cardinality&gt;</div><div class="line">                    &lt;commandScript&gt;</div><div class="line">                        &lt;script&gt;scripts/test_client.py&lt;/script&gt;</div><div class="line">                        &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line">                        &lt;timeout&gt;600&lt;/timeout&gt;</div><div class="line">                    &lt;/commandScript&gt;</div><div class="line">                &lt;/component&gt;</div><div class="line">            &lt;/components&gt;</div><div class="line">            &lt;osSpecifics&gt;</div><div class="line">                &lt;osSpecific&gt;</div><div class="line">                    &lt;osFamily&gt;any&lt;/osFamily&gt;  &lt;!-- note: use osType rather than osFamily for Ambari 1.5.0 and 1.5.1 --&gt;</div><div class="line">                &lt;/osSpecific&gt;</div><div class="line">            &lt;/osSpecifics&gt;</div><div class="line">        &lt;/service&gt;</div><div class="line">    &lt;/services&gt;</div><div class="line">&lt;/metainfo&gt;</div></pre></td></tr></table></figure></p>
<p>4、在上面，我的service的名为“TESTCONFIGSRV”，并且它包含一个名为“TESTCONFIG_CLIENT”组件，这个组件的类型为“CLINT”。这个client通过命令脚本scripts/test_client.py来管理。接下来创建这个命令脚本。<br>5、为命令脚本创建目录/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/package/scripts，这个脚本在ervice metainfo <commandscript>中指定。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/package/scripts</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/package/scripts</div></pre></td></tr></table></figure></commandscript></p>
<p>6、调转到scripts目录，并创建test_client.py文件。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import sys</div><div class="line">from resource_management import *</div><div class="line"> </div><div class="line">class TestClient(Script):</div><div class="line">  def install(self, env):</div><div class="line">    print &apos;Install the config client&apos;;</div><div class="line">  def configure(self, env):</div><div class="line">    print &apos;Configure the config client&apos;;</div><div class="line"> </div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">  TestClient().execute()</div></pre></td></tr></table></figure></p>
<p>7、现在，为这个service定义配置类型。为配置目录/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/configuration创建一个目录。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/configuration</div><div class="line">cd /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/TESTCONFIGSRV/configuration</div></pre></td></tr></table></figure></p>
<p>8、跳转到配置目录，并创建test-config.xml文件。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</div><div class="line"> </div><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;some.test.property&lt;/name&gt;</div><div class="line">    &lt;value&gt;this.is.the.default.value&lt;/value&gt;</div><div class="line">    &lt;description&gt;This is a kool description.&lt;/description&gt;</div><div class="line"> &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<p>9、现在，重启Ambari Server以便将service分发到集群中的所有Agent上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ambari-server restart</div></pre></td></tr></table></figure></p>
<h1 id="How-To-Define-Stacks-and-Services"><a href="#How-To-Define-Stacks-and-Services" class="headerlink" title="How-To Define  Stacks and Services"></a>How-To Define  Stacks and Services</h1><p>Ambari管理的Services在Ambari的stacks文件夹中定义。<br>要定义自己的services和stacks并被Ambari管理，请遵循如下步骤。<br>上面的create your custom stack and service的例子也可以学习。<br>stack是services的集合。一个stack可以定义多个版本，每个版本有自己的一组service。Ambari中的Stacks在 ambari-server/src/main/resources/stacks 文件夹中定义，这个文件夹可以在安装之后的/var/lib/ambari-server/resources/stacks目录找到。<br>被stack管理的servces能够在 ambari-server/src/main/resources/common-services 或 ambari-server/src/main/resources/stacks 文件夹中定义。这些文件对应安装后的目录分别为：/var/lib/ambari-server/resources/common-services 或  /var/lib/ambari-server/resources/stacks。</p>
<blockquote>
<p>Question : 什么时候在 common-services 或 stacks 文件夹中定义service呢<br>当service可能被用于多个stacks时，我们将在common-services文件夹中定义service。例如，几乎所有的stacks都需要HDFS service，因此将它定义在common-services而不是在每个stack中定义是值得推荐的。同样，如果一个service从不会被共享，它能够被定义在stack文件夹中。基本上来说stacks文件夹中定义services是不推荐的，而推荐将service定义在common-services中。</p>
</blockquote>
<h2 id="Define-Service"><a href="#Define-Service" class="headerlink" title="Define Service"></a>Define Service</h2><p>下面展示了如何在common-services文件夹中定义一个service。在stacks文件夹中定义services时，也可以使用相同的方法，具体会在定义stack章节介绍。</p>
<p><img src="http://oaavtz33a.bkt.clouddn.com/Screen%20Shot%202016-03-01%20at%202.47.32%20PM.png"></p>
<p>Services必须提供主要的metainfo.xml文件，它提供了关于这个service的重要元数据。<br>除此之外，其他文件提供了关于server的更多信息。关于这些文件的更多信息将在下面提供。</p>
<p>一个service也可能继承自它的之前版本或common services。关于继承的更多信息，请查看<a href="https://cwiki.apache.org/confluence/display/AMBARI/Service+Inheritance" title="Service Inheritance" target="_blank" rel="external">Service Inheritance</a>。</p>
<h2 id="metainfo-xml"><a href="#metainfo-xml" class="headerlink" title="metainfo.xml"></a>metainfo.xml</h2><p>在metainfo.xml服务描述符中，首先被定义的是service和它的components。<br>完整的参考文献可以在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Writing+metainfo.xml" title="Writing metainfo.xml" target="_blank" rel="external">Writing metainfo.xml</a>中找到。<br>值得推荐的metainfo.xml实现是<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L27" title="HDFS metainfo.xml" target="_blank" rel="external">HDFS metainfo.xml</a>。</p>
<blockquote>
<p>Question : 是否可以在同一个metainfo.xml中定义多个services？<br>可以。尽管可以，但是强烈拒绝在相同的service文件夹中定义多个services。<br>YARN和MapReduces2就被一起定义在YARN文件夹中。它的metainfo.xml同时定义了两个services。</p>
</blockquote>
<h3 id="Scripts"><a href="#Scripts" class="headerlink" title="Scripts"></a>Scripts</h3><p>对于components的定义，我们需要提供脚本来处理service的不同阶段以及组件的生命周期。<br>管理service和components的脚本在metainfo.xml(<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L35" title="HDFS" target="_blank" rel="external">HDFS</a>)中指定。<br>每个脚本应该继承<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-common/src/main/python/resource_management/libraries/script/script.py" title="Script" target="_blank" rel="external">Script</a>类，这个父类提供了有用的方法。例如：<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L68" title="NameNode script" target="_blank" rel="external">NameNode script</a>。</p>
<p><img src="http://oaavtz33a.bkt.clouddn.com/Screen%20Shot%202016-03-02%20at%2012.39.49%20PM.png"><br>这些脚本应该在<service-id>/<service-version>/package/script文件夹中提供。<br><img src="http://oaavtz33a.bkt.clouddn.com/Screen%20Shot%202016-03-02%20at%2012.32.58%20PM.png"></service-version></service-id></p>
<table>
<thead>
<tr>
<th style="text-align:left">Folder</th>
<th style="text-align:left">Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">package/script</td>
<td style="text-align:left">包含了由Ambari执行的脚本。这些脚本使用正确的环境被加载到执行路径中。例如：<a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts" title="HDFS" target="_blank" rel="external">HDFS</a></td>
</tr>
<tr>
<td style="text-align:left">package/files</td>
<td style="text-align:left">包含被上面脚本使用的文件。一般是其他一些作为独立进程执行的脚本（bash、python等）。例如：checkWebUI.py在HDFS检查中运行，用来确定Journal Node是否活跃。</td>
</tr>
<tr>
<td style="text-align:left">package/tmplates</td>
<td style="text-align:left">上述脚本在管理节点上生成的临时文件。一般是service需要操作的配置文件。例如：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/templates/exclude_hosts_list.j2" title="exclude_hosts_list.j2" target="_blank" rel="external">exclude_hosts_list.j2</a> ，被脚本使用来产生/etc/hadoop/conf/dfs.exclude。</td>
</tr>
</tbody>
</table>
<h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>Ambari默认支持python脚本来管理service和components。<br>component脚本应该继承resource_management.Script类并提供component的生命周期所需的方法。<br>参考<a href="https://cwiki.apache.org/confluence/display/AMBARI/Defining+a+Custom+Stack+and+Services" title="how to create custom stack" target="_blank" rel="external">how to create custom stack</a>页面，MASTER、SLAVE和CLIENT组件贯穿生命周期所需的方法如下：<br>master.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> Script</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Master</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Stop the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Start the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Status of the Sample Srv Master'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Master'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  Master().execute()</div></pre></td></tr></table></figure></p>
<p>slave.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> Script</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Slave</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Stop the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Start the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Status of the Sample Srv Slave'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Slave'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  Slave().execute()</div></pre></td></tr></table></figure></p>
<p>client.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> Script</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SampleClient</span><span class="params">(Script)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Install the Sample Srv Client'</span>;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Configure the Sample Srv Client'</span>;</div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  SampleClient().execute()</div></pre></td></tr></table></figure></p>
<p>Ambari提供了有用的Python库，以便在以下方面提供写servier脚本的帮助。对于这些库的完整介绍，请通过<a href="https://cwiki.apache.org/confluence/display/AMBARI/Ambari+Python+Libraries" title="Ambari Python Libraries" target="_blank" rel="external">Ambari Python Libraries</a>页面访问。</p>
<blockquote>
<p>resource_management<br>ambari_commons<br>ambari_simplejson</p>
</blockquote>
<h4 id="OS-Variant-Script"><a href="#OS-Variant-Script" class="headerlink" title="OS Variant Script"></a>OS Variant Script</h4><p>如果service支持多个操作系统，则需要根据不同的操作系统由独立的脚本，可以继承resource_management.Script类并使用不同的@OSFamilyImpl()注解。<br>这能够区分组件的不同操作系统的方法。<br>例如： <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L126" title="NameNode default script" target="_blank" rel="external">NameNode default script</a>， <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L346" title="NameNode Windows script" target="_blank" rel="external">NameNode Windows script</a></p>
<blockquote>
<p>Examples<br>NameNode <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_namenode.py#L93" title="start" target="_blank" rel="external">Start</a>， <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_namenode.py#L208" title="Stop" target="_blank" rel="external">Stop</a><br>DataNode <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_datanode.py#L68" title="
Start and Stop" target="_blank" rel="external">Start and Stop</a><br>HDFS <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs.py#L31" title="configurations persistence" target="_blank" rel="external">configurations persistence</a></p>
</blockquote>
<h3 id="Custom-Actions"><a href="#Custom-Actions" class="headerlink" title="Custom Actions"></a>Custom Actions</h3><p>有些时候，services需要执行一些行为，这些行为不同于Ambari提供的默认行为（install、start、stop、configure等）。<br>services能够定义一些action，并将这些action在UI中展示给用户，因此这些行为能够方便执行。<br>举例说明，如HDFS实现的Rebalance HDFS自定义行为。</p>
<h4 id="Stack-Changes"><a href="#Stack-Changes" class="headerlink" title="Stack Changes"></a>Stack Changes</h4><blockquote>
<p>1、在metainfo.xml中component的<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L49" title="Define custom command insid the customCommands section" target="_blank" rel="external"><customcommands>部分中定义指定义命令</customcommands></a>。<br>2、在metainfo.xml相关的脚本中，用相同的名字实现方法，来作为自定义命令。<br>    a）如果自定义命令不含有操作系统变量，它可以在同一个继承resource_management.Script的类中被实现。<br>    b）如果含有操作系统变量，每个类中的不同方法可以通过@OsFamilyImpl(os_family=…)来实现。<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L273" title="Default rebalancehdfs" target="_blank" rel="external">Default rebalancehdfs</a>, <a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L354" title="Windows rebalancehdfs" target="_blank" rel="external">Windows rebalancehdfs</a>。<br>这将提供在安装了service的被管理的主机上以后端方式运行脚本的能力。</p>
</blockquote>
<h4 id="UI-Changes"><a href="#UI-Changes" class="headerlink" title="UI Changes"></a>UI Changes</h4><p>在host页面上查看自定义action不需要修改UI。<br>action将展示在主机组件的action列表中。任何master-component action将自动展示在service的action菜单上。<br>当action被点击后，将自动产生POST调用来触发上面定义的脚本。</p>
<blockquote>
<p>Question ： 如何为UI中的自定义action提供自己的标签和图标？<br>在Ambari UI中，使用自定义图标和名称，添加你的component action到App.HostComponentActionMap对象。</p>
</blockquote>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p>service的配置文件应当位于默认的configuration文件夹中。<br>如果使用了不同的文件夹，metainfo.xml中的<configuration-dir>，可以用来指明使用的文件夹。<br>metainfo.xml中需要考虑配置的重要部分是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</div><div class="line">&lt;metainfo&gt;</div><div class="line">  &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt;</div><div class="line">  &lt;services&gt;</div><div class="line">    &lt;service&gt;</div><div class="line">      &lt;name&gt;HDFS&lt;/name&gt;</div><div class="line">      &lt;displayName&gt;HDFS&lt;/displayName&gt;</div><div class="line">      &lt;comment&gt;Apache Hadoop Distributed File System&lt;/comment&gt;</div><div class="line">      &lt;version&gt;2.1.0.2.0&lt;/version&gt;</div><div class="line">      &lt;components&gt;</div><div class="line">        ...</div><div class="line">        &lt;component&gt;</div><div class="line">          &lt;name&gt;HDFS_CLIENT&lt;/name&gt;</div><div class="line">          ...</div><div class="line">          &lt;configFiles&gt;</div><div class="line">            &lt;configFile&gt;</div><div class="line">              &lt;type&gt;xml&lt;/type&gt;</div><div class="line">              &lt;fileName&gt;hdfs-site.xml&lt;/fileName&gt;</div><div class="line">              &lt;dictionaryName&gt;hdfs-site&lt;/dictionaryName&gt;</div><div class="line">            &lt;/configFile&gt;</div><div class="line">            &lt;configFile&gt;</div><div class="line">              &lt;type&gt;xml&lt;/type&gt;</div><div class="line">              &lt;fileName&gt;core-site.xml&lt;/fileName&gt;</div><div class="line">              &lt;dictionaryName&gt;core-site&lt;/dictionaryName&gt;</div><div class="line">            &lt;/configFile&gt;</div><div class="line">            &lt;configFile&gt;</div><div class="line">              &lt;type&gt;env&lt;/type&gt;</div><div class="line">              &lt;fileName&gt;log4j.properties&lt;/fileName&gt;</div><div class="line">              &lt;dictionaryName&gt;hdfs-log4j,yarn-log4j&lt;/dictionaryName&gt;</div><div class="line">            &lt;/configFile&gt;                         </div><div class="line">            &lt;configFile&gt;</div><div class="line">              &lt;type&gt;env&lt;/type&gt;</div><div class="line">              &lt;fileName&gt;hadoop-env.sh&lt;/fileName&gt;</div><div class="line">              &lt;dictionaryName&gt;hadoop-env&lt;/dictionaryName&gt;</div><div class="line">            &lt;/configFile&gt;</div><div class="line">          &lt;/configFiles&gt;</div><div class="line">          ...</div><div class="line">          &lt;configuration-dependencies&gt;</div><div class="line">             &lt;config-type&gt;core-site&lt;/config-type&gt;</div><div class="line">             &lt;config-type&gt;hdfs-site&lt;/config-type&gt;</div><div class="line">          &lt;/configuration-dependencies&gt;</div><div class="line">        &lt;/component&gt;</div><div class="line">          ...</div><div class="line">      &lt;/components&gt;</div><div class="line">  </div><div class="line">      &lt;configuration-dir&gt;configuration&lt;/configuration-dir&gt;</div><div class="line">      &lt;configuration-dependencies&gt;</div><div class="line">        &lt;config-type&gt;core-site&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;hdfs-site&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;hadoop-env&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;hadoop-policy&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;hdfs-log4j&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ranger-hdfs-plugin-properties&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ssl-client&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ssl-server&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ranger-hdfs-audit&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ranger-hdfs-policymgr-ssl&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ranger-hdfs-security&lt;/config-type&gt;</div><div class="line">        &lt;config-type&gt;ams-ssl-client&lt;/config-type&gt;</div><div class="line">      &lt;/configuration-dependencies&gt;</div><div class="line">    &lt;/service&gt;</div><div class="line">  &lt;/services&gt;</div><div class="line">&lt;/metainfo&gt;</div></pre></td></tr></table></figure></configuration-dir></p>
<blockquote>
<p>config-type - 字符串表示的一组配置。例如：core-site, hdfs-site, yarn-site等。当配置在Ambari中保存，它们被固化到一个config-type版本中，而且这个版本是不可变的。如果你更改并保存HDFS core-site配置4次，你将有4个版本的config-type core-site。同样，当一个service的配置被保存时，只有更改的config-type被更新。<br>configFiles - 列出由<component>处理的配置文件。<br>configFile - 某种类型的一个配置文件。<br>    type - 基于文件内容的不同指定文件的类型<br>        xml - Hadoop中友好的方式，XML文件。<br>        env - 通常用于将内容值作为模版的脚本。模版具有配置标签，并且它的值在运行时生成。<br>        properties - 生成属性文件，每条属性的格式为key=value。<br>    dictionaryName - 配置类型的名字。<br>configuration-dependencies - 列出component或service所依赖的config-type的列表。<br>configuration-dir - configFiles所指定的文件所处的目录。可选的，默认为configuration。</component></p>
</blockquote>
<h3 id="Adding-new-configs-in-a-config-type"><a href="#Adding-new-configs-in-a-config-type" class="headerlink" title="Adding new configs in a config-type"></a>Adding new configs in a config-type</h3><p>向config-type中添加一个配置项时有很多不同的参数可选。它们在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Configuration+support+in+Ambari" title="config-type的可选属性" target="_blank" rel="external">这里</a>被全面介绍。</p>
<h3 id="UI-Categories"><a href="#UI-Categories" class="headerlink" title="UI - Categories"></a>UI - Categories</h3><p>上面的定义的配置在service的配置页面显示。<br>要自定义分类并在UI中对配置进行排序，需要更新下面的文件。<br>Create Category - 更新 ambari-web/app/models/stack_service.js 文件，用来添加自己的service，以及你的新分类。<br>Use Category - 要将配置置于某种分类中，并指定配置的顺序，将配置添加到  ambari-web/app/data/HDP2/site_properties.js 文件中。在这个文件中，可以指定需要使用到分类，以及配置的索引。ambari-web/app/data中的stack文件夹时分层的且继承自前一个版本。片段中的配置属性在这里定义。例如 <a href="https://github.com/apache/ambari/blob/trunk/ambari-web/app/data/HDP2.2/hive_properties.js" title="Hive Categories" target="_blank" rel="external">Hive Categories</a>, <a href="https://github.com/apache/ambari/blob/trunk/ambari-web/app/data/HDP2.2/tez_properties.js" title="Tez Categories" target="_blank" rel="external">Tez Categories</a></p>
<h3 id="UI-Enhanced-Configs"><a href="#UI-Enhanced-Configs" class="headerlink" title="UI - Enhanced Configs"></a>UI - Enhanced Configs</h3><p>Enhanced Config特性使得服务提供者能够定制他们自己的service配置，并确定哪些配置主要显示给用户，而不需要修改任何UI代码。自定义包括为service提供友好的布局，更好的控制（sliders, combos, lists, toggles, spinners, etc）、更好的验证（minimum, maximum, enums）、自动的单位转换（MB, GB, seconds, milliseconds, etc.）、配置依赖以及默认值的动态推荐。<br>servier提供者能够达成上面所有的，只需要在stacks文件夹中修改它们service的定义。<br>在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Enhanced+Configs" title="Enhanced Configs" target="_blank" rel="external">Enhanced Configs</a>页面中查看更多。</p>
<h2 id="Alerts"><a href="#Alerts" class="headerlink" title="Alerts"></a>Alerts</h2><p>通过提供一个alert.js文件，每个service都能够定义Ambari应该跟踪的警报。<br>在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Alerts" title="Alerts wiki page" target="_blank" rel="external">Alerts wiki page</a>页面能够读到更多关于报警框架的信息，而alerts.json文件的格式在<a href="https://github.com/apache/ambari/blob/branch-2.1/ambari-server/docs/api/v1/alert-definitions.md" title="Alerts definition document" target="_blank" rel="external">Alerts definition document</a>中可以了解到。</p>
<h2 id="Kerberos"><a href="#Kerberos" class="headerlink" title="Kerberos"></a>Kerberos</h2><p>Ambari能够对一个集群启用或禁用Kerberos。要通知Ambari服务及其组件使用的身份和配置，每个服务需要提供一个kerberos.json文件。<br>在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Automated+Kerberizaton" title="Automated Kerberization" target="_blank" rel="external">Automated Kerberization</a>wiki页面可以读到关于Kerberos的支持的信息，还可以在<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/docs/security/kerberos/kerberos_descriptor.md" title="Kerberos Descriptor documentation" target="_blank" rel="external">Kerberos Descriptor documentation</a>中得到Kerberos的描述信息。</p>
<h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><p>对于Hadoop和Ambari管理的集群，Ambari提供了<a href="https://cwiki.apache.org/confluence/display/AMBARI/Metrics" title="Ambari Metrics System" target="_blank" rel="external">Ambari Metrics System</a>服务，用来收集、聚合系统的metrics。<br>每个service可以定义哪些metrics能够被AMS收集，通过metrics.json文件来定义。你可以在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Stack+Defined+Metrics" title="Stack Defined Metrics" target="_blank" rel="external">Stack Defined Metrics</a>页面中得到关于metrics.json格式的信息。</p>
<h2 id="Quick-Links"><a href="#Quick-Links" class="headerlink" title="Quick Links"></a>Quick Links</h2><p>一个service通过向一个文本添加metainfo来实现向Ambari web UI中添加一个快速链接的列表，添加数据的文本遵循一个预定义JSON格式。Ambari server解析quicklink JSON文件，并将它的内容展示在UI。因此，Ambari web UI能够根据这些信息计算quick link URLs，并相应的填充quicklink的下拉列表。<br>关于quick link的JSON文件的设计，可以参看<a href="https://cwiki.apache.org/confluence/display/AMBARI/Quick+Links" title="Quick Links" target="_blank" rel="external">Quick Links</a>页面。</p>
<h2 id="Widgets"><a href="#Widgets" class="headerlink" title="Widgets"></a>Widgets</h2><p>每个service都可以通过定一个widgets.json文件来定义在service的摘要页面上默认显示哪些widgets和heatmaps。<br>你可以在<a href="https://cwiki.apache.org/confluence/display/AMBARI/Enhanced+Service+Dashboard" title="Enhanced Service Dashboard" target="_blank" rel="external">Enhanced Service Dashboard</a>页面中看到更多关于widgets描述符的信息。</p>
<h2 id="Role-Command-Order"><a href="#Role-Command-Order" class="headerlink" title="Role Command Order"></a>Role Command Order</h2><p>从Ambari 2.2开始，每个service通过在service文件夹中包含一个role_rommand_order.json文件来定义自己的role command order。这个service应当只指定它的组件到其他组件之间的关系。换句话说，如果service只包含COMP_X，那么servier应当只列出与COMP_X相关的依赖。如果COMP_X启动，它依赖于NameNode的启动，当NameNode停止时，NameNode应该要等COMP_X先停止，下面的信息将被包含在role command order中：<br>Example service role_command_order.json<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&quot;COMP_X-START&quot;: [&quot;NAMENODE-START&quot;],</div><div class="line">&quot;NAMENODE-STOP&quot;: [&quot;COMP_X-STOP&quot;]</div></pre></td></tr></table></figure></p>
<p>service的role command order条目将会与stack中定义的role command order合并。例如，因为stack已经依赖NAMENODE_STOP，在上面的例子中，COMP_X-STOP将被添加到NAMENODE-STOP的依赖，此外，COMP_X-START对NAMENODE-START的依赖将作为一个新的依赖项被添加。<br>对于role command order的更多信息，可以查看<a href="https://cwiki.apache.org/confluence/display/AMBARI/How-To+Define+Stacks+and+Services#How-ToDefineStacksandServices-RoleCommandOrder" title="Role Command Order" target="_blank" rel="external">Role Command Order</a>章节。</p>
<h2 id="Service-Advisor"><a href="#Service-Advisor" class="headerlink" title="Service Advisor"></a>Service Advisor</h2><p>从Ambari 2.4开始，每个service可以选择定义自己的service advisor，而不是在stack advisor中定义它的配置和布局的细节。这专门用于哪些没有在stack中定义的自定义service。service能够在它的service文件夹中编写一个名为service-advisor.py的Python脚本来提供Service Advisor的能力。这个文件夹可以位于定义service的stack的services目录或者用来定义可继承service的common-services目录。例如：<a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services/HAWQ/2.0.0" title="common-services/HAWQ/2.0.0" target="_blank" rel="external">common-services/HAWQ/2.0.0</a>。<br>与Stack-advisor脚本不同，service-advisor脚本不会自动的继承父级service的service-advisor脚本。service-advisor脚本需要声明来继承它们父级service的service-advisor脚本。下面的代码向你展示了如何引用父级service的service-advisor.py。在这个例子中，它继承了位于resource/stacks中的顶级service-advisor.py。<br>Sample service-advisor.py file inheritance<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))</div><div class="line">STACKS_DIR = os.path.join(SCRIPT_DIR, <span class="string">'../../../stacks/'</span>)</div><div class="line">PARENT_FILE = os.path.join(STACKS_DIR, <span class="string">'service_advisor.py'</span>)</div><div class="line"> </div><div class="line"><span class="keyword">try</span>:</div><div class="line">  <span class="keyword">with</span> open(PARENT_FILE, <span class="string">'rb'</span>) <span class="keyword">as</span> fp:</div><div class="line">    service_advisor = imp.load_module(<span class="string">'service_advisor'</span>, fp, PARENT_FILE, (<span class="string">'.py'</span>, <span class="string">'rb'</span>, imp.PY_SOURCE))</div><div class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">  traceback.print_exc()</div><div class="line">  <span class="keyword">print</span> <span class="string">"Failed to load parent"</span></div><div class="line"> </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HAWQ200ServiceAdvisor</span><span class="params">(service_advisor.ServiceAdvisor)</span>:</span></div></pre></td></tr></table></figure></p>
<p>与stack advisors类似，service advisor在4个重要概念上提供了信息：</p>
<blockquote>
<p>1、推荐集群上service的布局。<br>2、推荐service配置。<br>3、验证集群上service的布局。<br>4、验证service配置。<br>通过提供的service-advisor.py文件，service能够动态控制上面的每一个。<br>对于service-advisor脚本来说主要接口是如何调用上面的每一项，以及给它们提供什么数据。</p>
</blockquote>
<p>Base service_advisor.py from resources/stacks<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ServiceAdvisor</span><span class="params">(DefaultStackAdvisor)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  Abstract class implemented by all service advisors.</div><div class="line">  """</div><div class="line"> </div><div class="line">  <span class="string">"""</span></div><div class="line">  If any components of the service should be colocated with other services,</div><div class="line">  this is where you should set up that layout.  Example:</div><div class="line"> </div><div class="line">    # colocate HAWQSEGMENT with DATANODE, if no hosts have been allocated for HAWQSEGMENT</div><div class="line">    hawqSegment = [component for component in serviceComponents if component["StackServiceComponents"]["component_name"] == "HAWQSEGMENT"][0]</div><div class="line">    if not self.isComponentHostsPopulated(hawqSegment):</div><div class="line">      for hostName in hostsComponentsMap.keys():</div><div class="line">        hostComponents = hostsComponentsMap[hostName]</div><div class="line">        if &#123;"name": "DATANODE"&#125; in hostComponents and &#123;"name": "HAWQSEGMENT"&#125; not in hostComponents:</div><div class="line">          hostsComponentsMap[hostName].append( &#123; "name": "HAWQSEGMENT" &#125; )</div><div class="line">        if &#123;"name": "DATANODE"&#125; not in hostComponents and &#123;"name": "HAWQSEGMENT"&#125; in hostComponents:</div><div class="line">          hostComponents.remove(&#123;"name": "HAWQSEGMENT"&#125;)</div><div class="line">  """</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">colocateService</span><span class="params">(self, hostsComponentsMap, serviceComponents)</span>:</span></div><div class="line">    <span class="keyword">pass</span></div><div class="line"> </div><div class="line">  <span class="string">"""</span></div><div class="line">  Any configuration recommendations for the service should be defined in this function.</div><div class="line">  This should be similar to any of the recommendXXXXConfigurations functions in the stack_advisor.py</div><div class="line">  such as recommendYARNConfigurations().</div><div class="line">  """</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getServiceConfigurationRecommendations</span><span class="params">(self, configurations, clusterSummary, services, hosts)</span>:</span></div><div class="line">    <span class="keyword">pass</span></div><div class="line"> </div><div class="line">  <span class="string">"""</span></div><div class="line">  Returns an array of Validation objects about issues with the hostnames to which components are assigned.</div><div class="line">  This should detect validation issues which are different than those the stack_advisor.py detects.</div><div class="line">  The default validations are in stack_advisor.py getComponentLayoutValidations function.</div><div class="line">  """</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getServiceComponentLayoutValidations</span><span class="params">(self, services, hosts)</span>:</span></div><div class="line">    <span class="keyword">return</span> []</div><div class="line"> </div><div class="line">  <span class="string">"""</span></div><div class="line">  Any configuration validations for the service should be defined in this function.</div><div class="line">  This should be similar to any of the validateXXXXConfigurations functions in the stack_advisor.py</div><div class="line">  such as validateHDFSConfigurations.</div><div class="line">  """</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getServiceConfigurationsValidationItems</span><span class="params">(self, configurations, recommendedDefaults, services, hosts)</span>:</span></div><div class="line">    <span class="keyword">return</span> []</div></pre></td></tr></table></figure></p>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><ul><br>    <li><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/service_advisor.py#L51" title="Service Advisor interface" target="_blank" rel="external">Service Advisor interface</a></li><br>    <li><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HAWQ/2.0.0/service_advisor.py" title="HAWQ 2.0.0 Service Advisor implementation" target="_blank" rel="external">HAWQ 2.0.0 Service Advisor implementation</a></li><br>    <li><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/PXF/3.0.0/service_advisor.py" title="PXF 3.0.0 Service Advisor implementation" target="_blank" rel="external">PXF 3.0.0 Service Advisor implementation</a></li><br></ul>

<h2 id="Service-Upgrade"><a href="#Service-Upgrade" class="headerlink" title="Service Upgrade"></a>Service Upgrade</h2><p>从Ambari开始，每个service能够在它的service definition中定义它自己的更新。这对哪些不再需要修改stack的upgrade-packs的自定义service，以便它们融合到集群的更新。</p>
<p>每个service能够定义upgrade-packs，upgrade-packs是一些XML文件，它们描述了某个service的更新进程已经这个更新包如何与所有的stack更新包相关联。这些upgrade-pack XML文件在service的upgrades/文件夹中的独立的子文件夹中，这些子文件夹指明了需要扩展的stack版本。测试代码中的一些例子。</p>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><ul><br>    <li><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/" title="Upgrades folder" target="_blank" rel="external">Upgrades folder</a></li><br>    <li><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml" title="Upgrade-pack XML" target="_blank" rel="external">Upgrade-pack XML</a></li><br></ul>

<p>service定义的每个upgrade-pack通过一个特定的stack版本，应当匹配service定义的文件名。例如，在测试代码中，HDP 2.2.0有一个名为upgrade_test_15388.xml的upgrade-pack。HDFS service定义了一个extension来扩展那个upgrade pack<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml" title="HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml" target="_blank" rel="external">HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml</a>。在这个例子中，upgrade-pack定义在HDP/2.0.5的stack中。这个upgrade-pack是HDP/2.2.0的一个扩展，因为他被定义在upgrade/HDP/2.2.0目录中。最终，扩展到upgrad-pack upgrade_test_15388.xml的service的名字与HDP/2.2.0/upgrades中的upgrade-pack的名字匹配。<br>对于service的文件格式与stack的有很大的相同。target、target-stack和type属性应该和stack的upgrade-pack的信息完全对应。service能够添加自己的前提检测。</p>
<p>General Attributes and Prerequisite Checks<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">upgrade</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">target</span>&gt;</span>2.4.*<span class="tag">&lt;/<span class="name">target</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">target-stack</span>&gt;</span>HDP-2.4.0<span class="tag">&lt;/<span class="name">target-stack</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">type</span>&gt;</span>ROLLING<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">prerequisite-checks</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">check</span>&gt;</span>org.apache.ambari.server.checks.FooCheck<span class="tag">&lt;/<span class="name">check</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">prerequisite-checks</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>upgrade-pack的<order>部分，由<group>标签组成，就像stack的upgrade-pack。关键的不同是如何定义这些<group>，使它们与stack的upgrade pack的<group>或其他service的upgrade pack的<group>相关联。在第一个例子中，我们引入了名为PRE_CLUSTER的<group>并为名为FOO的service新增了一个<execute-stage>。该项应该在基于<add-after-group-entry>标签的HDFS之后的<execute-stage>中添加。</execute-stage></add-after-group-entry></execute-stage></group></group></group></group></group></order></p>
<p>Order Section - Add After Group Entry<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">order</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">group</span> <span class="attr">xsi:type</span>=<span class="string">"cluster"</span> <span class="attr">name</span>=<span class="string">"PRE_CLUSTER"</span> <span class="attr">title</span>=<span class="string">"Pre &#123;&#123;direction.text.proper&#125;&#125;"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">add-after-group-entry</span>&gt;</span>HDFS<span class="tag">&lt;/<span class="name">add-after-group-entry</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">execute-stage</span> <span class="attr">service</span>=<span class="string">"FOO"</span> <span class="attr">component</span>=<span class="string">"BAR"</span> <span class="attr">title</span>=<span class="string">"Backup FOO"</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">task</span> <span class="attr">xsi:type</span>=<span class="string">"manual"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">message</span>&gt;</span>Back FOO up.<span class="tag">&lt;/<span class="name">message</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">task</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">execute-stage</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">group</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>同样的语法也可以被用于service检查优先级和group services等。</p>
<p>Order Section - Further Add After Group Entry Examples<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">group</span> <span class="attr">name</span>=<span class="string">"SERVICE_CHECK1"</span> <span class="attr">title</span>=<span class="string">"All Service Checks"</span> <span class="attr">xsi:type</span>=<span class="string">"service-check"</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">add-after-group-entry</span>&gt;</span>ZOOKEEPER<span class="tag">&lt;/<span class="name">add-after-group-entry</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">priority</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">service</span>&gt;</span>HBASE<span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">priority</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">group</span>&gt;</span></div><div class="line"> </div><div class="line"><span class="tag">&lt;<span class="name">group</span> <span class="attr">name</span>=<span class="string">"CORE_MASTER"</span> <span class="attr">title</span>=<span class="string">"Core Masters"</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">add-after-group-entry</span>&gt;</span>YARN<span class="tag">&lt;/<span class="name">add-after-group-entry</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">service</span> <span class="attr">name</span>=<span class="string">"HBASE"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">component</span>&gt;</span>HBASE_MASTER<span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">group</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>还可以在stack的upgrade-pack中增加新的group，并将它们排列在其他group之后。在下面的例子中，我们在使用<add-after-group>标签的HIVE的group之后增加了一个名为FOO的group。</add-after-group></p>
<p>Order Section - Add After Group<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">group</span> <span class="attr">name</span>=<span class="string">"FOO"</span> <span class="attr">title</span>=<span class="string">"Foo"</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">add-after-group</span>&gt;</span>HIVE<span class="tag">&lt;/<span class="name">add-after-group</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">skippable</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skippable</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">allow-retry</span>&gt;</span>false<span class="tag">&lt;/<span class="name">allow-retry</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">service</span> <span class="attr">name</span>=<span class="string">"FOO"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">component</span>&gt;</span>BAR<span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">group</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>你还可以在同一个<group>中同时创建<add-after-group>和<add-after-groujp-entry>。这将会在指定的group不存在的情况下才会创建一个新的group，并且会将他排列在<add-after-group>指定的group之后。<add-after-group-entry>将会确定它的group的service的内部排序、优先级和执行阶段。</add-after-group-entry></add-after-group></add-after-groujp-entry></add-after-group></group></p>
<p>Order Section - Add After Group<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">group</span> <span class="attr">name</span>=<span class="string">"FOO"</span> <span class="attr">title</span>=<span class="string">"Foo"</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">add-after-group</span>&gt;</span>HIVE<span class="tag">&lt;/<span class="name">add-after-group</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">add-after-group-entry</span>&gt;</span>FOO<span class="tag">&lt;/<span class="name">add-after-group-entry</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">skippable</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skippable</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">allow-retry</span>&gt;</span>false<span class="tag">&lt;/<span class="name">allow-retry</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">service</span> <span class="attr">name</span>=<span class="string">"FOO2"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">component</span>&gt;</span>BAR2<span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">group</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>upgrade-pack剩余的<processing>部分，与stack的upgrade-pack的相同。</processing></p>
<p>Processing Section<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">processing</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">service</span> <span class="attr">name</span>=<span class="string">"FOO"</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">component</span> <span class="attr">name</span>=<span class="string">"BAR"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">upgrade</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">task</span> <span class="attr">xsi:type</span>=<span class="string">"restart-task"</span> /&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">upgrade</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">component</span> <span class="attr">name</span>=<span class="string">"BAR2"</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">upgrade</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">task</span> <span class="attr">xsi:type</span>=<span class="string">"restart-task"</span> /&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">upgrade</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">processing</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h1 id="Define-Stack"><a href="#Define-Stack" class="headerlink" title="Define Stack"></a>Define Stack</h1><p>一个Stack就是一个版本化的service的集合。每个stack就是一个定义在ambari-server/src/main/resource/stacks中的一个文件夹。安装ambari之后，stack的定义则位于ambari-server主机的/var/lib/ambari-server/resources/stacks中。<br>每个stack文件夹中包含该stack的每个版本的子文件夹。一些stack版本可用，一些不可用。每个stack版本包含一些service，这些service有的继承自common-services，有些在stack版本的services中定义。<br><img src="http://oaavtz33a.bkt.clouddn.com/Screen%20Shot%202016-03-08%20at%2012.46.40%20PM.png"><br>Example : <a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.4" title="HDP stack.HDP-2.4 stack version" target="_blank" rel="external">HDP stack.HDP-2.4 stack version</a>。</p>
<h2 id="Stack-Version-Descriptor"><a href="#Stack-Version-Descriptor" class="headerlink" title="Stack-Version Descriptor"></a>Stack-Version Descriptor</h2><p>每个Stack-version应当提供一个metainfo.xml（如：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/metainfo.xml" title="HDP-2.3" target="_blank" rel="external">HDP-2.3</a>、<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.4/metainfo.xml" title="HDP-2.4" target="_blank" rel="external">HDP-2.4</a> ）文件作为描述符，它如下描述了stack-verion：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">metainfo</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">versions</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">active</span>&gt;</span>true<span class="tag">&lt;/<span class="name">active</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">versions</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">extends</span>&gt;</span>2.3<span class="tag">&lt;/<span class="name">extends</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">minJdk</span>&gt;</span>1.7<span class="tag">&lt;/<span class="name">minJdk</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">maxJdk</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">maxJdk</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metainfo</span>&gt;</span></div></pre></td></tr></table></figure></p>
<blockquote>
<p>versions/active - 当前版本的stack是否还可以用于安装。如果不可用，这个版本在安装的时候将不会在UI中显示。<br>extends - 当前stack继承的版本。进行继承的stack版本会继承service以及父stack版本的所有方面。<br>minJdk - stack版本支持的最低JDK版本。在安装向导期间如果被Ambari使用的JDK低于这个版本，用户将被警告。<br>maxJdk - stack版本支持的最高JDK版本。在安装向导期间，如果被Ambari使用的JDK版本高于这个版本，用户将被警告。</p>
</blockquote>
<h2 id="Stack-Properties"><a href="#Stack-Properties" class="headerlink" title="Stack Properties"></a>Stack Properties</h2><p>stack必须包含或继承一个属性字典，属性字典包含两个文件：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_features.json" title="stack_features.json" target="_blank" rel="external">stack_features.json</a>和<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_tools.json" title="stack_tools.json" target="_blank" rel="external">stack_tools.json</a>。这个字典是在Ambari 2.4中新增的。<br>stack_features.json中包含了一个features的列表，这个列表指定了哪些版本的stack包含这些特性。<br>特性列表由特定的Ambari版本所确定。特定Ambari版本的详细列表能够在HDP/2.0.6/properties/stack_features.json中找到。每个feature由name、description以及特性所支持stack的最高版本和最低版本来构成。<br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"stack_features"</span>: [</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"name"</span>: <span class="string">"snappy"</span>,</div><div class="line">      <span class="attr">"description"</span>: <span class="string">"Snappy compressor/decompressor support"</span>,</div><div class="line">      <span class="attr">"min_version"</span>: <span class="string">"2.0.0.0"</span>,</div><div class="line">      <span class="attr">"max_version"</span>: <span class="string">"2.2.0.0"</span></div><div class="line">    &#125;,</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>stack_tools.json包含了stack_selector和conf_selector这两个工具对应的名称以及安装位置。<br>任何自定义的stack必须包含这两个JSON文件。更多的信息请查看<a href="https://cwiki.apache.org/confluence/display/AMBARI/Stack+Properties" title="Stack Properties" target="_blank" rel="external">Stack Properties</a>的wiki页面。</p>
<h2 id="Services"><a href="#Services" class="headerlink" title="Services"></a>Services</h2><p>每个stack版本中都包含services，这些services要么是引用的common-services中的，要么是在stack版本中services文件夹下定义的。<br>common-services中定义的services能够被多个stack共享。如果他们不会被共享，那么他们可以定义在stack版本中。</p>
<h3 id="Reference-common-services"><a href="#Reference-common-services" class="headerlink" title="Reference common-services"></a>Reference common-services</h3><p>要引用common-services中的一个service，service描述文件需要使用<extends>项。（例如： <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/HDFS/metainfo.xml" title="DFS in HDP-2.0.6" target="_blank" rel="external">HDFS in HDP-2.0.6</a>）<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">metainfo</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">schemaVersion</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">schemaVersion</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">services</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">service</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>HDFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">extends</span>&gt;</span>common-services/HDFS/2.1.0.2.0<span class="tag">&lt;/<span class="name">extends</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">services</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metainfo</span>&gt;</span></div></pre></td></tr></table></figure></extends></p>
<h3 id="Define-Service-1"><a href="#Define-Service-1" class="headerlink" title="Define Service"></a>Define Service</h3><p>与common-services中定义的services格式相同，可以子啊services文件夹中定义新的service。<br>Examples：</p>
<ul><br>    <li><a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/BIGTOP/0.8/services/HDFS" title="HDFS in BIGTOP-0.8" target="_blank" rel="external">HDFS in BIGTOP-0.8</a></li><br>    <li><a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.3.GlusterFS/services/GLUSTERFS" title="GlusterFS in HDP-2.3.GlusterFS" target="_blank" rel="external">GlusterFs in HDP-2.3.CusterFs</a></li><br></ul>

<h3 id="Extend-Service"><a href="#Extend-Service" class="headerlink" title="Extend Service"></a>Extend Service</h3><p>当一个版本继承另外一个版本时，它继承父级service的所有细节。它也可以自由的重写或删除继承的service定义的任何部分。<br>Examples：</p>
<ul><br>    <li>HDP-2.3/HDFS - <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/HDFS/metainfo.xml" title="添加NFS_GATEWAY组件，更新service版本和OS特定包" target="_blank" rel="external">添加NFS_GATEWAY组件，更新service版本和OS特定包</a></li><br>    <li>HDP-2.2/Storm - <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.2/services/STORM/metainfo.xml" title="删除了STORM_REST_API组件，更新service版本和OS特定包" target="_blank" rel="external">删除了STORM_REST_API组件，更新service版本和OS特定包</a></li><br>    <li>HDP-2.3/YARN - <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/YARN/configuration/capacity-scheduler.xml" title="从capacity-scheduler.mxl中删除YARN node-lable配置" target="_blank" rel="external">从capacity-scheduler.mxl中删除YARN node-lable配置</a></li><br>    <li>HDP-2.3/Kafka - <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/KAFKA/alerts.json" title="增加Kafka Broker进程告警" target="_blank" rel="external">增加Kafka Broker进程告警</a></li><br></ul>

<h2 id="Role-Command-Order-1"><a href="#Role-Command-Order-1" class="headerlink" title="Role Command Order"></a>Role Command Order</h2><p>Role是Component（如：NAMENODE、DATANODE、RESOURCEMANAGER、HBASE_MASTER等）的另一个名称。<br>顾名思义，它可以告诉Amberi在你stack中定义的component执行命令的顺序。<br>例如：”ZooKeeper Server 应当在启动NameNode之前启动”。“HBase Master应当在NameNode和DataNode启动之后再启动”。<br>这可以通过在stack-version文件夹中包含<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/role_command_order.json" title="role_command_order.json" target="_blank" rel="external">role_command_order.json</a>来具体说明。</p>
<h3 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h3><p>以JSON格式指定，这个文件包含一个JSON对象，并且顶级key是section名称或comments。如：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/role_command_order.json" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a>。<br>在每个section对象内部，key描述了它对应的component的行为，value列出当前component-action之前应当完成的component-action。<br>Structure of role_command_order.json<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  "_comment": "Section 1 comment",</div><div class="line">  "section_name_1": &#123;</div><div class="line">    "_comment": "Section containing role command orders",</div><div class="line">    "&lt;DEPENDENT_COMPONENT_1&gt;-&lt;COMMAND&gt;": ["&lt;DEPENDS_ON_COMPONENT_1&gt;-&lt;COMMAND&gt;", "&lt;DEPENDS_ON_COMPONENT_1&gt;-&lt;COMMAND&gt;"],</div><div class="line">    "&lt;DEPENDENT_COMPONENT_2&gt;-&lt;COMMAND&gt;": ["&lt;DEPENDS_ON_COMPONENT_3&gt;-&lt;COMMAND&gt;"],</div><div class="line">    ...</div><div class="line">  &#125;,</div><div class="line">  "_comment": "Next section comment",</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="Sections"><a href="#Sections" class="headerlink" title="Sections"></a>Sections</h3><p>Ambari只使用了如下的sections：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Section Name</th>
<th style="text-align:left">When Used</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">general_deps</td>
<td style="text-align:left">适用于所有情况</td>
</tr>
<tr>
<td style="text-align:left">optional_glusterfs</td>
<td style="text-align:left">当集群有GLUSTERFS服务实例时</td>
</tr>
<tr>
<td style="text-align:left">optional_no_glusterfs</td>
<td style="text-align:left">当集群没有GLUSTERFS服务实例时</td>
</tr>
<tr>
<td style="text-align:left">namenode_optional_ha</td>
<td style="text-align:left">当安装了HDFS服务，且有JOURNALNODE组件时</td>
</tr>
<tr>
<td style="text-align:left">resourcemanager_optional_ha</td>
<td style="text-align:left">当安装了YARN服务，且存在多个RESOURCEMANAGER host-components存在时</td>
</tr>
</tbody>
</table>
<h3 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h3><p>Ambari当前支持的命令有：</p>
<blockquote>
<p>INSTALL<br>UNINSTALL<br>START<br>RESTART<br>STOP<br>EXECUTE<br>ABORT<br>UPGRADE<br>SERVICE_CHECK<br>CUSTOM_COMMAND<br>ACTIONEXECUTE</p>
</blockquote>
<h3 id="Examples-2"><a href="#Examples-2" class="headerlink" title="Examples"></a>Examples</h3><table>
<thead>
<tr>
<th style="text-align:left">Role Command Order</th>
<th style="text-align:left">Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">“HIVE_METASTORE-START”:[“MYSQL_SERVER-START”, “NAMENODE-START”]</td>
<td style="text-align:left">启动Hive Metastore之前先启动MySQL和NameNode。</td>
</tr>
<tr>
<td style="text-align:left">“MAPREDUCE_SERVICE_CHECK-SERVICE_CHECK”:[“NODEMANAGER-START”, “RESOURCEMANAGER-START”]</td>
<td style="text-align:left">MapReduce服务检查需要ResourceManager和NodeManager的启动。</td>
</tr>
<tr>
<td style="text-align:left">“ZOOKEEPER_SERVER-STOP”:[“HBASE_MASTER-STOP”, “HBASE_REGIONSERVER-STOP”, “METRICS_COLLECTOR-STOP”]</td>
<td style="text-align:left">在停止Zookeeper之前，应该先确保HBase Master、Hbase RegionServers和AMS Metrics收集器先停止。</td>
</tr>
</tbody>
</table>
<h2 id="Repositories"><a href="#Repositories" class="headerlink" title="Repositories"></a>Repositories</h2><p>通过提供一个repos/repoinfo.xml（如 <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/repos/repoinfo.xml" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a>），每个stack版本可以提供package的库的位置来使用。<br>repoinfo.xml文件中包含的库根据操作系统进行分组。每个os指定一个库列表，这些库列表会在stack版本安装时展示给用户。<br>这些库与<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L161" title="packages defined in a service&#39;s metainfo.xml" target="_blank" rel="external">packages defined in a service’s metainfo.xml</a>配合使用，以便在系统上安装正确的。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">reposinfo</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">os</span> <span class="attr">family</span>=<span class="string">"redhat6"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">repo</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">baseurl</span>&gt;</span>http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.0.6.1<span class="tag">&lt;/<span class="name">baseurl</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">repoid</span>&gt;</span>HDP-2.0.6<span class="tag">&lt;/<span class="name">repoid</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">reponame</span>&gt;</span>HDP<span class="tag">&lt;/<span class="name">reponame</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">repo</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">repo</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">baseurl</span>&gt;</span>http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6<span class="tag">&lt;/<span class="name">baseurl</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">repoid</span>&gt;</span>HDP-UTILS-1.1.0.17<span class="tag">&lt;/<span class="name">repoid</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">reponame</span>&gt;</span>HDP-UTILS<span class="tag">&lt;/<span class="name">reponame</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">repo</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">os</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">reposinfo</span>&gt;</span></div></pre></td></tr></table></figure></p>
<blockquote>
<p>baseurl - RPM库的URL，可以在这里找到repoid提供的软件。<br>repoid - baseurl地址使用的repo id。<br>reponame - 需要使用的repo的展示名。</p>
</blockquote>
<h3 id="Latest-Builds"><a href="#Latest-Builds" class="headerlink" title="Latest Builds"></a>Latest Builds</h3><p>尽管repository基本URL能够对某个特定repo提供更新，但是必须在构建时定义它。当repository变更位置或更新包位于不同网站时，这就会成为一个问题。<br>对于这样的情况，stack-version能够提供一个JSON文件，来提供要使用的其他repo URL。<br>例如： <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/repos/repoinfo.xml" title="HDP-2.3 repoinfo.xml uses &lt;latest&gt; file" target="_blank" rel="external">HDP-2.3 repoinfo.xml uses <latest> file</latest></a>，它指出最新的构建包的repository URL。</p>
<figure class="highlight plain"><figcaption><span>json</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    ...</div><div class="line">    &quot;HDP-2.3&quot;:&#123;</div><div class="line">        &quot;latest&quot;:&#123;</div><div class="line">            &quot;centos6&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;centos7&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos7/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;debian6&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/debian6/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;debian7&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/debian7/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;suse11&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/suse11sp3/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;ubuntu12&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/ubuntu12/2.x/BUILDS/2.3.6.0-3586/&quot;,</div><div class="line">            &quot;ubuntu14&quot;:&quot;http://s3.amazonaws.com/dev.hortonworks.com/HDP/ubuntu14/2.x/BUILDS/2.3.6.0-3586/&quot;</div><div class="line">        &#125;</div><div class="line">    &#125;,</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Hooks"><a href="#Hooks" class="headerlink" title="Hooks"></a>Hooks</h2><p>stack-version会有非常基本且通用的指令，这些指令需要在某个Ambari命令之前或之后运行。<br>避免将代码在service脚本之间复制并要求用户确认，通过将前置代码和后置代码放到hooks文件夹中，Ambari提供了Hooks的功能。（如：<a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a>）<br><img src=""></p>
<h3 id="Command-Sub-Folders"><a href="#Command-Sub-Folders" class="headerlink" title="Command Sub-Folders"></a>Command Sub-Folders</h3><p>hooks子文件夹的命名模式为”<before|after>-<any|<commandname>&gt;”。<br>那意味着子文件夹中的scripts/hook.py文件是在命令之前运行还是之后运行。<br>Examples：</any|<commandname></before|after></p>
<table>
<thead>
<tr>
<th style="text-align:left">Sub-Folder</th>
<th style="text-align:left">Purpose</th>
<th style="text-align:left">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">before-START</td>
<td style="text-align:left">hook脚本，会在stack-version的任何组件启动之前被调用</td>
<td style="text-align:left"><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks/before-START/scripts/hook.py#L30" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a> 1、设置hadoop的日志和pid目录。2、创建javahome的symlink。3、创建/etc/hadoop/conf/topology_script.py脚本</td>
</tr>
<tr>
<td style="text-align:left">before-INSTALL</td>
<td style="text-align:left">hook脚本，会在stack-version的任何组件安装之前被调用</td>
<td style="text-align:left"><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks/before-START/scripts/hook.py#L30" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a> 1、在/etc/yum.repos.d中创建repo文件。 2、安装基本包，如curl、unzip等</td>
</tr>
</tbody>
</table>
<p>Ambari当前支持的命令，根据需要可以创建如下的子文件夹</p>
<table>
<thead>
<tr>
<th style="text-align:left">Prefix</th>
<th style="text-align:left">Command</th>
<th style="text-align:left">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">before</td>
<td style="text-align:left">INSTALL</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">before</td>
<td style="text-align:left">UNINSTALL</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">before</td>
<td style="text-align:left">START</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">before</td>
<td style="text-align:left">RESTART</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">before</td>
<td style="text-align:left">STOP</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">after</td>
<td style="text-align:left">EXECUTE</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">after</td>
<td style="text-align:left">ABORT</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">after</td>
<td style="text-align:left">UPGRADE</td>
<td style="text-align:left">&nbsp;</td>
</tr>
<tr>
<td style="text-align:left">after</td>
<td style="text-align:left">SERVICE_CHECK</td>
<td style="text-align:left">&nbps;</td>
</tr>
<tr>
<td style="text-align:left">after</td>
<td style="text-align:left">&lt; custom_command&gt;</td>
<td style="text-align:left">用户指定的自定义命令，如HDFS指定的DECOMMISSION或REBALANCEHDFS这两个命令。</td>
</tr>
</tbody>
</table>
<p>script/hooks.py脚本应该导入<a href="https://github.com/apache/ambari/blob/trunk/ambari-common/src/main/python/resource_management/libraries/script/hook.py" title="resource_management.libraries.script.hook" target="_blank" rel="external">resource_management.libraries.script.hook</a>模块，并继承Hook类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> resource_management.libraries.script.hook <span class="keyword">import</span> Hook</div><div class="line"> </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomHook</span><span class="params">(Hook)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">hook</span><span class="params">(self, env)</span>:</span></div><div class="line">    <span class="comment"># Do custom work</span></div><div class="line">     </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">  CustomHook().execute()</div></pre></td></tr></table></figure></p>
<h2 id="Configurations"><a href="#Configurations" class="headerlink" title="Configurations"></a>Configurations</h2><p>尽管大多数配置是在service级别设置的，但是也可以有适用于所有servies的配置，以便指示安装了此stack的集群的状态。<br>例如，像<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration/cluster-env.xml#L25" target="_blank" rel="external">is security enabled?</a>，<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration/cluster-env.xml#L46" target="_blank" rel="external">what user runs smoke tests?</a> 等。<br>这样的配置可以定义在sstack的<a href="https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration" target="_blank" rel="external">configuration文件夹</a>中。它们就像service级配置一样访问。</p>
<h3 id="Stack-Advisor"><a href="#Stack-Advisor" class="headerlink" title="Stack Advisor"></a>Stack Advisor</h3><p>由于每个stack包含多个复杂的service，因此有必要动态确定services的布局以及确定某些配置的值。<br>stacks在services/目录中编写一个名为stack-advisor.py的Python脚本，使Ambari提供了Stack Advisor的能力。例如：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py" title="HDP-2.0.6" target="_blank" rel="external">HDP-2.0.6</a>。Stack advisor脚本能够自动继承父级stack版本的stack advisor脚本。这允许较新的stack版本能够改变行为而不会影响之前的版本的行为。<br>Stack advisor在4个重要概念上提供了信息：</p>
<blockquote>
<p>Recommend layout of services on cluster。<br>Recommend service configurations。<br>Validate layout of services on cluster。<br>Validate service configurations。</p>
</blockquote>
<p>通过提供stack-advisor.py文件，能够动态的控制上面的每一项。<br>stack-advisor脚本的主要接口描述了上面每项应当如何调用，以及提供什么数据。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StackAdvisor</span><span class="params">(object)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line">  Abstract class implemented by all stack advisors. Stack advisors advise on stack specific questions.</div><div class="line"> </div><div class="line"> </div><div class="line">  Currently stack advisors provide following abilities:</div><div class="line">  - Recommend where services should be installed in cluster</div><div class="line">  - Recommend configurations based on host hardware</div><div class="line">  - Validate user selection of where services are installed on cluster</div><div class="line">  - Validate user configuration values</div><div class="line"> </div><div class="line">  Each of the above methods is passed in parameters about services and hosts involved as described below.</div><div class="line"> </div><div class="line"> </div><div class="line">    @type services: dictionary</div><div class="line">    @param services: Dictionary containing all information about services selected by the user.</div><div class="line">      Example: &#123;</div><div class="line">      "services": [</div><div class="line">        &#123;</div><div class="line">          "StackServices": &#123;</div><div class="line">            "service_name" : "HDFS",</div><div class="line">            "service_version" : "2.6.0.2.2",</div><div class="line">          &#125;,</div><div class="line">          "components" : [</div><div class="line">            &#123;</div><div class="line">              "StackServiceComponents" : &#123;</div><div class="line">                "cardinality" : "1+",</div><div class="line">                "component_category" : "SLAVE",</div><div class="line">                "component_name" : "DATANODE",</div><div class="line">                "display_name" : "DataNode",</div><div class="line">                "service_name" : "HDFS",</div><div class="line">                "hostnames" : []</div><div class="line">              &#125;,</div><div class="line">              "dependencies" : []</div><div class="line">            &#125;, &#123;</div><div class="line">              "StackServiceComponents" : &#123;</div><div class="line">                "cardinality" : "1-2",</div><div class="line">                "component_category" : "MASTER",</div><div class="line">                "component_name" : "NAMENODE",</div><div class="line">                "display_name" : "NameNode",</div><div class="line">                "service_name" : "HDFS",</div><div class="line">                "hostnames" : []</div><div class="line">              &#125;,</div><div class="line">              "dependencies" : []</div><div class="line">            &#125;,</div><div class="line">            ...</div><div class="line">          ]</div><div class="line">        &#125;,</div><div class="line">        ...</div><div class="line">      ]</div><div class="line">    &#125;</div><div class="line">  @type hosts: dictionary</div><div class="line">  @param hosts: Dictionary containing all information about hosts in this cluster</div><div class="line">    Example: &#123;</div><div class="line">      "items": [</div><div class="line">        &#123;</div><div class="line">          Hosts: &#123;</div><div class="line">            "host_name": "c6401.ambari.apache.org",</div><div class="line">            "public_host_name" : "c6401.ambari.apache.org",</div><div class="line">            "ip": "192.168.1.101",</div><div class="line">            "cpu_count" : 1,</div><div class="line">            "disk_info" : [</div><div class="line">              &#123;</div><div class="line">              "available" : "4564632",</div><div class="line">              "used" : "5230344",</div><div class="line">              "percent" : "54%",</div><div class="line">              "size" : "10319160",</div><div class="line">              "type" : "ext4",</div><div class="line">              "mountpoint" : "/"</div><div class="line">              &#125;,</div><div class="line">              &#123;</div><div class="line">              "available" : "1832436",</div><div class="line">              "used" : "0",</div><div class="line">              "percent" : "0%",</div><div class="line">              "size" : "1832436",</div><div class="line">              "type" : "tmpfs",</div><div class="line">              "mountpoint" : "/dev/shm"</div><div class="line">              &#125;</div><div class="line">            ],</div><div class="line">            "host_state" : "HEALTHY",</div><div class="line">            "os_arch" : "x86_64",</div><div class="line">            "os_type" : "centos6",</div><div class="line">            "total_mem" : 3664872</div><div class="line">          &#125;</div><div class="line">        &#125;,</div><div class="line">        ...</div><div class="line">      ]</div><div class="line">    &#125;</div><div class="line"> </div><div class="line"> </div><div class="line">    Each of the methods can either return recommendations or validations.</div><div class="line"> </div><div class="line">    Recommendations are made in a Ambari Blueprints friendly format.</div><div class="line">    Validations are an array of validation objects.</div><div class="line">  """</div><div class="line"> </div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">recommendComponentLayout</span><span class="params">(self, services, hosts)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Returns recommendation of which hosts various service components should be installed on.</div><div class="line"> </div><div class="line">    This function takes as input all details about services being installed, and hosts</div><div class="line">    they are being installed into, to generate hostname assignments to various components</div><div class="line">    of each service.</div><div class="line"> </div><div class="line"> </div><div class="line">    @type services: dictionary</div><div class="line">    @param services: Dictionary containing all information about services selected by the user.</div><div class="line">    @type hosts: dictionary</div><div class="line">    @param hosts: Dictionary containing all information about hosts in this cluster</div><div class="line">    @rtype: dictionary</div><div class="line">    @return: Layout recommendation of service components on cluster hosts in Ambari Blueprints friendly format.</div><div class="line">        Example: &#123;</div><div class="line">          "resources" : [</div><div class="line">            &#123;</div><div class="line">              "hosts" : [</div><div class="line">                "c6402.ambari.apache.org",</div><div class="line">                "c6401.ambari.apache.org"</div><div class="line">              ],</div><div class="line">              "services" : [</div><div class="line">                "HDFS"</div><div class="line">              ],</div><div class="line">              "recommendations" : &#123;</div><div class="line">                "blueprint" : &#123;</div><div class="line">                  "host_groups" : [</div><div class="line">                    &#123;</div><div class="line">                      "name" : "host-group-2",</div><div class="line">                      "components" : [</div><div class="line">                        &#123; "name" : "JOURNALNODE" &#125;,</div><div class="line">                        &#123; "name" : "ZKFC" &#125;,</div><div class="line">                        &#123; "name" : "DATANODE" &#125;,</div><div class="line">                        &#123; "name" : "SECONDARY_NAMENODE" &#125;</div><div class="line">                      ]</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                      "name" : "host-group-1",</div><div class="line">                      "components" :</div><div class="line">                        &#123; "name" : "HDFS_CLIENT" &#125;,</div><div class="line">                        &#123; "name" : "NAMENODE" &#125;,</div><div class="line">                        &#123; "name" : "JOURNALNODE" &#125;,</div><div class="line">                        &#123; "name" : "ZKFC" &#125;,</div><div class="line">                        &#123; "name" : "DATANODE" &#125;</div><div class="line">                      ]</div><div class="line">                    &#125;</div><div class="line">                  ]</div><div class="line">                &#125;,</div><div class="line">                "blueprint_cluster_binding" : &#123;</div><div class="line">                  "host_groups" : [</div><div class="line">                    &#123;</div><div class="line">                      "name" : "host-group-1",</div><div class="line">                      "hosts" : [ &#123; "fqdn" : "c6401.ambari.apache.org" &#125; ]</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                      "name" : "host-group-2",</div><div class="line">                      "hosts" : [ &#123; "fqdn" : "c6402.ambari.apache.org" &#125; ]</div><div class="line">                    &#125;</div><div class="line">                  ]</div><div class="line">                &#125;</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">          ]</div><div class="line">        &#125;</div><div class="line">    """</div><div class="line">    <span class="keyword">pass</span></div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">validateComponentLayout</span><span class="params">(self, services, hosts)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Returns array of Validation issues with service component layout on hosts</div><div class="line"> </div><div class="line"> </div><div class="line">    This function takes as input all details about services being installed along with</div><div class="line">    hosts the components are being installed on (hostnames property is populated for</div><div class="line">    each component). </div><div class="line"> </div><div class="line">    @type services: dictionary</div><div class="line">    @param services: Dictionary containing information about services and host layout selected by the user.</div><div class="line">    @type hosts: dictionary</div><div class="line">    @param hosts: Dictionary containing all information about hosts in this cluster</div><div class="line">    @rtype: dictionary</div><div class="line">    @return: Dictionary containing array of validation items</div><div class="line">        Example: &#123;</div><div class="line">          "items": [</div><div class="line">            &#123;</div><div class="line">              "type" : "host-group",</div><div class="line">              "level" : "ERROR",</div><div class="line">              "message" : "NameNode and Secondary NameNode should not be hosted on the same machine",</div><div class="line">              "component-name" : "NAMENODE",</div><div class="line">              "host" : "c6401.ambari.apache.org"</div><div class="line">            &#125;,</div><div class="line">            ...</div><div class="line">          ]</div><div class="line">        &#125; </div><div class="line">    """</div><div class="line">    <span class="keyword">pass</span></div><div class="line"> </div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">recommendConfigurations</span><span class="params">(self, services, hosts)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Returns recommendation of service configurations based on host-specific layout of components.</div><div class="line"> </div><div class="line">    This function takes as input all details about services being installed, and hosts</div><div class="line">    they are being installed into, to recommend host-specific configurations.</div><div class="line"> </div><div class="line"> </div><div class="line">    @type services: dictionary</div><div class="line">    @param services: Dictionary containing all information about services and component layout selected by the user.</div><div class="line">    @type hosts: dictionary</div><div class="line">    @param hosts: Dictionary containing all information about hosts in this cluster</div><div class="line">    @rtype: dictionary</div><div class="line">    @return: Layout recommendation of service components on cluster hosts in Ambari Blueprints friendly format.</div><div class="line">        Example: &#123;</div><div class="line">         "services": [</div><div class="line">          "HIVE",</div><div class="line">          "TEZ",</div><div class="line">          "YARN"</div><div class="line">         ],</div><div class="line">         "recommendations": &#123;</div><div class="line">          "blueprint": &#123;</div><div class="line">           "host_groups": [],</div><div class="line">           "configurations": &#123;</div><div class="line">            "yarn-site": &#123;</div><div class="line">             "properties": &#123;</div><div class="line">              "yarn.scheduler.minimum-allocation-mb": "682",</div><div class="line">              "yarn.scheduler.maximum-allocation-mb": "2048",</div><div class="line">              "yarn.nodemanager.resource.memory-mb": "2048"</div><div class="line">             &#125;</div><div class="line">            &#125;,</div><div class="line">            "tez-site": &#123;</div><div class="line">             "properties": &#123;</div><div class="line">              "tez.am.java.opts": "-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:+UseNUMA -XX:+UseParallelGC",</div><div class="line">              "tez.am.resource.memory.mb": "682"</div><div class="line">             &#125;</div><div class="line">            &#125;,</div><div class="line">            "hive-site": &#123;</div><div class="line">             "properties": &#123;</div><div class="line">              "hive.tez.container.size": "682",</div><div class="line">              "hive.tez.java.opts": "-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC",</div><div class="line">              "hive.auto.convert.join.noconditionaltask.size": "238026752"</div><div class="line">             &#125;</div><div class="line">            &#125;</div><div class="line">           &#125;</div><div class="line">          &#125;,</div><div class="line">          "blueprint_cluster_binding": &#123;</div><div class="line">           "host_groups": []</div><div class="line">          &#125;</div><div class="line">         &#125;,</div><div class="line">         "hosts": [</div><div class="line">          "c6401.ambari.apache.org",</div><div class="line">          "c6402.ambari.apache.org",</div><div class="line">          "c6403.ambari.apache.org"</div><div class="line">         ]</div><div class="line">        &#125;</div><div class="line">    """</div><div class="line">    <span class="keyword">pass</span></div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">validateConfigurations</span><span class="params">(self, services, hosts)</span>:</span></div><div class="line">    <span class="string">""""</span></div><div class="line">    Returns array of Validation issues with configurations provided by user</div><div class="line">    This function takes as input all details about services being installed along with</div><div class="line">    configuration values entered by the user. These configurations can be validated against</div><div class="line">    service requirements, or host hardware to generate validation issues.</div><div class="line"> </div><div class="line"> </div><div class="line">    @type services: dictionary</div><div class="line">    @param services: Dictionary containing information about services and user configurations.</div><div class="line">    @type hosts: dictionary</div><div class="line">    @param hosts: Dictionary containing all information about hosts in this cluster</div><div class="line">    @rtype: dictionary</div><div class="line">    @return: Dictionary containing array of validation items</div><div class="line">        Example: &#123;</div><div class="line">         "items": [</div><div class="line">          &#123;</div><div class="line">           "config-type": "yarn-site",</div><div class="line">           "message": "Value is less than the recommended default of 682",</div><div class="line">           "type": "configuration",</div><div class="line">           "config-name": "yarn.scheduler.minimum-allocation-mb",</div><div class="line">           "level": "WARN"</div><div class="line">          &#125;</div><div class="line">         ]</div><div class="line">       &#125;</div><div class="line">    """</div><div class="line">    <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<h4 id="Examples-3"><a href="#Examples-3" class="headerlink" title="Examples:"></a>Examples:</h4><blockquote>
<p><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/stack_advisor.py#L23" title="Stack Advisor interface" target="_blank" rel="external">Stack Advisor interface</a><br><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/stack_advisor.py#L303" title="Default Stack Advisor implementation - for all stacks" target="_blank" rel="external">Default Stack Advisor implementation - for all stacks</a><br><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L28" title="HDP(2.0.6) Default Stack Advisor implementation" target="_blank" rel="external">HDP(2.0.6) Default Stack Advisor implementation</a><br><a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L807" title="YARN container size calculate" target="_blank" rel="external">YARN container size calculate</a><br>Recommended configurations - <a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L222" target="_blank" rel="external">HDFS</a>，<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L133" target="_blank" rel="external">YARN</a>，<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L148" target="_blank" rel="external">MapReduce2</a>, <a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L245" target="_blank" rel="external">HBase</a> (HDP-2.0.6)，<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L148" target="_blank" rel="external">HBase</a> (HDP-2.3)<br><a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/services/stack_advisor.py#L272" target="_blank" rel="external">Delete HBase Bucket Cache configs on smaller machines</a><br><a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/services/stack_advisor.py#L184" target="_blank" rel="external">Specify maximum value for Tez config</a></p>
</blockquote>
<h3 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h3><p>与stack的配置类似，大多属性都是在service级定义，然而也可以在stack-version级别定义全局属性来影响所有的services。<br>一些例子：<a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_tools.json#L2" target="_blank" rel="external">stack-selector and conf-selector</a> 或 <a href="https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_features.json#L5" target="_blank" rel="external">stack versions certain stack features</a>。这里的大多属性都是在Ambari 2.4版本引入的以影响stack信息参数化和促进common-service代码重用。<br>这些属性可以定义在stack的properties文件中的.json文件中。<br>stack属性的更多信息可以在<a href="https://cwiki.apache.org/confluence/x/pgPiAw" target="_blank" rel="external">Stack Properties section</a>找到。</p>
<h3 id="Widgets-1"><a href="#Widgets-1" class="headerlink" title="Widgets"></a>Widgets</h3><p>暂无</p>
<h3 id="Kerberos-1"><a href="#Kerberos-1" class="headerlink" title="Kerberos"></a>Kerberos</h3><p>之前我们已经在service级别介绍了Kerberos。<br>stack-version级别定义的Kerberos为所有的service提供了身份描述。</p>
<p>Examples：<a href="https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/kerberos.json" target="_blank" rel="external">Smoke test user and SPNEGO user define in HDP-2.0.6</a></p>
<h3 id="Stack-Upgrades"><a href="#Stack-Upgrades" class="headerlink" title="Stack Upgrades"></a>Stack Upgrades</h3><p>暂无</p>
<h1 id="Writing-metainfo-xml"><a href="#Writing-metainfo-xml" class="headerlink" title="Writing metainfo.xml"></a>Writing metainfo.xml</h1><p>metainfo.xml是Ambari管理的service的定义，它描述了service的内容。它是service定义中最重要的文件。这一章来介绍metainfo.xml中的各个片段。</p>
<h2 id="Structure-1"><a href="#Structure-1" class="headerlink" title="Structure"></a>Structure</h2><p>不重要的字段使用斜体显示。<br>描述一个service的顶级字段如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Field</th>
<th style="text-align:left">What is it used for</th>
<th style="text-align:left">Sample Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>name</strong></td>
<td style="text-align:left">service的名字。这个名字必须是service所在Stack范围内唯一的。</td>
<td style="text-align:left">HDFS</td>
</tr>
<tr>
<td style="text-align:left"><strong>displayName</strong></td>
<td style="text-align:left">service在UI中显示的名字。</td>
<td style="text-align:left">HDFS</td>
</tr>
<tr>
<td style="text-align:left"><strong>version</strong></td>
<td style="text-align:left">service的版本。名字和版本一起确定了唯一的service。</td>
<td style="text-align:left">2.1.0.2.0</td>
</tr>
<tr>
<td style="text-align:left"><strong>components</strong></td>
<td style="text-align:left">service的组件列表</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><strong>osSpecifics</strong></td>
<td style="text-align:left">指定service运行所需的操作系统</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>commandScript</em></td>
<td style="text-align:left">定义service check脚本</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>comment</em></td>
<td style="text-align:left">service的简短描述</td>
<td style="text-align:left">Apache Hadoop Distributed File System</td>
</tr>
<tr>
<td style="text-align:left"><em>requiredServices</em></td>
<td style="text-align:left">该服务所需的前置服务</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>configuration-dependencies</em></td>
<td style="text-align:left">service所需的其他配置文件（这些配置文件本身属于其他service）</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>restartRequiredAfterRackChange</em></td>
<td style="text-align:left">Rack变更后是否必须重启</td>
<td style="text-align:left">true / false</td>
</tr>
<tr>
<td style="text-align:left"><em>configuration-dir</em></td>
<td style="text-align:left">如果配置目录不是默认的configuration，则需要使用该项来指定</td>
<td style="text-align:left">-</td>
</tr>
</tbody>
</table>
<h3 id="service-components-一个service包含多个components。与component有关的字段有："><a href="#service-components-一个service包含多个components。与component有关的字段有：" class="headerlink" title="service/components - 一个service包含多个components。与component有关的字段有："></a>service/components - 一个service包含多个components。与component有关的字段有：</h3><table>
<thead>
<tr>
<th style="text-align:left">Field</th>
<th style="text-align:left">What is it used it</th>
<th style="text-align:left">Sample Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>name</strong></td>
<td style="text-align:left">component的名字。</td>
<td style="text-align:left">NameNode</td>
</tr>
<tr>
<td style="text-align:left"><strong>dsplayName</strong></td>
<td style="text-align:left">component的显示名。</td>
<td style="text-align:left">NameNode</td>
</tr>
<tr>
<td style="text-align:left"><strong>category</strong></td>
<td style="text-align:left">component的类型。可选值为MASTER、SLAVE或CLIENT。</td>
<td style="text-align:left">-</td>
</tr>
<tr>
<td style="text-align:left"><strong>commandScript</strong></td>
<td style="text-align:left">应用的命令。</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>cardinality</em></td>
<td style="text-align:left">允许的实例个数。</td>
<td style="text-align:left">MASTER一般设置为1-2， SLAVE一般设置为1+</td>
</tr>
<tr>
<td style="text-align:left"><em>reassignAllowed</em></td>
<td style="text-align:left">是否允许component被重新分配或移动到另外的主机。</td>
<td style="text-align:left">true / false</td>
</tr>
<tr>
<td style="text-align:left"><em>versionAdvertised</em></td>
<td style="text-align:left">component是否显示它的版本信息。回滚/升级时使用。</td>
<td style="text-align:left">true / false</td>
</tr>
<tr>
<td style="text-align:left"><em>timelineAppid</em></td>
<td style="text-align:left">metrics收集时用来进行区分的id。</td>
<td style="text-align:left">HDFS</td>
</tr>
<tr>
<td style="text-align:left"><em>dependencies</em></td>
<td style="text-align:left">component所依赖的其他component列表。</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><em>customCommands</em></td>
<td style="text-align:left">组件的自定义命令，有别与标准命令。</td>
<td style="text-align:left">RESTART_LLAP (Check out HIVE metainfo)</td>
</tr>
</tbody>
</table>
<h3 id="service-osSpecifics-操作系统包的名"><a href="#service-osSpecifics-操作系统包的名" class="headerlink" title="service/osSpecifics - 操作系统包的名"></a>service/osSpecifics - 操作系统包的名</h3><table>
<thead>
<tr>
<th style="text-align:left">Field</th>
<th style="text-align:left">What is it used for</th>
<th style="text-align:left">Sample Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>osFamily</strong></td>
<td style="text-align:left">service对应的操作系统</td>
<td style="text-align:left">any =&gt; all， amazon2015、redhat6、debian7</td>
</tr>
<tr>
<td style="text-align:left"><strong>packages</strong></td>
<td style="text-align:left">部署这个service所需的packages列表</td>
<td style="text-align:left">&lt; check out HDFS metainfo&gt;</td>
</tr>
<tr>
<td style="text-align:left"><strong>package/name</strong></td>
<td style="text-align:left">package的名字(会被yum\apt等命令使用)</td>
<td style="text-align:left">如 hadoop-lzo</td>
</tr>
</tbody>
</table>
<h3 id="service-commandScript-service检查的脚本"><a href="#service-commandScript-service检查的脚本" class="headerlink" title="service/commandScript - service检查的脚本"></a>service/commandScript - service检查的脚本</h3><table>
<thead>
<tr>
<th style="text-align:left">Field</th>
<th style="text-align:left">What is it used for</th>
<th style="text-align:left">Sample Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>script</strong></td>
<td style="text-align:left">脚本的相对路径</td>
<td style="text-align:left">scripts/service_check.py</td>
</tr>
<tr>
<td style="text-align:left"><strong>scriptType</strong></td>
<td style="text-align:left">脚本的类型，当前纸支持PYTHON</td>
<td style="text-align:left">PYTHON</td>
</tr>
<tr>
<td style="text-align:left"><strong>timeout</strong></td>
<td style="text-align:left">命令的超时时间</td>
<td style="text-align:left">300</td>
</tr>
</tbody>
</table>
<h3 id="service-component-customCommand-component的自定义命令"><a href="#service-component-customCommand-component的自定义命令" class="headerlink" title="service/component/customCommand - component的自定义命令"></a>service/component/customCommand - component的自定义命令</h3><blockquote>
<p><strong>name:</strong> 自定义命令的名字<br><strong>commandScript:</strong> 实现自定义命令的脚本信息，它包含其他片段。<br><strong>commandScript/script:</strong> 脚本的相对路径<br><strong>commandScript/scriptType:</strong> 脚本的类型，目前只支持PYTHON。<br><strong>commandScript/timeout:</strong> 命令的超时时间。</p>
</blockquote>
<h2 id="Sample-metainfo-xml"><a href="#Sample-metainfo-xml" class="headerlink" title="Sample metainfo.xml"></a>Sample metainfo.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">metainfo</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">schemaVersion</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">schemaVersion</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">services</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">service</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>HBASE<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">displayName</span>&gt;</span>HBase<span class="tag">&lt;/<span class="name">displayName</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">comment</span>&gt;</span>Non-relational distributed database and centralized service for configuration management &amp;amp;</div><div class="line"> synchronization</div><div class="line">      <span class="tag">&lt;/<span class="name">comment</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.96.0.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">components</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">component</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>HBASE_MASTER<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">displayName</span>&gt;</span>HBase Master<span class="tag">&lt;/<span class="name">displayName</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">category</span>&gt;</span>MASTER<span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">cardinality</span>&gt;</span>1+<span class="tag">&lt;/<span class="name">cardinality</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">versionAdvertised</span>&gt;</span>true<span class="tag">&lt;/<span class="name">versionAdvertised</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">timelineAppid</span>&gt;</span>HBASE<span class="tag">&lt;/<span class="name">timelineAppid</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>HDFS/HDFS_CLIENT<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">scope</span>&gt;</span>host<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">auto-deploy</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">              <span class="tag">&lt;/<span class="name">auto-deploy</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>ZOOKEEPER/ZOOKEEPER_SERVER<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">scope</span>&gt;</span>cluster<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">auto-deploy</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">co-locate</span>&gt;</span>HBASE/HBASE_MASTER<span class="tag">&lt;/<span class="name">co-locate</span>&gt;</span></div><div class="line">              <span class="tag">&lt;/<span class="name">auto-deploy</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">commandScript</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined">scripts/hbase_master.py</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">scriptType</span>&gt;</span>PYTHON<span class="tag">&lt;/<span class="name">scriptType</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">timeout</span>&gt;</span>1200<span class="tag">&lt;/<span class="name">timeout</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">commandScript</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">customCommands</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">customCommand</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>DECOMMISSION<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">commandScript</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined">scripts/hbase_master.py</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">scriptType</span>&gt;</span>PYTHON<span class="tag">&lt;/<span class="name">scriptType</span>&gt;</span></div><div class="line">                <span class="tag">&lt;<span class="name">timeout</span>&gt;</span>600<span class="tag">&lt;/<span class="name">timeout</span>&gt;</span></div><div class="line">              <span class="tag">&lt;/<span class="name">commandScript</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">customCommand</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">customCommands</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">component</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>HBASE_REGIONSERVER<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">displayName</span>&gt;</span>RegionServer<span class="tag">&lt;/<span class="name">displayName</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">category</span>&gt;</span>SLAVE<span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">cardinality</span>&gt;</span>1+<span class="tag">&lt;/<span class="name">cardinality</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">versionAdvertised</span>&gt;</span>true<span class="tag">&lt;/<span class="name">versionAdvertised</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">timelineAppid</span>&gt;</span>HBASE<span class="tag">&lt;/<span class="name">timelineAppid</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">commandScript</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined">scripts/hbase_regionserver.py</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">scriptType</span>&gt;</span>PYTHON<span class="tag">&lt;/<span class="name">scriptType</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">commandScript</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">component</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>HBASE_CLIENT<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">displayName</span>&gt;</span>HBase Client<span class="tag">&lt;/<span class="name">displayName</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">category</span>&gt;</span>CLIENT<span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">cardinality</span>&gt;</span>1+<span class="tag">&lt;/<span class="name">cardinality</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">versionAdvertised</span>&gt;</span>true<span class="tag">&lt;/<span class="name">versionAdvertised</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">commandScript</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined">scripts/hbase_client.py</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">scriptType</span>&gt;</span>PYTHON<span class="tag">&lt;/<span class="name">scriptType</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">commandScript</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">configFiles</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">configFile</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">type</span>&gt;</span>xml<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">fileName</span>&gt;</span>hbase-site.xml<span class="tag">&lt;/<span class="name">fileName</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">dictionaryName</span>&gt;</span>hbase-site<span class="tag">&lt;/<span class="name">dictionaryName</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">configFile</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">configFile</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">type</span>&gt;</span>env<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">fileName</span>&gt;</span>hbase-env.sh<span class="tag">&lt;/<span class="name">fileName</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">dictionaryName</span>&gt;</span>hbase-env<span class="tag">&lt;/<span class="name">dictionaryName</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">configFile</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">configFiles</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">component</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">components</span>&gt;</span></div><div class="line"></div><div class="line">      <span class="tag">&lt;<span class="name">osSpecifics</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">osSpecific</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">osFamily</span>&gt;</span>any<span class="tag">&lt;/<span class="name">osFamily</span>&gt;</span></div><div class="line">          <span class="tag">&lt;<span class="name">packages</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">package</span>&gt;</span></div><div class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">            <span class="tag">&lt;/<span class="name">package</span>&gt;</span></div><div class="line">          <span class="tag">&lt;/<span class="name">packages</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">osSpecific</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">osSpecifics</span>&gt;</span></div><div class="line"></div><div class="line">      <span class="tag">&lt;<span class="name">commandScript</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined">scripts/service_check.py</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">scriptType</span>&gt;</span>PYTHON<span class="tag">&lt;/<span class="name">scriptType</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">timeout</span>&gt;</span>300<span class="tag">&lt;/<span class="name">timeout</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">commandScript</span>&gt;</span></div><div class="line">      </div><div class="line">      <span class="tag">&lt;<span class="name">requiredServices</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">service</span>&gt;</span>ZOOKEEPER<span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">service</span>&gt;</span>HDFS<span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">requiredServices</span>&gt;</span></div><div class="line"></div><div class="line">      <span class="tag">&lt;<span class="name">configuration-dependencies</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">config-type</span>&gt;</span>core-site<span class="tag">&lt;/<span class="name">config-type</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">config-type</span>&gt;</span>hbase-site<span class="tag">&lt;/<span class="name">config-type</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">config-type</span>&gt;</span>ranger-hbase-policymgr-ssl<span class="tag">&lt;/<span class="name">config-type</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">config-type</span>&gt;</span>ranger-hbase-security<span class="tag">&lt;/<span class="name">config-type</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">configuration-dependencies</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;/<span class="name">service</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">services</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">metainfo</span>&gt;</span></div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/blog/2018/08/13/ambari/" itemprop="url">
                  Ambari
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-08-13T10:42:44+08:00" content="2018-08-13">
              2018-08-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/blog/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                

              
            </span>
          

          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文用来记录Ambari的学习</p>
<h1 id="Ambari的简单介绍"><a href="#Ambari的简单介绍" class="headerlink" title="Ambari的简单介绍"></a>Ambari的简单介绍</h1><p>从Ambari的作用来说，它是用来创建、管理、监控Hadoop生态（例如hadoop、hive、hbase、Sqoop以及Zookeeper）集群的工具。Ambari就是为了让Hadoop已经相关的大数据软件更容易使用的一个工具。Ambari支持的平台组建也越来越多，如流行的Spark、Storm等计算框架，已经资源调度平台YARN等，都可以通过Ambari来轻松部署。</p>
<p>Ambari自称也是一个分布式架构的软件，主要由两部分组成：Ambari Server和Ambari Agent。用户通过Ambari Server来通知Ambari Agent来安装对应的软件；Agent会定时的发送各个机器每个软件模块的状态给Ambari Server，最终这些信息会呈现在Ambari的GUI中，方便用户了解集群中各个模块的状态，并进行维护。</p>
<h1 id="Ambari的架构和工作原理"><a href="#Ambari的架构和工作原理" class="headerlink" title="Ambari的架构和工作原理"></a>Ambari的架构和工作原理</h1><p>Ambari Server会读取Stack和Service的配置文件。当用Ambari创建集群的时候，Ambari Server传送Stack和Service的配置文件配以及Service生命周期的控制脚本到Ambari Agent。Agent拿到配置文件后，会下载安装公共资源里的软件包。安装完成后，Ambari Server会通知Agent去启动Service。之后，Ambari Server会定时发送命令道Agent检查Service的状态，Agent上报给Server并显示在Ambari的UI上。<br>Ambari Server支持其他API，这样能够很容易的扩展或定制Ambari。<br>如果有安全方面的要求，Ambari支持Kerberos认证的hadoop集群。</p>
<blockquote>
<p>Ambari web：用户交互界面，通过HTTP发送使用Rest API与Ambari Server进行交互。<br>Ambari Server：Ambari服务器，用于和Web、Agent进行交互，并且包含了Agent的所有控制逻辑，Server产生的数据存储在DB中。<br>Ambari Agent：守护进程，主要包含节点状态与执行结果信息汇报给Server，以及接受Server操作命令的两个消息队列。<br>Host：安装实际大数据服务组件的物理机器，每台机器都有Ambari Agent和Metrcis Monitor守护进程服务。<br>Metrics Collector：主要包括将Metrics monitor汇报的监控信息存储到Hbase，以及提供给Ambari Server的查询接口。</p>
</blockquote>
<h1 id="Ambari的自定义命令"><a href="#Ambari的自定义命令" class="headerlink" title="Ambari的自定义命令"></a>Ambari的自定义命令</h1><p>在Ambari的Stack中，每个Service都有start、stop、status和configure这样的命令，我们称为生命周期的控制命令。Service的每个模块必须实现这几个命令。为了让用户可以更好的控制每个service以及模块，Ambari支持了自定义命令。<br>具体的自定义命令配置在每个Service的metainfo.xml中。不过不同的模块类型，呈现在GUI的方式是不一样的。当一个service的Master模块增加一个自定义命令时，该命令会显示在该Service的Service Action List中。如果点击这个命令，Ambari Server就会通知Master所在机器的Agent，Agent就会执行该自定义命令的逻辑。当增加一个自定义命令给Slave或Client类型的Component，该命令会呈现在机器的Component页面。在哪个机器的Component页面点击该命令，Ambari Server就会通知对应机器的Agent调用这个自定义的命令接口。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/blog/page/2/">2</a><a class="page-number" href="/blog/page/3/">3</a><a class="extend next" rel="next" href="/blog/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/blog/uploads/avatar.png"
               alt="baimoon" />
          <p class="site-author-name" itemprop="name">baimoon</p>
          <p class="site-description motion-element" itemprop="description">Baimoon's blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/blog/archives">
              <span class="site-state-item-count">56</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/blog/categories">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/blog/tags">
                <span class="site-state-item-count">25</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/baimoon" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://gallery.xrange.org" title="xrange" target="_blank">xrange</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016-07 - 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">baimoon</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/blog/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/blog/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/blog/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/blog/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
